{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"source/favicon.ico","path":"favicon.ico","modified":0,"renderable":0},{"_id":"source/about/index.md.bak","path":"about/index.md.bak","modified":0,"renderable":0},{"_id":"source/uploads/alipay-reward.jpg","path":"uploads/alipay-reward.jpg","modified":0,"renderable":0},{"_id":"source/uploads/wechat-qcode.jpg","path":"uploads/wechat-qcode.jpg","modified":0,"renderable":0},{"_id":"source/uploads/wechat-reward.jpg","path":"uploads/wechat-reward.jpg","modified":0,"renderable":0},{"_id":"source/images/pasted-0.png","path":"images/pasted-0.png","modified":0,"renderable":0},{"_id":"source/images/pasted-1.png","path":"images/pasted-1.png","modified":0,"renderable":0},{"_id":"source/images/pasted-10.png","path":"images/pasted-10.png","modified":0,"renderable":0},{"_id":"source/images/pasted-11.png","path":"images/pasted-11.png","modified":0,"renderable":0},{"_id":"source/images/pasted-12.png","path":"images/pasted-12.png","modified":0,"renderable":0},{"_id":"source/images/pasted-13.png","path":"images/pasted-13.png","modified":0,"renderable":0},{"_id":"source/images/pasted-14.png","path":"images/pasted-14.png","modified":0,"renderable":0},{"_id":"source/images/pasted-15.png","path":"images/pasted-15.png","modified":0,"renderable":0},{"_id":"source/images/pasted-16.png","path":"images/pasted-16.png","modified":0,"renderable":0},{"_id":"source/images/pasted-17.png","path":"images/pasted-17.png","modified":0,"renderable":0},{"_id":"source/images/pasted-18.png","path":"images/pasted-18.png","modified":0,"renderable":0},{"_id":"source/images/pasted-19.png","path":"images/pasted-19.png","modified":0,"renderable":0},{"_id":"source/images/pasted-2.png","path":"images/pasted-2.png","modified":0,"renderable":0},{"_id":"source/images/pasted-20.png","path":"images/pasted-20.png","modified":0,"renderable":0},{"_id":"source/images/pasted-21.png","path":"images/pasted-21.png","modified":0,"renderable":0},{"_id":"source/images/pasted-22.png","path":"images/pasted-22.png","modified":0,"renderable":0},{"_id":"source/images/pasted-23.png","path":"images/pasted-23.png","modified":0,"renderable":0},{"_id":"source/images/pasted-24.png","path":"images/pasted-24.png","modified":0,"renderable":0},{"_id":"source/images/pasted-25.png","path":"images/pasted-25.png","modified":0,"renderable":0},{"_id":"source/images/pasted-26.png","path":"images/pasted-26.png","modified":0,"renderable":0},{"_id":"source/images/pasted-27.png","path":"images/pasted-27.png","modified":0,"renderable":0},{"_id":"source/images/pasted-28.png","path":"images/pasted-28.png","modified":0,"renderable":0},{"_id":"source/images/pasted-29.png","path":"images/pasted-29.png","modified":0,"renderable":0},{"_id":"source/images/pasted-3.png","path":"images/pasted-3.png","modified":0,"renderable":0},{"_id":"source/images/pasted-30.png","path":"images/pasted-30.png","modified":0,"renderable":0},{"_id":"source/images/pasted-31.png","path":"images/pasted-31.png","modified":0,"renderable":0},{"_id":"source/images/pasted-32.png","path":"images/pasted-32.png","modified":0,"renderable":0},{"_id":"source/images/pasted-33.png","path":"images/pasted-33.png","modified":0,"renderable":0},{"_id":"source/images/pasted-34.png","path":"images/pasted-34.png","modified":0,"renderable":0},{"_id":"source/images/pasted-35.png","path":"images/pasted-35.png","modified":0,"renderable":0},{"_id":"source/images/pasted-36.png","path":"images/pasted-36.png","modified":0,"renderable":0},{"_id":"source/images/pasted-37.png","path":"images/pasted-37.png","modified":0,"renderable":0},{"_id":"source/images/pasted-38.png","path":"images/pasted-38.png","modified":0,"renderable":0},{"_id":"source/images/pasted-39.png","path":"images/pasted-39.png","modified":0,"renderable":0},{"_id":"source/images/pasted-4.png","path":"images/pasted-4.png","modified":0,"renderable":0},{"_id":"source/images/pasted-40.png","path":"images/pasted-40.png","modified":0,"renderable":0},{"_id":"source/images/pasted-41.png","path":"images/pasted-41.png","modified":0,"renderable":0},{"_id":"source/images/pasted-42.png","path":"images/pasted-42.png","modified":0,"renderable":0},{"_id":"source/images/pasted-43.png","path":"images/pasted-43.png","modified":0,"renderable":0},{"_id":"source/images/pasted-44.png","path":"images/pasted-44.png","modified":0,"renderable":0},{"_id":"source/images/pasted-45.png","path":"images/pasted-45.png","modified":0,"renderable":0},{"_id":"source/images/pasted-46.png","path":"images/pasted-46.png","modified":0,"renderable":0},{"_id":"source/images/pasted-47.png","path":"images/pasted-47.png","modified":0,"renderable":0},{"_id":"source/images/pasted-48.png","path":"images/pasted-48.png","modified":0,"renderable":0},{"_id":"source/images/pasted-49.png","path":"images/pasted-49.png","modified":0,"renderable":0},{"_id":"source/images/pasted-5.png","path":"images/pasted-5.png","modified":0,"renderable":0},{"_id":"source/images/pasted-50.png","path":"images/pasted-50.png","modified":0,"renderable":0},{"_id":"source/images/pasted-51.png","path":"images/pasted-51.png","modified":0,"renderable":0},{"_id":"source/images/pasted-52.png","path":"images/pasted-52.png","modified":0,"renderable":0},{"_id":"source/images/pasted-53.png","path":"images/pasted-53.png","modified":0,"renderable":0},{"_id":"source/images/pasted-54.png","path":"images/pasted-54.png","modified":0,"renderable":0},{"_id":"source/images/pasted-55.png","path":"images/pasted-55.png","modified":0,"renderable":0},{"_id":"source/images/pasted-56.png","path":"images/pasted-56.png","modified":0,"renderable":0},{"_id":"source/images/pasted-57.png","path":"images/pasted-57.png","modified":0,"renderable":0},{"_id":"source/images/pasted-58.png","path":"images/pasted-58.png","modified":0,"renderable":0},{"_id":"source/images/pasted-59.png","path":"images/pasted-59.png","modified":0,"renderable":0},{"_id":"source/images/pasted-6.png","path":"images/pasted-6.png","modified":0,"renderable":0},{"_id":"source/images/pasted-60.png","path":"images/pasted-60.png","modified":0,"renderable":0},{"_id":"source/images/pasted-61.png","path":"images/pasted-61.png","modified":0,"renderable":0},{"_id":"source/images/pasted-62.png","path":"images/pasted-62.png","modified":0,"renderable":0},{"_id":"source/images/pasted-63.png","path":"images/pasted-63.png","modified":0,"renderable":0},{"_id":"source/images/pasted-64.png","path":"images/pasted-64.png","modified":0,"renderable":0},{"_id":"source/images/pasted-65.png","path":"images/pasted-65.png","modified":0,"renderable":0},{"_id":"source/images/pasted-66.png","path":"images/pasted-66.png","modified":0,"renderable":0},{"_id":"source/images/pasted-67.png","path":"images/pasted-67.png","modified":0,"renderable":0},{"_id":"source/images/pasted-68.png","path":"images/pasted-68.png","modified":0,"renderable":0},{"_id":"source/images/pasted-69.png","path":"images/pasted-69.png","modified":0,"renderable":0},{"_id":"source/images/pasted-7.png","path":"images/pasted-7.png","modified":0,"renderable":0},{"_id":"source/images/pasted-8.png","path":"images/pasted-8.png","modified":0,"renderable":0},{"_id":"source/images/pasted-9.png","path":"images/pasted-9.png","modified":0,"renderable":0},{"_id":"source/researcherpapers/rdma/rdma_components.png","path":"researcherpapers/rdma/rdma_components.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/algolia-search.js","path":"js/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/anime.min.js","path":"lib/anime.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/muse.js","path":"js/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/schemes/pisces.js","path":"js/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/LICENSE","path":"lib/three/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/README.md","path":"lib/three/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/gulpfile.js","path":"lib/three/gulpfile.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/package.json","path":"lib/three/package.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/renovate.json","path":"lib/three/renovate.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/lib/CanvasRenderer.js","path":"lib/three/lib/CanvasRenderer.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/lib/Projector.js","path":"lib/three/lib/Projector.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/src/canvas_lines.js","path":"lib/three/src/canvas_lines.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/src/canvas_sphere.js","path":"lib/three/src/canvas_sphere.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/src/three-waves.js","path":"lib/three/src/three-waves.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/LICENSE","path":"lib/canvas-ribbon/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/README.md","path":"lib/canvas-ribbon/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/404.html","hash":"10893497bf3a1a7375be28d8cfed41cf5bd10534","modified":1715197678624},{"_id":"source/favicon.ico","hash":"1cdb7ff6cca73ee968a0e42077deda272364872c","modified":1715197678628},{"_id":"source/_posts/2014-OSDI-GraphX-Graph-Processing-in-a-Distributed-Dataflow-Framework.md","hash":"2f4e4992cb0baab5b29ff64a269e4ead73c96b5f","modified":1715197678624},{"_id":"source/_posts/Apache-Flink-官方文档翻译之-容错机制.md","hash":"d6729016ad81f5ba0122a74390238a9961a69131","modified":1715197678625},{"_id":"source/_posts/Apache-Flink-官方文档翻译之编程模型.md","hash":"52a6ac6218d359bc010c4ebbd8673dea7f764fae","modified":1715197678625},{"_id":"source/_posts/Bipartite-graph-二分图.md","hash":"acf12ee0995e54cb37253f110ed507dd5e52cea7","modified":1715197678625},{"_id":"source/_posts/Design-Guidelines-for-High-Performance-RDMA-Systems.md","hash":"f57c19418b73dba72530e73cb97672352915d7f7","modified":1715197678625},{"_id":"source/_posts/Linux服务管理.md","hash":"3a300153bf529a575b3e95981c11a4d79e775d6a","modified":1715197678625},{"_id":"source/_posts/PCIE和PCI-计算机总线.md","hash":"ddc1861f7bfe63003ff659dc0e7accd0a0a58e60","modified":1715197678626},{"_id":"source/_posts/RDMA技术详解.md","hash":"34508eaa463271f1a3fa7c5de75b6054ad9f11d5","modified":1715197678626},{"_id":"source/_posts/Sub-millisecond-Stateful-Stream-Querying-over-Fast-evolving-Linked-Data.md","hash":"200113d50305396c78da23ecf395815175d0450a","modified":1715197678626},{"_id":"source/_posts/TUX2-Distributed-Graph-Computation-for-Machine-Learning.md","hash":"907872967ffd5c68edf9de8d07a63bbca91d4e90","modified":1715197678626},{"_id":"source/_posts/Untitled.md","hash":"af74c55c055cd23853d3aaae612318563e127e2f","modified":1715197678626},{"_id":"source/_posts/内存映射IO-MMIO.md","hash":"49ce71e85ac6ccd8f340ae39c9543112118b0ff9","modified":1715197678627},{"_id":"source/_posts/深入浅出全面解析RDMA.md","hash":"958e790ca7adf6c0423c1478f5ab6d96955df45c","modified":1715197678627},{"_id":"source/_posts/虚拟内存.md","hash":"1a10445ca1976acbbe31b9f8147f8609fcc9229c","modified":1715197678627},{"_id":"source/about/index.md","hash":"cbcc329de7b97b2e24338e01545afee58c062492","modified":1715197678627},{"_id":"source/about/index.md.bak","hash":"172143edbd77ce53994687436731a5ca34946962","modified":1715197678627},{"_id":"source/categories/index.md","hash":"dde804421eaf348082ffb49629188b4815114e51","modified":1715197678628},{"_id":"source/tags/index.md","hash":"2dd1a12c9b11d7a7a870fd1f1991554759f682b3","modified":1715197678679},{"_id":"source/uploads/alipay-reward.jpg","hash":"c1e1b800343030c2a0cdf2f3368622435c692153","modified":1715197678680},{"_id":"source/images/pasted-1.png","hash":"f8661ab78160bf2bed84c0ebce858941ca7eda97","modified":1715197678630},{"_id":"source/images/pasted-12.png","hash":"7c62171444c797b96beb89cba10021e8cab9ad2c","modified":1715197678632},{"_id":"source/images/pasted-13.png","hash":"b5bb48aebbf1249d718ad9c7edec2b939db38129","modified":1715197678632},{"_id":"source/images/pasted-14.png","hash":"e3bddb2efac610df92827ea54765b03659d57e85","modified":1715197678633},{"_id":"source/images/pasted-17.png","hash":"03239d856a0ee58c78c9b6b582023dd2cc0d7c36","modified":1715197678637},{"_id":"source/images/pasted-18.png","hash":"0f9461af0fd8d822099ec8da73cf9a1ff192f837","modified":1715197678637},{"_id":"source/images/pasted-2.png","hash":"dab264dc9cbf978be9e8df18213585b2cfccdb41","modified":1715197678639},{"_id":"source/images/pasted-21.png","hash":"c005097d80fb0a5680db1fd57857b4d3c16f1aec","modified":1715197678642},{"_id":"source/images/pasted-23.png","hash":"240285a9754e5095726d44d9cd28c18344a9728b","modified":1715197678643},{"_id":"source/images/pasted-24.png","hash":"41b6c59420554d9ef0fd22e0ac60af432d1cd4b6","modified":1715197678644},{"_id":"source/images/pasted-25.png","hash":"235418b6ae3c4b9bbbd8e439a32ba29a770afe52","modified":1715197678645},{"_id":"source/images/pasted-26.png","hash":"efd5c95fe6e5a7eeb5f5957b6fa7f4f6de343e6f","modified":1715197678645},{"_id":"source/images/pasted-28.png","hash":"d3835a679e9fac342d5cf933bbece4cb67703011","modified":1715197678647},{"_id":"source/images/pasted-29.png","hash":"100c606466b307525106e6a4c64c4b422a8ac7b2","modified":1715197678647},{"_id":"source/images/pasted-33.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715197678654},{"_id":"source/images/pasted-35.png","hash":"eeca2dfb1180737cc2e92a0fb00d3ded3a365a25","modified":1715197678656},{"_id":"source/images/pasted-36.png","hash":"276441577a4a310c956e47245a530d6568c226d4","modified":1715197678656},{"_id":"source/images/pasted-37.png","hash":"5270f943b321d6970bed8b59c2e350ddb0538987","modified":1715197678656},{"_id":"source/images/pasted-39.png","hash":"8bd6bac07ffa78582f988b82967c84b8693aff83","modified":1715197678657},{"_id":"source/images/pasted-40.png","hash":"abc0661c843a0fc0a33eef18a6177f6ef1a11288","modified":1715197678658},{"_id":"source/images/pasted-42.png","hash":"76d2cafe4110693c64fe5bc433eee63132bf22c4","modified":1715197678659},{"_id":"source/images/pasted-43.png","hash":"7d6d385a94acc63b0e3f5c714853cd89d0745125","modified":1715197678660},{"_id":"source/images/pasted-45.png","hash":"abd869622f2f62f6baf3375467188224b0642d24","modified":1715197678661},{"_id":"source/images/pasted-46.png","hash":"5bb0646011c99f7ce5563dd9b617dce6775d33e5","modified":1715197678661},{"_id":"source/images/pasted-47.png","hash":"283d06284f966893464719dccb0068a62f33f736","modified":1715197678662},{"_id":"source/images/pasted-48.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715197678662},{"_id":"source/images/pasted-49.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715197678663},{"_id":"source/images/pasted-50.png","hash":"337b2c9b8aaf1b8caac23230cb46d38f31a54f64","modified":1715197678664},{"_id":"source/images/pasted-51.png","hash":"90d9d3e3e301b7da758f9e00b19aa497dea26d5d","modified":1715197678664},{"_id":"source/images/pasted-53.png","hash":"f8aee89da70a6e21e56daf1424ba89057c49805d","modified":1715197678666},{"_id":"source/images/pasted-54.png","hash":"66b02462ba6ffc37ce2b6ce3a9ecbcdcc08a06fe","modified":1715197678666},{"_id":"source/images/pasted-56.png","hash":"8086eba96cd26fadf46371986519b543c2d19bf1","modified":1715197678667},{"_id":"source/images/pasted-57.png","hash":"6b29df6415365f0abda6dac1a477a9f5b016629a","modified":1715197678668},{"_id":"source/images/pasted-6.png","hash":"51fd75a48cb09006767475956c8d822bebf9f705","modified":1715197678669},{"_id":"source/images/pasted-63.png","hash":"6ffb7887a7a7f405decf6b50e0e54dde6f2668a5","modified":1715197678671},{"_id":"source/images/pasted-65.png","hash":"42eccbee20c3f021a2a76a63e7fcba7e27fe155b","modified":1715197678673},{"_id":"source/images/pasted-66.png","hash":"ffd6971827ab02d85b550847968b0ffec3daa13f","modified":1715197678673},{"_id":"source/images/pasted-7.png","hash":"b73ff607d8ba6c4ccd64088f9b2fdda40fc98f35","modified":1715197678677},{"_id":"source/images/pasted-8.png","hash":"c2c4376eb1bc94d282caebe5234159e2c0180dfc","modified":1715197678677},{"_id":"source/images/pasted-9.png","hash":"32c8bf544f62ba0a59b3f14d271241530b8c95a2","modified":1715197678678},{"_id":"source/researcherpapers/rdma/rdma_components.png","hash":"782b39b00abe9d188a49cec84fcb58a6ef86f282","modified":1715197678679},{"_id":"source/uploads/wechat-qcode.jpg","hash":"c785f74f1b7778e8628e37f7d14fec37c411154e","modified":1715197678680},{"_id":"source/uploads/wechat-reward.jpg","hash":"0e0323d5a042387fe1cfab69aad5828ac0b68188","modified":1715197678681},{"_id":"source/images/pasted-10.png","hash":"2f8abe25445780f2dc0ca438eff2b90a1842fe8f","modified":1715197678631},{"_id":"source/images/pasted-16.png","hash":"f72fa6d08a10af16406df29abc35fd7c2fbe5a8a","modified":1715197678636},{"_id":"source/images/pasted-22.png","hash":"99092f7596b491c2ad65548cfba7d7236da983b0","modified":1715197678643},{"_id":"source/images/pasted-34.png","hash":"9569f2e0163d15d8d7315cf0cc78439ca8731d90","modified":1715197678655},{"_id":"source/images/pasted-38.png","hash":"350df6868afa9b38c4b31b41ca98f9d0cb5ebe22","modified":1715197678657},{"_id":"source/images/pasted-41.png","hash":"b11d22a1ac3f16efad7881fb4e6d5a070f14ff7d","modified":1715197678659},{"_id":"source/images/pasted-44.png","hash":"00f84a35d95a378425ed9c0b10d23cd14e98f735","modified":1715197678660},{"_id":"source/images/pasted-52.png","hash":"946e258ebfb73d4bce62de73940a1e0eba9272a5","modified":1715197678665},{"_id":"source/images/pasted-55.png","hash":"95fabb0e927b340993f9ce8be4f0432571c930bb","modified":1715197678667},{"_id":"source/images/pasted-58.png","hash":"838ae6abc5194b2fd9937c735bae29f46e5a9c87","modified":1715197678668},{"_id":"source/images/pasted-59.png","hash":"838ae6abc5194b2fd9937c735bae29f46e5a9c87","modified":1715197678669},{"_id":"source/images/pasted-60.png","hash":"e60b43d8f76b88818ae009e200f7b7d5ef24c7d1","modified":1715197678670},{"_id":"source/images/pasted-62.png","hash":"3c83c9be451346a6ecd0938af89ed1e05d55c1da","modified":1715197678671},{"_id":"source/images/pasted-64.png","hash":"80757a10240447f97d788630495a69f9c1e8f69a","modified":1715197678672},{"_id":"source/images/pasted-67.png","hash":"25f4b07a1e6adf4361cbb7d158169d80d05359e1","modified":1715197678674},{"_id":"source/images/pasted-11.png","hash":"635979cdc04325601667985fc5450722c1661f86","modified":1715197678631},{"_id":"source/images/pasted-27.png","hash":"b0f7b2e07b344dd8d0fe694c15f9dbb888636763","modified":1715197678646},{"_id":"source/images/pasted-4.png","hash":"145702a935771da5b1465512a69549f0e9eaa15e","modified":1715197678658},{"_id":"source/images/pasted-5.png","hash":"145702a935771da5b1465512a69549f0e9eaa15e","modified":1715197678663},{"_id":"source/images/pasted-61.png","hash":"924b207375bbdf56133ead33a1b899de298a31e5","modified":1715197678670},{"_id":"source/images/pasted-0.png","hash":"01634f69b71ed914d5d2aa271cd8321feb45e0bb","modified":1715197678629},{"_id":"source/images/pasted-19.png","hash":"54b7136c3cfa663d724092058a08f7518b2ef958","modified":1715197678639},{"_id":"source/images/pasted-20.png","hash":"c9a577b1c1704457fb0be745fa891925630abaad","modified":1715197678641},{"_id":"source/images/pasted-3.png","hash":"fa370da7a7b307773c03e3a14b5c694f52117550","modified":1715197678648},{"_id":"source/images/pasted-69.png","hash":"906c0974a8f4044870946aef0b23439fd11f9203","modified":1715197678676},{"_id":"source/images/pasted-31.png","hash":"db1e17649e6c338682fef9dc0b5742afcebd4cf4","modified":1715197678653},{"_id":"source/images/pasted-68.png","hash":"93389aa3c4196b983ef48a77b2e2dc8b60142b20","modified":1715197678675},{"_id":"source/images/pasted-32.png","hash":"84e5d86840d31fc2d9430a064c9ddbe609ff8cb3","modified":1715197678654},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1715197678748},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1715197678748},{"_id":"themes/next/.editorconfig","hash":"8570735a8d8d034a3a175afd1dd40b39140b3e6a","modified":1715197678682},{"_id":"source/images/pasted-30.png","hash":"c24e212b6281f24cb68963b87af9f319541a8df6","modified":1715197678650},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1715197678682},{"_id":"themes/next/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1715197678682},{"_id":"themes/next/.gitignore","hash":"c79d09b704c01e993542fdf74aa68f50f16c51ec","modified":1715197678682},{"_id":"themes/next/.stylintrc","hash":"2cf4d637b56d8eb423f59656a11f6403aa90f550","modified":1715197678683},{"_id":"themes/next/.travis.yml","hash":"ecca3b919a5b15886e3eca58aa84aafc395590da","modified":1715197678683},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1715197678683},{"_id":"themes/next/_config.yml","hash":"fe3ea22d71178f4be4503a27a6c038ffbb4a2e5d","modified":1715200103306},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1715197678684},{"_id":"themes/next/gulpfile.js","hash":"72e6d5a6e32d5f95d82e4c4d0c963d39555bb760","modified":1715197678691},{"_id":"themes/next/package.json","hash":"19dda7fab09594faba989669e29de88c4289877f","modified":1715197678723},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"5b4c013e0598b3211ebd899265936cfdaf7c139f","modified":1715197678685},{"_id":"themes/next/docs/AUTHORS.md","hash":"10135a2f78ac40e9f46b3add3e360c025400752f","modified":1715197678685},{"_id":"themes/next/docs/DATA-FILES.md","hash":"40a8089076005e0d26ef7c0db58a2b5b464cda6c","modified":1715197678685},{"_id":"themes/next/docs/INSTALLATION.md","hash":"af88bcce035780aaa061261ed9d0d6c697678618","modified":1715197678686},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"08cda41b4bcf687facfda19ab39718ec7a05ae54","modified":1715197678686},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1715197678686},{"_id":"themes/next/docs/MATH.md","hash":"f520b336f16665e164d6edf075bdcc6aa17b31bc","modified":1715197678687},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"682937d48bf5d243842a76190921322e26c75247","modified":1715197678687},{"_id":"themes/next/languages/de.yml","hash":"285b294b1dd2ce49b0694beb4fd75ed05dc20ccb","modified":1715197678692},{"_id":"themes/next/languages/default.yml","hash":"89eb0cff04435307e4eccb0d72a653499627d02d","modified":1715197678693},{"_id":"themes/next/languages/en.yml","hash":"89eb0cff04435307e4eccb0d72a653499627d02d","modified":1715197678693},{"_id":"themes/next/languages/es.yml","hash":"3bd0977225a9b9dc3cdc856161b3a77e5993ac4a","modified":1715197678694},{"_id":"themes/next/languages/fa.yml","hash":"35468531ad0236df5b188f28bd1b4bb0c0537faf","modified":1715197678694},{"_id":"themes/next/languages/fr.yml","hash":"5fe560d14824c71ea90b2a76d0c17b2332b9d08a","modified":1715197678694},{"_id":"themes/next/languages/hu.yml","hash":"dd9e4cd2873ed9a9ae7cb89962eeff911de396b4","modified":1715197678695},{"_id":"themes/next/languages/id.yml","hash":"80c3db4c2dbbea0703f6c8f1191218f692899507","modified":1715197678695},{"_id":"themes/next/languages/it.yml","hash":"68ac5a0aa361210f51915e101c842ed1c9464889","modified":1715197678695},{"_id":"themes/next/languages/ja.yml","hash":"e61529ddf80426a5362ed07642216027615bd740","modified":1715197678695},{"_id":"themes/next/languages/ko.yml","hash":"14a162509dc71bb364335c20281d3bccbd2a51f3","modified":1715197678696},{"_id":"themes/next/languages/nl.yml","hash":"4d9b09aff03648cbbbfeb0c51a2d1214320b5ec6","modified":1715197678696},{"_id":"themes/next/languages/pt-BR.yml","hash":"024dcdeb30c93e57cd1ba4cd707f8988dcad2468","modified":1715197678696},{"_id":"themes/next/languages/pt.yml","hash":"88fb58e537a949c013a2adcdaebcbe09543c0bd2","modified":1715197678696},{"_id":"themes/next/languages/ru.yml","hash":"f7d5efd6289845f2375bbee8fe883813de745767","modified":1715197678697},{"_id":"themes/next/languages/tr.yml","hash":"e08d8d6ee9507a7c7d4450bc1c76b435470a3739","modified":1715197678697},{"_id":"themes/next/languages/uk.yml","hash":"e58393cf726401bf50a772392e23507d9e11049e","modified":1715197678697},{"_id":"themes/next/languages/vi.yml","hash":"0c0890ccffcb5cca0893de63ebad66e3ce740707","modified":1715197678697},{"_id":"themes/next/languages/zh-CN.yml","hash":"4b36a51556e87d236c6ac6ee6975de1beb95724c","modified":1715197678698},{"_id":"themes/next/languages/zh-HK.yml","hash":"6d83daf9df1811e3ae6cde5ad778c888d8027b13","modified":1715197678698},{"_id":"themes/next/languages/zh-TW.yml","hash":"5e395cb492a0b6284f8d2ffdd93f7380db31486f","modified":1715197678700},{"_id":"themes/next/layout/_layout.swig","hash":"29ee038b0d5ffdb45327598733ea968588367769","modified":1715197678701},{"_id":"themes/next/layout/archive.swig","hash":"26526c09a4334099e2141456697696fcd1f9783f","modified":1715197678722},{"_id":"themes/next/layout/category.swig","hash":"c55debb2588e4746b02d31ec249bf0a84fdea260","modified":1715197678722},{"_id":"themes/next/layout/index.swig","hash":"3bc6fb1e9707d74b96e1346d3f03fe6584f764f4","modified":1715197678722},{"_id":"themes/next/layout/page.swig","hash":"e61d64c055b6497a04affc143f47fdd0a6dc495b","modified":1715197678723},{"_id":"themes/next/layout/post.swig","hash":"382d9f9a9b35e1f369585f7f9f9b5dd6fa58d2f0","modified":1715197678723},{"_id":"themes/next/layout/tag.swig","hash":"7ff6e34d557a3da1c6a29ecd97842bf73ff213dc","modified":1715197678723},{"_id":"themes/next/scripts/renderer.js","hash":"49a65df2028a1bc24814dc72fa50d52231ca4f05","modified":1715197678731},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"0bd2d696f62a997a11a7d84fec0130122234174e","modified":1715197678687},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"9c4fe2873123bf9ceacab5c50d17d8a0f1baef27","modified":1715197678687},{"_id":"themes/next/docs/ru/README.md","hash":"41b1bef32fb991410ebf559b4c45022549f95215","modified":1715197678688},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"fe3f5cda1975114884d84bef384a562920d70335","modified":1715197678688},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"4245fe9472647226692fcbdd5a52d6e6dcd251bc","modified":1715197678688},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"fb23b85db6f7d8279d73ae1f41631f92f64fc864","modified":1715197678689},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"17d7203e85a8ce9760c42a853dee0f26a8f7ee4e","modified":1715197678689},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"ca1030efdfca5e20f9db2e7a428998e66a24c0d0","modified":1715197678689},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"579c7bd8341873fb8be4732476d412814f1a3df7","modified":1715197678690},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"0b0b9ec6ec4a89e701a3b91f8d7d95752d3e241b","modified":1715197678690},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"f0ffb74de522749c9f2fda46970a61bdafbfbc24","modified":1715197678690},{"_id":"themes/next/docs/zh-CN/README.md","hash":"b6a3611d40863c12804c5846994786119ce3b79f","modified":1715197678691},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"7f37327bbcae7ed7d04d187fd5e9bc6bbf14926a","modified":1715197678691},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"815676d904f92748ddf4f529bed2baf066997bc6","modified":1715197678701},{"_id":"themes/next/layout/_macro/post.swig","hash":"049caf88e2cb8dde780b0c6196db984c7bc3a4cc","modified":1715197678702},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"e2c9db54cc9e154e882008fde6588b065fadc9a7","modified":1715197678702},{"_id":"themes/next/layout/_partials/comments.swig","hash":"0c4914a5fd08f15beec71940218c814ad9a89f3f","modified":1715197678702},{"_id":"themes/next/layout/_partials/footer.swig","hash":"1ee6335c12773dc43f8b92136770cb10d460c25c","modified":1715197678703},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9876dbfc15713c7a47d4bcaa301f4757bd978269","modified":1715197678706},{"_id":"themes/next/layout/_partials/widgets.swig","hash":"83a40ce83dfd5cada417444fb2d6f5470aae6bb0","modified":1715197678709},{"_id":"themes/next/layout/_scripts/index.swig","hash":"cea942b450bcb0f352da78d76dc6d6f1d23d5029","modified":1715197678709},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"d1f2bfde6f1da51a2b35a7ab9e7e8eb6eefd1c6b","modified":1715197678709},{"_id":"themes/next/layout/_scripts/pjax.swig","hash":"9675acc599ffa546f05a60375c1637b0327be4fd","modified":1715197678710},{"_id":"themes/next/layout/_scripts/three.swig","hash":"a4f42f2301866bd25a784a2281069d8b66836d0b","modified":1715197678711},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"ef38c213679e7b6d2a4116f56c9e55d678446069","modified":1715197678711},{"_id":"themes/next/layout/_third-party/baidu-push.swig","hash":"8627c8c8b031ecee16c522433b66fa4d6979b8ea","modified":1715197678715},{"_id":"themes/next/layout/_third-party/index.swig","hash":"70c3c01dd181de81270c57f3d99b6d8f4c723404","modified":1715197678718},{"_id":"themes/next/layout/_third-party/quicklink.swig","hash":"dd6bd817cb69b5ad5e9746498146314b54054ff8","modified":1715197678719},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"da6a9d14ed10203e378c6e2c00a7b5e7afabca58","modified":1715197678719},{"_id":"themes/next/scripts/events/index.js","hash":"9047d8ae2670e43429b16a7919a08a0a0a81afe0","modified":1715197678724},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"aec50ed57b9d5d3faf2db3c88374f107203617e0","modified":1715197678729},{"_id":"themes/next/scripts/filters/front-matter.js","hash":"703bdd142a671b4b67d3d9dfb4a19d1dd7e7e8f7","modified":1715197678729},{"_id":"themes/next/scripts/filters/locals.js","hash":"5bbfdc1c373542159660b7a68ed0b57ca18ad10b","modified":1715197678730},{"_id":"themes/next/scripts/filters/minify.js","hash":"19985723b9f677ff775f3b17dcebf314819a76ac","modified":1715197678730},{"_id":"themes/next/scripts/filters/post.js","hash":"5e5035372b3d94a65309334c93303c858e072012","modified":1715197678730},{"_id":"themes/next/scripts/helpers/engine.js","hash":"cb211b6b50913454b1737782e9e2af96cfa40448","modified":1715197678730},{"_id":"themes/next/scripts/helpers/font.js","hash":"32268fb4c59c5b37c1eb1c9582ab630e09e5cc7d","modified":1715197678731},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"58347687b02f7ab5e64bef07525c8efa97c9e8fb","modified":1715197678731},{"_id":"themes/next/scripts/tags/button.js","hash":"1d1d25f7e579d92fa563778dd0f163e8eda190da","modified":1715197678731},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"20e392b8583ba6ae5037449c2c7e191d3927641b","modified":1715197678732},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f13430d9d1c9773b390787c2f046bb1f12a79878","modified":1715197678732},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"d902fd313e8d35c3cc36f237607c2a0536c9edf1","modified":1715197678732},{"_id":"themes/next/scripts/tags/label.js","hash":"fc5b267d903facb7a35001792db28b801cccb1f8","modified":1715197678732},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"983c6c4adea86160ecc0ba2204bc312aa338121d","modified":1715197678732},{"_id":"themes/next/scripts/tags/note.js","hash":"0a02bb4c15aec41f6d5f1271cdb5c65889e265d9","modified":1715197678733},{"_id":"themes/next/scripts/tags/pdf.js","hash":"f780cc72bff91d2720626e7af69eed25e9c12a29","modified":1715197678733},{"_id":"themes/next/scripts/tags/tabs.js","hash":"00ca6340d4fe0ccdae7525373e4729117775bbfa","modified":1715197678733},{"_id":"themes/next/scripts/tags/video.js","hash":"e5ff4c44faee604dd3ea9db6b222828c4750c227","modified":1715197678733},{"_id":"themes/next/source/css/main.styl","hash":"68c3377b643162aeaae2b60c196486fdb3b509c3","modified":1715197678754},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1715197678754},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1715197678755},{"_id":"themes/next/source/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1715197678755},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1715197678755},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1715197678756},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1715197678756},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1715197678756},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1715197678756},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1715197678757},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1715197678757},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1715197678757},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1715197678757},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1715197678757},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1715197678758},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1715197678758},{"_id":"themes/next/source/js/algolia-search.js","hash":"813afcc30feee11d59f297f2d5a96f98fbbd4743","modified":1715197678758},{"_id":"themes/next/source/js/bookmark.js","hash":"a00945ff886e9f6f835731cdaf29a3a3727c8877","modified":1715197678758},{"_id":"themes/next/source/js/local-search.js","hash":"9f3d3ddff86e7b2828772aba915a5ebfd7d9f55f","modified":1715197678759},{"_id":"themes/next/source/js/motion.js","hash":"09f8be6bcc6920546bb06e3f8c0181ec62c70b90","modified":1715197678759},{"_id":"themes/next/source/js/next-boot.js","hash":"f7045763e277e685c271bd4b4c37e531d699ac63","modified":1715197678759},{"_id":"themes/next/source/js/utils.js","hash":"41fa3f7cc18e028263b6fa524a3a95fc93b1b81e","modified":1715197678760},{"_id":"themes/next/source/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1715197678760},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"1638483d2d2dad1da4c841a6fb9f6ee96b850187","modified":1715197678703},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"0172055d118d1d7f4c8379c8495c1ee1aa50c7d9","modified":1715197678703},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"7487ca8f0e4b16351ea0d6b35dc52b0d32176d57","modified":1715197678704},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"30528a8da30994b1ef9355a72b09b2cd85a7c0e9","modified":1715197678704},{"_id":"themes/next/layout/_partials/header/menu-item.swig","hash":"e6076865dba066c5f0008e22217efb850d5af69c","modified":1715197678704},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"bbf0c8e42491fac70f4f8165224f1d7d92a040d7","modified":1715197678705},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"54ba9508a901c295a02c8e34e9cece7c7dcad518","modified":1715197678705},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"c851717497ca64789f2176c9ecd1dedab237b752","modified":1715197678705},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"a56e4f6ad95c106f361d354f828d1ef4810b1d76","modified":1715197678706},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"94d54b0c65d504f772af1e62424952e092b6c21d","modified":1715197678706},{"_id":"themes/next/layout/_partials/post/post-footer.swig","hash":"8f14f3f8a1b2998d5114cc56b680fb5c419a6b07","modified":1715197678707},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"f79c44692451db26efce704813f7a8872b7e63a0","modified":1715197678707},{"_id":"themes/next/layout/_partials/post/post-reward.swig","hash":"78cb2077f50bc3b81130a516ffc04bc1fcea5834","modified":1715197678707},{"_id":"themes/next/layout/_partials/search/algolia-search.swig","hash":"7fa01334a0ba84500e920bb9202baa08067d2ee1","modified":1715197678707},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"d6fa9e4432b87004c5678dfe2d4b2c1f4a702b93","modified":1715197678708},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"733d6874aa4f50d1071e670a554508a5a0094eb3","modified":1715197678708},{"_id":"themes/next/layout/_partials/sidebar/site-overview.swig","hash":"716b78cd90addc4216413719554721cb362b0c18","modified":1715197678708},{"_id":"themes/next/layout/_scripts/pages/schedule.swig","hash":"a2bb0bec243685e670b60a3d54142950adc03af0","modified":1715197678710},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1715197678710},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1715197678710},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"7f14ef43d9e82bc1efc204c5adf0b1dbfc919a9f","modified":1715197678711},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"1c910fc066c06d5fbbe9f2b0c47447539e029af7","modified":1715197678711},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"4790058691b7d36cf6d2d6b4e93795a7b8d608ad","modified":1715197678712},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"2fa2b51d56bfac6a1ea76d651c93b9c20b01c09b","modified":1715197678712},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"5adea065641e8c55994dd2328ddae53215604928","modified":1715197678712},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"1472cabb0181f60a6a0b7fec8899a4d03dfb2040","modified":1715197678713},{"_id":"themes/next/layout/_third-party/chat/chatra.swig","hash":"fdcf006e1ba2e53eab65e901b6c63159538307ef","modified":1715197678715},{"_id":"themes/next/layout/_third-party/chat/tidio.swig","hash":"cba0e6e0fad08568a9e74ba9a5bee5341cfc04c1","modified":1715197678716},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"f39a5bf3ce9ee9adad282501235e0c588e4356ec","modified":1715197678716},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"1ef172bc041d6f6b6c8c642ea64496a188d79029","modified":1715197678717},{"_id":"themes/next/layout/_third-party/comments/disqusjs.swig","hash":"d3dc3e051e6816cdd576d00cc70b18b8a4c6a495","modified":1715197678717},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"ed236103bccbcf608f7d5d5b33b9f995d2f1a7de","modified":1715197678717},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"f7a9eca599a682479e8ca863db59be7c9c7508c8","modified":1715197678717},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4d6f9e09ca4056ff6a5d4923e202126a75242183","modified":1715197678718},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"6c5976621efd5db5f7c4c6b4f11bc79d6554885f","modified":1715197678718},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"4791c977a730f29c846efcf6c9c15131b9400ead","modified":1715197678718},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"fb27a38f9a4b8fcba4f637b03904f7a83cc73416","modified":1715197678719},{"_id":"themes/next/layout/_third-party/search/algolia-search.swig","hash":"e456d7a2aaabe55447f78cd952b30d70a6c1e742","modified":1715197678719},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"767b6c714c22588bcd26ba70b0fc19b6810cbacd","modified":1715197678720},{"_id":"themes/next/layout/_third-party/search/swiftype.swig","hash":"ba0dbc06b9d244073a1c681ff7a722dcbf920b51","modified":1715197678720},{"_id":"themes/next/layout/_third-party/statistics/cnzz-analytics.swig","hash":"a17ace37876822327a2f9306a472974442c9005d","modified":1715197678721},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.swig","hash":"d7258d02bcf0dac6c0fd8377c0909ddecb09d1d4","modified":1715197678720},{"_id":"themes/next/layout/_third-party/statistics/firestore.swig","hash":"0ea0bac09b0747bc16fde852164c0eaab2efe02c","modified":1715197678721},{"_id":"themes/next/layout/_third-party/statistics/index.swig","hash":"5f6a966c509680dbfa70433f9d658cee59c304d7","modified":1715197678721},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.swig","hash":"801e1d2f59f7d2db4096c4788b8469b4165f4965","modified":1715197678721},{"_id":"themes/next/layout/_third-party/tags/mermaid.swig","hash":"4958fa997ff6df2b2ce05341f40cc3a81b0f91bb","modified":1715197678722},{"_id":"themes/next/layout/_third-party/tags/pdf.swig","hash":"7fa72dc60c078842979861622839b109683e05a3","modified":1715197678722},{"_id":"themes/next/scripts/events/lib/config.js","hash":"b205d72a56b1827681f0a260c266e0c02065fd08","modified":1715197678724},{"_id":"themes/next/scripts/events/lib/injects-point.js","hash":"6661c1c91c7cbdefc6a5e6a034b443b8811235a1","modified":1715197678724},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"f233d8d0103ae7f9b861344aa65c1a3c1de8a845","modified":1715197678725},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"1f20213af8da3127701e6bb9da995e5c91be2051","modified":1715197678727},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"0803d4f4d3d02c24417c163ad0b27b60fda79250","modified":1715197678728},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"7f2d93af012c1e14b8596fecbfc7febb43d9b7f5","modified":1715197678728},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"5ba0480c2dbb0626501c90c920be85ce2308103c","modified":1715197678728},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"7f8b92913d21070b489457fa5ed996d2a55f2c32","modified":1715197678728},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"e51dc3072c1ba0ea3008f09ecae8b46242ec6021","modified":1715197678729},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"d5fefc31fba4ab0188305b1af1feb61da49fdeb0","modified":1715197678729},{"_id":"themes/next/scripts/filters/comment/valine.js","hash":"e24c4dd78f6e4adee0e7c15eb8bca12eb92452e4","modified":1715197678729},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2315dd8a7a2c7aabd29efa6193df08e805cb15fc","modified":1715197678747},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"644c1f0b02be9bf59955ebdf496136b3fa4b660b","modified":1715197678748},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0a25f3df1b5c39794365efde387647da81da884a","modified":1715197678748},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"52550138127ae9ebbe049bcdacd94d767c003855","modified":1715197678753},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"b9d7058db61df7bbd2b58779efe45621a06ffc18","modified":1715197678753},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"c261d685c5ed0df34718d94bb2ba977c0ed443e6","modified":1715197678753},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"50bc57e66331c0f15a4527010b4ca3316ac92403","modified":1715197678754},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d4e817e2b238ace5d7ac568ce0c5380196a6d039","modified":1715197678754},{"_id":"themes/next/source/js/schemes/muse.js","hash":"792f4522a3b0b96584a041a4aca20fcded410079","modified":1715197678759},{"_id":"themes/next/source/js/schemes/pisces.js","hash":"52d139e6f3bc212c8c9b71bc9e57e931920434a6","modified":1715197678760},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1715197678761},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1715197678761},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1715197678761},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1715197678761},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1715197678762},{"_id":"themes/next/source/lib/three/.gitignore","hash":"e691fe9e685cbd50bcd7e138f4ca3503e7b0eaa4","modified":1715197678765},{"_id":"themes/next/source/lib/three/LICENSE","hash":"b29db4c99aa5b8d574026f68804051ff4b75466e","modified":1715197678766},{"_id":"themes/next/source/lib/three/README.md","hash":"1e31051ce404eaa86df192b7000442bacd31e2b4","modified":1715197678766},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"ae6584edc0418d68731cab82c1494f26bd77c07d","modified":1715197678766},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"186c3bd6ae352d336cdbd0e555ee76a844854c94","modified":1715197678766},{"_id":"themes/next/source/lib/three/gulpfile.js","hash":"e0e9e7051d9d82a37c2aba1df396d8b3916323c4","modified":1715197678767},{"_id":"themes/next/source/lib/three/package.json","hash":"af5089f910e1041b316def5512a23443f0ffaadc","modified":1715197678768},{"_id":"themes/next/source/lib/three/renovate.json","hash":"cb29cc16e61b0b8a6dac34657d76822ae29ad5aa","modified":1715197678768},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"329483be97cdda030779da9a6cd1e3eae645cf4f","modified":1715197678769},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1715197678772},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1715197678772},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"80d359661d08b80ad561b97f8508766b3e1f6d01","modified":1715197678734},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"47ee915d7b0a97e74140a25fbfc01c04d6781534","modified":1715197678734},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"112f5e8f1fe5cec4419e87acfbdef0e615ed23f3","modified":1715197678735},{"_id":"themes/next/source/css/_common/components/rainbow.styl","hash":"41c7cd1b63d49476ed5fbdd26ab9411d8f44bd05","modified":1715197678739},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"170c4598cbbe49cd1527f94158d97d2320a6b906","modified":1715197678739},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"990bd301ce2de0a6b936781c58318f3945d81bc2","modified":1715197678742},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"44fe82eadbdbb2f66adda37ac83ebd0f85876bfc","modified":1715197678742},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"4f7879a50d4608c46cc2061c725a2564597a45bd","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"d8ba44b8e1a0332c5c1079ff65fc83d2918a5865","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"3faa8a7cdb05ef3f3b02920d381773dfd54270a5","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"b56367ea676ea8e8783ea89cd4ab150c7da7a060","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"8f58570a1bbc34c4989a47a1b7d42a8030f38b06","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"523fb7b653b87ae37fc91fc8813e4ffad87b0d7e","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"2b52b0eb4c66e06762cf115450da0ca1dd435e75","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"179e33b8ac7f4d8a8e76736a7e4f965fe9ab8b42","modified":1715197678747},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"1693ec6b53758ac15d2c7798c789d6ae8af913ea","modified":1715197678749},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"4fb385d8533877678440c8faa08b68fa793cb1a2","modified":1715197678749},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"24a086a6904bbf5355a354403c9b0e6069f7eb01","modified":1715197678749},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"48743ac61af37a4de2026667e15a65de5e8cf542","modified":1715197678749},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"e321bd62f5e04d1fdc101a470ec13604e99816a5","modified":1715197678750},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"a717969829fa6ef88225095737df3f8ee86c286b","modified":1715197678750},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"3646e915b0a55f3b66e41d802b082aba88a76e06","modified":1715197678750},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"4d1c17345d2d39ef7698f7acf82dfc0f59308c34","modified":1715197678750},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"c6905c694c6fbbf372b53456a0d219701010a110","modified":1715197678751},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"eeab294e14abbae231107e1a327e907b25323136","modified":1715197678751},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"c48ccd8d6651fe1a01faff8f01179456d39ba9b1","modified":1715197678751},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1715197678751},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"f1f81bca31e82ccbd375f0cb9fb8dbb3beac810d","modified":1715197678752},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"f5abb2ea7746586738fb4e82107fceed041708ee","modified":1715197678752},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"71a3d7f2242706f7a6b79933a67ef3664cca3a24","modified":1715197678752},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d7587df06b30042091316d8b1cc58ba361211492","modified":1715197678752},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"0424a1fcffa1ae82fe70935972a894aca885bf9a","modified":1715197678752},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"6ad168288b213cec357e9b5a97674ff2ef3a910c","modified":1715197678753},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1715197678762},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1715197678762},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1715197678763},{"_id":"themes/next/source/lib/three/lib/CanvasRenderer.js","hash":"cf8e1ce6e884023ad0d692cf30f399862407fb40","modified":1715197678767},{"_id":"themes/next/source/lib/three/lib/Projector.js","hash":"1ad16e96cea2a8a9155bb429c83ef9bdd341ce99","modified":1715197678767},{"_id":"themes/next/source/lib/three/src/canvas_lines.js","hash":"650310ff6783671f8ceccf01f840b20d9c87b491","modified":1715197678768},{"_id":"themes/next/source/lib/three/src/canvas_sphere.js","hash":"7614790c67d3e79e3390fe688f6b01afad7e3bb1","modified":1715197678768},{"_id":"themes/next/source/lib/three/src/three-waves.js","hash":"e98e442f14920e9fb8691846dca3a2225d403048","modified":1715197678769},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fafc96c86926b22afba8bb9418c05e6afbc05a57","modified":1715197678735},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"2bd0eb1512415325653b26d62a4463e6de83c5ac","modified":1715197678735},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"7504dbc5c70262b048143b2c37d2b5aa2809afa2","modified":1715197678735},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"6336c2b129db802221b1fd75e5fbe8aab85c0a1f","modified":1715197678736},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"7ddb7453bf9b85b01bff136e9d10a7f06baac9e8","modified":1715197678736},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"98227b4de364b48b11e21efcf4f1beb2ed3ab329","modified":1715197678736},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"4b84f35e7040f9adb5cc540c366d7f9eb4c48bcc","modified":1715197678737},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"e3ade812b5541eca5b863ad3ff234ea95925bf31","modified":1715197678737},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"5d5c022aa3b2f89c2f2a178212338bb64804dd75","modified":1715197678737},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"72d495a88f7d6515af425c12cbc67308a57d88ea","modified":1715197678737},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"bcba503e956e4b737b062faa66341bd880f16c10","modified":1715197678737},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"9df5ba77e6cf36129bddc270407215c23c60ff38","modified":1715197678738},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"eca4d80dd0df1c3b1bc06bd39e6a4bd6c56198df","modified":1715197678738},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"f5c2788a78790aca1a2f37f7149d6058afb539e0","modified":1715197678738},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"99e12c9ce3d14d4837e3d3f12fc867ba9c565317","modified":1715197678738},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"5b5649b9749e3fd8b63aef22ceeece0a6e1df605","modified":1715197678738},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"284249dcfa3b49c5d76210bbb0f74f65fc2f12ea","modified":1715197678739},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"8a7fc03a568b95be8d3337195e38bc7ec5ba2b23","modified":1715197678739},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"ef66c0a08e4243a25e41408d70ca66682b8dcea1","modified":1715197678740},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"e2992846b39bf3857b5104675af02ba73e72eed5","modified":1715197678740},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"2d9d68a431a334626d463bb1bdfbcd2ea8242e94","modified":1715197678740},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9a878d0119785a2316f42aebcceaa05a120b9a7a","modified":1715197678740},{"_id":"themes/next/source/css/_common/outline/footer/footer.styl","hash":"f5821481440a0624c8aec5fc85f093de1527095f","modified":1715197678741},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"e02b1097a72a7d2ddc45ea8d53aa6d77c25ac407","modified":1715197678741},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"0672ea2acf28dcc2cfc5244da36d3387d71a17cb","modified":1715197678741},{"_id":"themes/next/source/css/_common/outline/header/header.styl","hash":"4b237e2344f35e9d1f6dbc3842d5e432d478ebfd","modified":1715197678741},{"_id":"themes/next/source/css/_common/outline/header/headerband.styl","hash":"0caf32492692ba8e854da43697a2ec8a41612194","modified":1715197678741},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"d5d85d3646d184e0340924addcfd2523fb289d00","modified":1715197678742},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"a7ed54e2f52185a7b6bb9a8201f6c3aa74b0cb00","modified":1715197678742},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"c27b3056d5e22d3c66d8a152a23634314d5c4a60","modified":1715197678742},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"2cb1876e9e0c9ac32160888af27b1178dbcb0616","modified":1715197678742},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"9b3ff4aa24069eab0e9771437013f45e450d4217","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"95339b71ac90553fb1634c536c9749055e0c788a","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"a237c290e8934d1a8cbbf22b3f30503d9663021d","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-dimmer.styl","hash":"9b479c2f9a9bfed77885e5093b8245cc5d768ec7","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"1db4ce981fe9fcb9ee4279395c29553efbb43947","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"e2ad7ccf1865a45548e3f31c70fac2c65d6ef534","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"b3220db827e1adbca7880c2bb23e78fa7cbe95cb","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar.styl","hash":"c83d750238d6ac13b65869a909465fe621c464c3","modified":1715197678743},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"9a18b186b08ec220d1b17cf83812bcdd06077814","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"b492a45422773ab2af06ee345d527ba4c6bbc608","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/highlight/diff.styl","hash":"d3f73688bb7423e3ab0de1efdf6db46db5e34f80","modified":1715197678744},{"_id":"themes/next/source/css/_common/scaffolding/highlight/highlight.styl","hash":"b4923515ca8e44aa62e839ce948f759cfd1f896f","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/highlight/theme.styl","hash":"3b3acc5caa0b95a2598bef4eeacb21bab21bea56","modified":1715197678745},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"709d10f763e357e1472d6471f8be384ec9e2d983","modified":1715197678746},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"7213e3d0ad7c95717ecd4e701d6ee9248ef2bf9f","modified":1715197678746},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"5bf28a03ef021c27cfd713971caca5a0b9466fd1","modified":1715197678746},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"1a14c1b92d8a4dd8aabb5949333ac0ac79094c6c","modified":1715197678746},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"2dc2a5b7becb11de1d4bdab6b5195588ae878cfc","modified":1715197678747},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"d2f0f2171722533bba308f944a2ec727b083582c","modified":1715197678747},{"_id":"themes/next/source/css/_common/scaffolding/tags/tags.styl","hash":"9e4c0653cfd3cc6908fa0d97581bcf80861fb1e7","modified":1715197678747},{"_id":"source/images/pasted-15.png","hash":"3bfe945e2c742897c6ffb70638c69112e2e8183e","modified":1715197678635},{"_id":"themes/next/README.md","hash":"dc026053a4d9fb97a58dbc3e9060e480f6852b23","modified":1715197678683},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1715197678685},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1715197678765},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1715197678765},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1715197678764},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1715197678771},{"_id":"public/search.xml","hash":"adb020ee8e8ca0b88010e94e90f540f66488631e","modified":1715200164652},{"_id":"public/404.html","hash":"68824a5663f5769bfc07f86c9bb96738ee7a4c6b","modified":1715200118236},{"_id":"public/about/index.html","hash":"f44c89dcadb98b2f6b9357b4bfbd83b7185237ec","modified":1715200118236},{"_id":"public/categories/index.html","hash":"e252993ebe3e68931c778798b16182a34561dae7","modified":1715200118236},{"_id":"public/tags/index.html","hash":"a5eacc5cee5fecee190b363b5c0504cf1d6e07d2","modified":1715200118236},{"_id":"public/archives/page/2/index.html","hash":"a3a25b7fb6ceb5696f01a82c2c3688675c872e62","modified":1715200118236},{"_id":"public/archives/2017/index.html","hash":"7117d2933871998e4426679910e22bbd19aed3b4","modified":1715200118236},{"_id":"public/archives/2017/04/index.html","hash":"dc02c4c95d8ddf7cc43fad8dc8db737d9868e0f5","modified":1715200118236},{"_id":"public/archives/2018/page/2/index.html","hash":"9b3b851e220183c074c767177a4dc5d32e0d3ba3","modified":1715200118236},{"_id":"public/archives/2018/05/page/2/index.html","hash":"549277d962636322af672e10c7ab4bae825a137c","modified":1715200118236},{"_id":"public/archives/2018/06/index.html","hash":"7970726b55bee2cc28e182f57e4d6d2872d3f55d","modified":1715200118236},{"_id":"public/categories/研究生论文研读/index.html","hash":"cefb3193d354120d5928d235ab20bd4d39158172","modified":1715200118236},{"_id":"public/categories/Linux/index.html","hash":"085d6f8418c8e0ebcb832938dcd30d0309d5980f","modified":1715200118236},{"_id":"public/categories/计算机硬件/index.html","hash":"f58388b9b3a513cd78631db9724a1c605c7a6515","modified":1715200118236},{"_id":"public/categories/研究生论文研读/RDMA论文研读/index.html","hash":"fd9bd30daf6073f5520452d85e90d106b5a5013b","modified":1715200118236},{"_id":"public/categories/RDMA技术/index.html","hash":"58f62dc2320c571945a484c2553f08b334ff0ec9","modified":1715200118236},{"_id":"public/tags/图计算/index.html","hash":"f0bab616763c1e8a865e38409f5810f11cf0e592","modified":1715200118236},{"_id":"public/tags/RDMA/index.html","hash":"2ab1ed132a4077ec0982473d478ed799346d0b3e","modified":1715200118236},{"_id":"public/tags/linux/index.html","hash":"5c5384dfb1f6fdf4c5d57d4e82fc1d41a4e5ee20","modified":1715200118236},{"_id":"public/tags/计算机硬件/index.html","hash":"2ffed6b743d0278574b63e330253b8d2d6755955","modified":1715200118236},{"_id":"public/tags/实时流处理/index.html","hash":"2dec2eac949a6537782c89427098b816672e8676","modified":1715200118236},{"_id":"public/2018/06/04/深入浅出全面解析RDMA/index.html","hash":"17da7fb411e0df868f2d0d6464e563617418977d","modified":1715200118236},{"_id":"public/2018/05/29/虚拟内存/index.html","hash":"4fccbf14392ca5e5d04943fca3b2a2e1bdc454cc","modified":1715200118236},{"_id":"public/2018/05/29/Apache-Flink-官方文档翻译之编程模型/index.html","hash":"05655d28a4f3857a291ec0145a8af7f7655b2796","modified":1715200118236},{"_id":"public/2018/05/29/Apache-Flink-官方文档翻译之-容错机制/index.html","hash":"39064c40e14f6a3f531be7d5532d5662c89ecdce","modified":1715200118236},{"_id":"public/2018/05/25/Untitled/index.html","hash":"bff31ce78064e0c845eecef80e345cd4a8653c7a","modified":1715200118236},{"_id":"public/2018/05/25/2014-OSDI-GraphX-Graph-Processing-in-a-Distributed-Dataflow-Framework/index.html","hash":"2eacdd1cedf1c9fec0601cb2f9d44bb7a34e01f1","modified":1715200118236},{"_id":"public/2018/05/25/TUX2-Distributed-Graph-Computation-for-Machine-Learning/index.html","hash":"c1afedf150eb7a881f4163ba6985b270509e9302","modified":1715200118236},{"_id":"public/2018/05/25/Sub-millisecond-Stateful-Stream-Querying-over-Fast-evolving-Linked-Data/index.html","hash":"6953f1dedc03cfc10e00fb83921b8c466b48cf2f","modified":1715200118236},{"_id":"public/2018/05/25/Bipartite-graph-二分图/index.html","hash":"c6020657fa803f6800bc64e61a0ef2557e220711","modified":1715200118236},{"_id":"public/2018/05/25/RDMA技术详解/index.html","hash":"90cb2955e419207bb5fb528b7b15026523311ebf","modified":1715200118236},{"_id":"public/2018/05/25/内存映射IO-MMIO/index.html","hash":"f5bc173e40a115c8532dd9fc8e8da55b96a5d7be","modified":1715200118236},{"_id":"public/2018/05/23/PCIE和PCI-计算机总线/index.html","hash":"0bcc66b01e31203830ba919589f3cbc8c05d5dc0","modified":1715200118236},{"_id":"public/2018/05/23/Design-Guidelines-for-High-Performance-RDMA-Systems/index.html","hash":"7b28eee4f674811fbde7cc90f5b278a25c0de9ab","modified":1715200118236},{"_id":"public/2017/04/25/Linux服务管理/index.html","hash":"e3315d813199da1e53b74b74be16754ca4bb1d1e","modified":1715200118236},{"_id":"public/archives/index.html","hash":"1feabc47f58ec8397cc6852d5850ee3c1062752e","modified":1715200118236},{"_id":"public/archives/2018/index.html","hash":"8a9488a32fe5a56c6e33aac75e4db958cd11e52b","modified":1715200118236},{"_id":"public/archives/2018/05/index.html","hash":"f80bb797de8b2bad67057609448ac622f451643f","modified":1715200118236},{"_id":"public/page/2/index.html","hash":"33283bcfe4e48a1cb5a66f8dd0244ee177f9242a","modified":1715200118236},{"_id":"public/index.html","hash":"48d5e351525e3d617f450461993a4ef9721d02cc","modified":1715200118236},{"_id":"public/favicon.ico","hash":"1cdb7ff6cca73ee968a0e42077deda272364872c","modified":1715198391573},{"_id":"public/about/index.md.bak","hash":"172143edbd77ce53994687436731a5ca34946962","modified":1715198391573},{"_id":"public/uploads/alipay-reward.jpg","hash":"c1e1b800343030c2a0cdf2f3368622435c692153","modified":1715198391573},{"_id":"public/images/pasted-1.png","hash":"f8661ab78160bf2bed84c0ebce858941ca7eda97","modified":1715198391573},{"_id":"public/images/pasted-13.png","hash":"b5bb48aebbf1249d718ad9c7edec2b939db38129","modified":1715198391573},{"_id":"public/images/pasted-12.png","hash":"7c62171444c797b96beb89cba10021e8cab9ad2c","modified":1715198391573},{"_id":"public/images/pasted-14.png","hash":"e3bddb2efac610df92827ea54765b03659d57e85","modified":1715198391573},{"_id":"public/images/pasted-17.png","hash":"03239d856a0ee58c78c9b6b582023dd2cc0d7c36","modified":1715198391573},{"_id":"public/images/pasted-18.png","hash":"0f9461af0fd8d822099ec8da73cf9a1ff192f837","modified":1715198391573},{"_id":"public/images/pasted-2.png","hash":"dab264dc9cbf978be9e8df18213585b2cfccdb41","modified":1715198391573},{"_id":"public/images/pasted-23.png","hash":"240285a9754e5095726d44d9cd28c18344a9728b","modified":1715198391573},{"_id":"public/images/pasted-24.png","hash":"41b6c59420554d9ef0fd22e0ac60af432d1cd4b6","modified":1715198391573},{"_id":"public/images/pasted-28.png","hash":"d3835a679e9fac342d5cf933bbece4cb67703011","modified":1715198391573},{"_id":"public/images/pasted-21.png","hash":"c005097d80fb0a5680db1fd57857b4d3c16f1aec","modified":1715198391573},{"_id":"public/images/pasted-26.png","hash":"efd5c95fe6e5a7eeb5f5957b6fa7f4f6de343e6f","modified":1715198391573},{"_id":"public/images/pasted-25.png","hash":"235418b6ae3c4b9bbbd8e439a32ba29a770afe52","modified":1715198391573},{"_id":"public/images/pasted-29.png","hash":"100c606466b307525106e6a4c64c4b422a8ac7b2","modified":1715198391573},{"_id":"public/images/pasted-33.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715198391573},{"_id":"public/images/pasted-36.png","hash":"276441577a4a310c956e47245a530d6568c226d4","modified":1715198391573},{"_id":"public/images/pasted-37.png","hash":"5270f943b321d6970bed8b59c2e350ddb0538987","modified":1715198391573},{"_id":"public/images/pasted-39.png","hash":"8bd6bac07ffa78582f988b82967c84b8693aff83","modified":1715198391573},{"_id":"public/images/pasted-35.png","hash":"eeca2dfb1180737cc2e92a0fb00d3ded3a365a25","modified":1715198391573},{"_id":"public/images/pasted-40.png","hash":"abc0661c843a0fc0a33eef18a6177f6ef1a11288","modified":1715198391573},{"_id":"public/images/pasted-42.png","hash":"76d2cafe4110693c64fe5bc433eee63132bf22c4","modified":1715198391573},{"_id":"public/images/pasted-43.png","hash":"7d6d385a94acc63b0e3f5c714853cd89d0745125","modified":1715198391573},{"_id":"public/images/pasted-46.png","hash":"5bb0646011c99f7ce5563dd9b617dce6775d33e5","modified":1715198391573},{"_id":"public/images/pasted-48.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715198391573},{"_id":"public/images/pasted-45.png","hash":"abd869622f2f62f6baf3375467188224b0642d24","modified":1715198391573},{"_id":"public/images/pasted-47.png","hash":"283d06284f966893464719dccb0068a62f33f736","modified":1715198391573},{"_id":"public/images/pasted-50.png","hash":"337b2c9b8aaf1b8caac23230cb46d38f31a54f64","modified":1715198391573},{"_id":"public/images/pasted-49.png","hash":"b37e96844329b0a67cc6a693a54634f380aa9751","modified":1715198391573},{"_id":"public/images/pasted-56.png","hash":"8086eba96cd26fadf46371986519b543c2d19bf1","modified":1715198391573},{"_id":"public/images/pasted-53.png","hash":"f8aee89da70a6e21e56daf1424ba89057c49805d","modified":1715198391573},{"_id":"public/images/pasted-6.png","hash":"51fd75a48cb09006767475956c8d822bebf9f705","modified":1715198391573},{"_id":"public/images/pasted-57.png","hash":"6b29df6415365f0abda6dac1a477a9f5b016629a","modified":1715198391573},{"_id":"public/images/pasted-63.png","hash":"6ffb7887a7a7f405decf6b50e0e54dde6f2668a5","modified":1715198391573},{"_id":"public/images/pasted-65.png","hash":"42eccbee20c3f021a2a76a63e7fcba7e27fe155b","modified":1715198391573},{"_id":"public/images/pasted-66.png","hash":"ffd6971827ab02d85b550847968b0ffec3daa13f","modified":1715198391573},{"_id":"public/images/pasted-7.png","hash":"b73ff607d8ba6c4ccd64088f9b2fdda40fc98f35","modified":1715198391573},{"_id":"public/images/pasted-8.png","hash":"c2c4376eb1bc94d282caebe5234159e2c0180dfc","modified":1715198391573},{"_id":"public/images/pasted-9.png","hash":"32c8bf544f62ba0a59b3f14d271241530b8c95a2","modified":1715198391573},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1715198391573},{"_id":"public/researcherpapers/rdma/rdma_components.png","hash":"782b39b00abe9d188a49cec84fcb58a6ef86f282","modified":1715198391573},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1715198391573},{"_id":"public/images/avatar.gif","hash":"18c53e15eb0c84b139995f9334ed8522b40aeaf6","modified":1715198391573},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1715198391573},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1715198391573},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1715198391573},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1715198391573},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1715198391573},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1715198391573},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1715198391573},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1715198391573},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1715198391573},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1715198391573},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1715198391573},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1715198391573},{"_id":"public/lib/three/LICENSE","hash":"b29db4c99aa5b8d574026f68804051ff4b75466e","modified":1715198391573},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1715198391573},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1715198391573},{"_id":"public/uploads/wechat-qcode.jpg","hash":"c785f74f1b7778e8628e37f7d14fec37c411154e","modified":1715198391573},{"_id":"public/uploads/wechat-reward.jpg","hash":"0e0323d5a042387fe1cfab69aad5828ac0b68188","modified":1715198391573},{"_id":"public/images/pasted-10.png","hash":"2f8abe25445780f2dc0ca438eff2b90a1842fe8f","modified":1715198391573},{"_id":"public/images/pasted-16.png","hash":"f72fa6d08a10af16406df29abc35fd7c2fbe5a8a","modified":1715198391573},{"_id":"public/images/pasted-22.png","hash":"99092f7596b491c2ad65548cfba7d7236da983b0","modified":1715198391573},{"_id":"public/images/pasted-34.png","hash":"9569f2e0163d15d8d7315cf0cc78439ca8731d90","modified":1715198391573},{"_id":"public/images/pasted-38.png","hash":"350df6868afa9b38c4b31b41ca98f9d0cb5ebe22","modified":1715198391573},{"_id":"public/images/pasted-41.png","hash":"b11d22a1ac3f16efad7881fb4e6d5a070f14ff7d","modified":1715198391573},{"_id":"public/images/pasted-44.png","hash":"00f84a35d95a378425ed9c0b10d23cd14e98f735","modified":1715198391573},{"_id":"public/images/pasted-52.png","hash":"946e258ebfb73d4bce62de73940a1e0eba9272a5","modified":1715198391573},{"_id":"public/images/pasted-51.png","hash":"90d9d3e3e301b7da758f9e00b19aa497dea26d5d","modified":1715198391573},{"_id":"public/images/pasted-54.png","hash":"66b02462ba6ffc37ce2b6ce3a9ecbcdcc08a06fe","modified":1715198391573},{"_id":"public/images/pasted-55.png","hash":"95fabb0e927b340993f9ce8be4f0432571c930bb","modified":1715198391573},{"_id":"public/images/pasted-58.png","hash":"838ae6abc5194b2fd9937c735bae29f46e5a9c87","modified":1715198391573},{"_id":"public/images/pasted-60.png","hash":"e60b43d8f76b88818ae009e200f7b7d5ef24c7d1","modified":1715198391573},{"_id":"public/images/pasted-59.png","hash":"838ae6abc5194b2fd9937c735bae29f46e5a9c87","modified":1715198391573},{"_id":"public/images/pasted-62.png","hash":"3c83c9be451346a6ecd0938af89ed1e05d55c1da","modified":1715198391573},{"_id":"public/images/pasted-64.png","hash":"80757a10240447f97d788630495a69f9c1e8f69a","modified":1715198391573},{"_id":"public/images/pasted-67.png","hash":"25f4b07a1e6adf4361cbb7d158169d80d05359e1","modified":1715198391573},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1715198391573},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1715198391573},{"_id":"public/images/pasted-11.png","hash":"635979cdc04325601667985fc5450722c1661f86","modified":1715198391573},{"_id":"public/images/pasted-27.png","hash":"b0f7b2e07b344dd8d0fe694c15f9dbb888636763","modified":1715198391573},{"_id":"public/images/pasted-4.png","hash":"145702a935771da5b1465512a69549f0e9eaa15e","modified":1715198391573},{"_id":"public/images/pasted-5.png","hash":"145702a935771da5b1465512a69549f0e9eaa15e","modified":1715198391573},{"_id":"public/images/pasted-61.png","hash":"924b207375bbdf56133ead33a1b899de298a31e5","modified":1715198391573},{"_id":"public/images/pasted-69.png","hash":"906c0974a8f4044870946aef0b23439fd11f9203","modified":1715198391573},{"_id":"public/images/pasted-19.png","hash":"54b7136c3cfa663d724092058a08f7518b2ef958","modified":1715198391573},{"_id":"public/images/pasted-20.png","hash":"c9a577b1c1704457fb0be745fa891925630abaad","modified":1715198391573},{"_id":"public/images/pasted-31.png","hash":"db1e17649e6c338682fef9dc0b5742afcebd4cf4","modified":1715198391573},{"_id":"public/images/pasted-68.png","hash":"93389aa3c4196b983ef48a77b2e2dc8b60142b20","modified":1715198391573},{"_id":"public/images/pasted-0.png","hash":"01634f69b71ed914d5d2aa271cd8321feb45e0bb","modified":1715198391573},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1715198391573},{"_id":"public/images/pasted-3.png","hash":"fa370da7a7b307773c03e3a14b5c694f52117550","modified":1715198391573},{"_id":"public/images/pasted-32.png","hash":"84e5d86840d31fc2d9430a064c9ddbe609ff8cb3","modified":1715198391573},{"_id":"public/js/algolia-search.js","hash":"813afcc30feee11d59f297f2d5a96f98fbbd4743","modified":1715198391573},{"_id":"public/js/local-search.js","hash":"9f3d3ddff86e7b2828772aba915a5ebfd7d9f55f","modified":1715198391573},{"_id":"public/js/next-boot.js","hash":"f7045763e277e685c271bd4b4c37e531d699ac63","modified":1715198391573},{"_id":"public/js/motion.js","hash":"09f8be6bcc6920546bb06e3f8c0181ec62c70b90","modified":1715198391573},{"_id":"public/js/utils.js","hash":"41fa3f7cc18e028263b6fa524a3a95fc93b1b81e","modified":1715198391573},{"_id":"public/js/bookmark.js","hash":"a00945ff886e9f6f835731cdaf29a3a3727c8877","modified":1715198391573},{"_id":"public/js/schemes/muse.js","hash":"792f4522a3b0b96584a041a4aca20fcded410079","modified":1715198391573},{"_id":"public/js/schemes/pisces.js","hash":"52d139e6f3bc212c8c9b71bc9e57e931920434a6","modified":1715198391573},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1715198391573},{"_id":"public/lib/three/README.html","hash":"dfb65c52765367cdcafd9aaf6241673cadfb150d","modified":1715198391573},{"_id":"public/lib/three/package.json","hash":"3e6a0c56ec47a38c0bf7b404f6e46965ec7d2e3d","modified":1715198391573},{"_id":"public/lib/three/renovate.json","hash":"94990e0ad04ce4a7c6f0ac3543318d9e02db1264","modified":1715198391573},{"_id":"public/lib/three/gulpfile.js","hash":"e0e9e7051d9d82a37c2aba1df396d8b3916323c4","modified":1715198391573},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1715198391573},{"_id":"public/lib/three/src/canvas_lines.js","hash":"650310ff6783671f8ceccf01f840b20d9c87b491","modified":1715198391573},{"_id":"public/lib/three/src/canvas_sphere.js","hash":"7614790c67d3e79e3390fe688f6b01afad7e3bb1","modified":1715198391573},{"_id":"public/lib/three/src/three-waves.js","hash":"e98e442f14920e9fb8691846dca3a2225d403048","modified":1715198391573},{"_id":"public/css/main.css","hash":"2ea4a5eeba168deb9545ee7fdbc5d1817185da22","modified":1715198391573},{"_id":"public/lib/anime.min.js","hash":"47cb482a8a488620a793d50ba8f6752324b46af3","modified":1715198391573},{"_id":"public/lib/three/canvas_lines.min.js","hash":"ae6584edc0418d68731cab82c1494f26bd77c07d","modified":1715198391573},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"186c3bd6ae352d336cdbd0e555ee76a844854c94","modified":1715198391573},{"_id":"public/lib/three/three-waves.min.js","hash":"329483be97cdda030779da9a6cd1e3eae645cf4f","modified":1715198391573},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1715198391573},{"_id":"public/lib/three/lib/Projector.js","hash":"1ad16e96cea2a8a9155bb429c83ef9bdd341ce99","modified":1715198391573},{"_id":"public/lib/three/lib/CanvasRenderer.js","hash":"cf8e1ce6e884023ad0d692cf30f399862407fb40","modified":1715198391573},{"_id":"public/images/pasted-15.png","hash":"3bfe945e2c742897c6ffb70638c69112e2e8183e","modified":1715198391573},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1715198391573},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1715198391573},{"_id":"public/images/pasted-30.png","hash":"c24e212b6281f24cb68963b87af9f319541a8df6","modified":1715198391573},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1715198391573},{"_id":"themes/next/source/lib/canvas-ribbon/LICENSE","hash":"b29db4c99aa5b8d574026f68804051ff4b75466e","modified":1715199425055},{"_id":"themes/next/source/lib/canvas-ribbon/README.md","hash":"3a18d68b0673c0e79faecc8503268ac7bec7d30e","modified":1715199425056},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"65b1a8f12d04b15d7ed6eeb9d11dec760a799c5f","modified":1715199425056},{"_id":"themes/next/source/lib/canvas-ribbon/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1715199425051},{"_id":"themes/next/source/lib/canvas-ribbon/.git/config","hash":"f79e33176f8d3e893553102df6eb347a74fd078f","modified":1715199425054},{"_id":"themes/next/source/lib/canvas-ribbon/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1715199423099},{"_id":"themes/next/source/lib/canvas-ribbon/.git/packed-refs","hash":"1a669ea6243f62a7f4c02d82225d6a49fdadb567","modified":1715199425048},{"_id":"themes/next/source/lib/canvas-ribbon/.github/stale.yml","hash":"fd0856f6745db8bd0228079ccb92a662830cc4fb","modified":1715199425055},{"_id":"themes/next/source/lib/canvas-ribbon/.git/index","hash":"ae05f70e0016821487ac5b8b8cb6d655bd1283af","modified":1715199425056},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1715199423101},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1715199423100},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/fsmonitor-watchman.sample","hash":"0ec0ec9ac11111433d17ea79e0ae8cec650dcfa4","modified":1715199423102},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1715199423103},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1715199423104},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-commit.sample","hash":"a79d057388ee2c2fe6561d7697f1f5efcff96f23","modified":1715199423101},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-merge-commit.sample","hash":"04c64e58bc25c149482ed45dbd79e40effb89eb7","modified":1715199423103},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-push.sample","hash":"a599b773b930ca83dbc3a5c7c13059ac4a6eaedc","modified":1715199423104},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1715199423101},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1715199423102},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1715199423103},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/push-to-checkout.sample","hash":"508240328c8b55f8157c93c43bf5e291e5d2fbcb","modified":1715199423105},{"_id":"themes/next/source/lib/canvas-ribbon/.git/hooks/update.sample","hash":"730e6bd5225478bab6147b7a62a6e2ae21d40507","modified":1715199423104},{"_id":"themes/next/source/lib/canvas-ribbon/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1715199423099},{"_id":"themes/next/source/lib/canvas-ribbon/.git/logs/HEAD","hash":"f67b7ee01071c39de3dd633147d3f8966bfad102","modified":1715199425052},{"_id":"themes/next/source/lib/canvas-ribbon/.git/objects/pack/pack-51ad3c571540d30ecb2fd40cca6293673eef2128.idx","hash":"b3ed21853151871bcff26c186e8f7f91d585c99e","modified":1715199425032},{"_id":"themes/next/source/lib/canvas-ribbon/.git/objects/pack/pack-51ad3c571540d30ecb2fd40cca6293673eef2128.pack","hash":"721d98e54084ae6c5a293eb8f4f49db4f530f135","modified":1715199425032},{"_id":"themes/next/source/lib/canvas-ribbon/.git/refs/heads/master","hash":"16bd947558482613ed699f6cd50bfef39a7837da","modified":1715199425052},{"_id":"themes/next/source/lib/canvas-ribbon/.git/logs/refs/heads/master","hash":"f67b7ee01071c39de3dd633147d3f8966bfad102","modified":1715199425052},{"_id":"themes/next/source/lib/canvas-ribbon/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1715199425050},{"_id":"themes/next/source/lib/canvas-ribbon/.git/logs/refs/remotes/origin/HEAD","hash":"f67b7ee01071c39de3dd633147d3f8966bfad102","modified":1715199425050},{"_id":"public/lib/canvas-ribbon/LICENSE","hash":"b29db4c99aa5b8d574026f68804051ff4b75466e","modified":1715199870795},{"_id":"public/lib/canvas-ribbon/README.html","hash":"7cfbb44eb0245dc42d52d833b8ab10696f663a53","modified":1715199870795},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"65b1a8f12d04b15d7ed6eeb9d11dec760a799c5f","modified":1715199870795}],"Category":[{"name":"研究生论文研读","_id":"clvy8u62k000hdoy90xbj7r8e"},{"name":"-Linux","_id":"clvy8u62t000mdoy9f8c7c73d"},{"name":"计算机硬件","_id":"clvy8u62y000odoy9eiuug831"},{"name":"RDMA论文研读","parent":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64a0011doy936lcfwth"},{"name":"RDMA技术","_id":"clvy8u64c0017doy9d2jf1wwc"}],"Data":[],"Page":[{"_content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>","source":"404.html","raw":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>","date":"2024-05-08T19:47:58.624Z","updated":"2024-05-08T19:47:58.624Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"clvy8u61o0000doy91dttgd6j","content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>","excerpt":"","more":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>"},{"title":"个人主页","comments":0,"_content":"\n## 现实中的我\n  - 英文名：Master.TJ。\n  - 一个爱学习，知上进，善沟通，重细节，懂感恩的人。\n  - 对待生活认真，这辈子太短，想着能留下一些精神财富仅此而已。\n  - 热爱技术，沉迷追求技术。\n  \n## 网络中的我\n  - 就是一个技术控 沉迷学习无法自拔。\n  - [https://tjcug.github.io](https://tjcug.github.io) 是我技术博客，涉及的内容与计算机相关。\n  \n## 技术介绍\n  - JavaWeb、JavaWeb,Android,SpringMVC,Hibernate,Struts2 \n  - bootstrap,jquery,EasyUI,three.js\n  - Storm, Hadoop ,Spark ,Hbase ,Flink\n  \n## 目前主要学习大数据方面知识，欢迎大家前来讨论学习。","source":"about/index.md","raw":"title: 个人主页\ncomments: false\n---\n\n## 现实中的我\n  - 英文名：Master.TJ。\n  - 一个爱学习，知上进，善沟通，重细节，懂感恩的人。\n  - 对待生活认真，这辈子太短，想着能留下一些精神财富仅此而已。\n  - 热爱技术，沉迷追求技术。\n  \n## 网络中的我\n  - 就是一个技术控 沉迷学习无法自拔。\n  - [https://tjcug.github.io](https://tjcug.github.io) 是我技术博客，涉及的内容与计算机相关。\n  \n## 技术介绍\n  - JavaWeb、JavaWeb,Android,SpringMVC,Hibernate,Struts2 \n  - bootstrap,jquery,EasyUI,three.js\n  - Storm, Hadoop ,Spark ,Hbase ,Flink\n  \n## 目前主要学习大数据方面知识，欢迎大家前来讨论学习。","date":"2024-05-08T19:47:58.627Z","updated":"2024-05-08T19:47:58.627Z","path":"about/index.html","layout":"page","_id":"clvy8u61v0002doy95h7j7g0r","content":"<h2 id=\"现实中的我\"><a href=\"#现实中的我\" class=\"headerlink\" title=\"现实中的我\"></a>现实中的我</h2><ul>\n<li>英文名：Master.TJ。</li>\n<li>一个爱学习，知上进，善沟通，重细节，懂感恩的人。</li>\n<li>对待生活认真，这辈子太短，想着能留下一些精神财富仅此而已。</li>\n<li>热爱技术，沉迷追求技术。</li>\n</ul>\n<h2 id=\"网络中的我\"><a href=\"#网络中的我\" class=\"headerlink\" title=\"网络中的我\"></a>网络中的我</h2><ul>\n<li>就是一个技术控 沉迷学习无法自拔。</li>\n<li><a href=\"https://tjcug.github.io\">https://tjcug.github.io</a> 是我技术博客，涉及的内容与计算机相关。</li>\n</ul>\n<h2 id=\"技术介绍\"><a href=\"#技术介绍\" class=\"headerlink\" title=\"技术介绍\"></a>技术介绍</h2><ul>\n<li>JavaWeb、JavaWeb,Android,SpringMVC,Hibernate,Struts2 </li>\n<li>bootstrap,jquery,EasyUI,three.js</li>\n<li>Storm, Hadoop ,Spark ,Hbase ,Flink</li>\n</ul>\n<h2 id=\"目前主要学习大数据方面知识，欢迎大家前来讨论学习。\"><a href=\"#目前主要学习大数据方面知识，欢迎大家前来讨论学习。\" class=\"headerlink\" title=\"目前主要学习大数据方面知识，欢迎大家前来讨论学习。\"></a>目前主要学习大数据方面知识，欢迎大家前来讨论学习。</h2>","excerpt":"","more":"<h2 id=\"现实中的我\"><a href=\"#现实中的我\" class=\"headerlink\" title=\"现实中的我\"></a>现实中的我</h2><ul>\n<li>英文名：Master.TJ。</li>\n<li>一个爱学习，知上进，善沟通，重细节，懂感恩的人。</li>\n<li>对待生活认真，这辈子太短，想着能留下一些精神财富仅此而已。</li>\n<li>热爱技术，沉迷追求技术。</li>\n</ul>\n<h2 id=\"网络中的我\"><a href=\"#网络中的我\" class=\"headerlink\" title=\"网络中的我\"></a>网络中的我</h2><ul>\n<li>就是一个技术控 沉迷学习无法自拔。</li>\n<li><a href=\"https://tjcug.github.io\">https://tjcug.github.io</a> 是我技术博客，涉及的内容与计算机相关。</li>\n</ul>\n<h2 id=\"技术介绍\"><a href=\"#技术介绍\" class=\"headerlink\" title=\"技术介绍\"></a>技术介绍</h2><ul>\n<li>JavaWeb、JavaWeb,Android,SpringMVC,Hibernate,Struts2 </li>\n<li>bootstrap,jquery,EasyUI,three.js</li>\n<li>Storm, Hadoop ,Spark ,Hbase ,Flink</li>\n</ul>\n<h2 id=\"目前主要学习大数据方面知识，欢迎大家前来讨论学习。\"><a href=\"#目前主要学习大数据方面知识，欢迎大家前来讨论学习。\" class=\"headerlink\" title=\"目前主要学习大数据方面知识，欢迎大家前来讨论学习。\"></a>目前主要学习大数据方面知识，欢迎大家前来讨论学习。</h2>"},{"title":"分类","date":"2014-12-22T04:39:04.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"title: 分类\ndate: 2014-12-22 12:39:04\ntype: \"categories\"\ncomments: false\n---","updated":"2024-05-08T19:47:58.628Z","path":"categories/index.html","layout":"page","_id":"clvy8u61x0004doy9hnjs80uw","content":"","excerpt":"","more":""},{"title":"标签","date":"2014-12-22T04:39:04.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"title: 标签\ndate: 2014-12-22 12:39:04\ntype: \"tags\"\ncomments: false\n---","updated":"2024-05-08T19:47:58.679Z","path":"tags/index.html","layout":"page","_id":"clvy8u6210006doy91mlaffxs","content":"","excerpt":"","more":""}],"Post":[{"title":"GraphX Graph Processing in a Distributed Dataflow Framework","author":"Master.TJ","date":"2018-05-25T09:34:00.000Z","_content":"## 解决的问题：\n\n![upload successful](\\blog\\images\\pasted-26.png)\n虽然现有的专用图系统能够实现广泛的系统优化，但也是有代价的。 图只是较大的分析过程的一部分，通常将非结构化的图形和表格式数据组合在一起。 因此，分析流水线（例如图11）被迫组成多个系统，这增加了复杂性并导致不必要的数据移动和重复。 此外，为了追求性能，图形处理系统通常会放弃容错，以支持快照恢复。 最后，作为专门的图处理系统，图处理框架通常不能享受分布式数据流框架的广泛支持。\n\n相比之下，通用分布式数据流框架（例如Map-Reduce [10]，Spark [39]，Dryad [15]）暴露丰富的数据流操作符（例如map，reduce，group-by，join） 用于分析非结构化和表格化数据，并被广泛采用。 但是，直接使用数据流操作符来实现迭代图算法可能具有挑战性，往往需要复杂连接的多个阶段。 此外，分布式数据流框架中定义的通用连接和聚合策略不利用迭代图算法中的常见模式和结构，因此错过了重要的优化机会。\n\n为了支持这个论点，我们引入了GraphX，一个嵌入到Spark [39]分布式数据流系统中的高效的图形处理框架。\n\n它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。\n\n\n## 3.3  GraphX operators\n\n**GraphX Pregel abstraction**:\n\n它的主要思想是通过构造出这样一个Triplet 三元组视图这样的一个结构。这个结构是通过将顶点RDD和边RDD进行Join操作得到\n\n这样一个三元组信息。为什么要得到这样一个Triplet 三元组视图这样的一个结构。最主要的原因是因为这个三元组视图包括源顶点属性、目标顶点属性、以及边属性。这样我们就可以通过一些类似于专业图处理系统的GAS计算模型进行 类似MpaReduce思想的图形计算。\n     它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。\n\n\n## GraphX优化\n### Vertex Mirroring\n由于GraphX的顶点和边属性集合分区都是独立的，然而Join操作需要数据移动。GraphX则通过将顶点属性通过网络传输到边分区上。由于两个原因，这种方法大大减少了通信。 首先，现实世界的图通常比顶点具有更多数量级的边。 其次，单个顶点在同一个分区中可能有许多边，从而实现顶点属性的大量重用。\n\n### Multicast Join(多路广播)\n虽然所有顶点被发送到每个边缘分区的广播连接将确保连接发生在边缘分区上，但是由于大多数分区只需要一小部分顶点来完成连接，所以它仍然是低效的。 因此，GraphX引入了多播连接，其中每个顶点属性仅发送到包含相邻边的边缘分区。\n\n![upload successful](\\blog\\images\\pasted-32.png)\n\n### Partial Materialization （部分实体化）\n当顶点属性改变时，顶点复制被急切地执行，但是，在边缘分区上的本地join没有实现，以避免重复。 相反，镜像顶点属性存储在每个边界分区上的散列映射中，并在构建三元组时引用。\n\n### Incremental View Maintenacne\n当下一次访问三元组视图时，只有已更改的顶点被重新路由到其边缘分割连接点，并且未更改的顶点的局部Mirror被重用。然后被更改的顶点更新相应的Triplets View视图。\n\n![upload successful](\\blog\\images\\pasted-31.png)\n\n### mrTriplets 优化\n#### 4.3.1 Filtered Index Scanning\nmrTriplets操作的第一阶段就是通过扫描triplets三元组视图，然后应用用户定义的map 函数应用到每个triplets三元组中。然而随着迭代算法的进行，工作集合被收缩，大多数顶点已经收敛。Map function只需要操作那些活跃顶点的triplets三元组视图。直接顺序扫描所有的索引将会变得很浪费。\n\n为了解决这个问题，GraphX提出了Index Scanning对于triplets三元组视图。也就是说应用程序通过使用subgraph运算符来限制图来表示当前活跃顶点。活跃顶点通过route table (查询活跃顶点属于相应的edge partitions)被推送edge partitions，它可以用来使用源顶点id上的CSR索引来快速查找到相应的edge（4.1节）。\n#### 4.3.2 Automatic Join Elimination\n问题：对于triplets三元组视图的某些operator访问来说，可能某些顶点属性没有访问，或则根本一个都没有使用。那么对于triplets三元组视图来说，会造成一部分资源浪费，因为riplets三元组视图被构造的时候所有的source vertex属性和distinction vertex属性都被join构造到triplets视图中。\n\nGraphX使用JVM字节码分析器在运行时检查用户定义的函数，并确定是否引用源或目标顶点属性。如果只引用一个属性，并且三元组视图尚未实现，则GraphX自动重写生成的查询计划 三联视图从三联加入到双向联接。 如果没有引用顶点属性，则GraphX完全消除连接。 这种修改是可能的，因为三元组视图遵循Spark中RDD的惰性语义。 如果用户从不访问三元组视图，则永远不会实现。 因此，对mrTriplets的调用能够重写生成三元组视图的相关部分所需的联接。\n\n### GraphX 容错\nGraph实现容错主要是通过丢失分区的剩余副本或者重新计算它们来恢复","source":"_posts/2014-OSDI-GraphX-Graph-Processing-in-a-Distributed-Dataflow-Framework.md","raw":"title: GraphX Graph Processing in a Distributed Dataflow Framework\nauthor: Master.TJ\ntags:\n  - 图计算\ncategories:\n  - 研究生论文研读\ndate: 2018-05-25 17:34:00\n---\n## 解决的问题：\n\n![upload successful](\\blog\\images\\pasted-26.png)\n虽然现有的专用图系统能够实现广泛的系统优化，但也是有代价的。 图只是较大的分析过程的一部分，通常将非结构化的图形和表格式数据组合在一起。 因此，分析流水线（例如图11）被迫组成多个系统，这增加了复杂性并导致不必要的数据移动和重复。 此外，为了追求性能，图形处理系统通常会放弃容错，以支持快照恢复。 最后，作为专门的图处理系统，图处理框架通常不能享受分布式数据流框架的广泛支持。\n\n相比之下，通用分布式数据流框架（例如Map-Reduce [10]，Spark [39]，Dryad [15]）暴露丰富的数据流操作符（例如map，reduce，group-by，join） 用于分析非结构化和表格化数据，并被广泛采用。 但是，直接使用数据流操作符来实现迭代图算法可能具有挑战性，往往需要复杂连接的多个阶段。 此外，分布式数据流框架中定义的通用连接和聚合策略不利用迭代图算法中的常见模式和结构，因此错过了重要的优化机会。\n\n为了支持这个论点，我们引入了GraphX，一个嵌入到Spark [39]分布式数据流系统中的高效的图形处理框架。\n\n它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。\n\n\n## 3.3  GraphX operators\n\n**GraphX Pregel abstraction**:\n\n它的主要思想是通过构造出这样一个Triplet 三元组视图这样的一个结构。这个结构是通过将顶点RDD和边RDD进行Join操作得到\n\n这样一个三元组信息。为什么要得到这样一个Triplet 三元组视图这样的一个结构。最主要的原因是因为这个三元组视图包括源顶点属性、目标顶点属性、以及边属性。这样我们就可以通过一些类似于专业图处理系统的GAS计算模型进行 类似MpaReduce思想的图形计算。\n     它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。\n\n\n## GraphX优化\n### Vertex Mirroring\n由于GraphX的顶点和边属性集合分区都是独立的，然而Join操作需要数据移动。GraphX则通过将顶点属性通过网络传输到边分区上。由于两个原因，这种方法大大减少了通信。 首先，现实世界的图通常比顶点具有更多数量级的边。 其次，单个顶点在同一个分区中可能有许多边，从而实现顶点属性的大量重用。\n\n### Multicast Join(多路广播)\n虽然所有顶点被发送到每个边缘分区的广播连接将确保连接发生在边缘分区上，但是由于大多数分区只需要一小部分顶点来完成连接，所以它仍然是低效的。 因此，GraphX引入了多播连接，其中每个顶点属性仅发送到包含相邻边的边缘分区。\n\n![upload successful](\\blog\\images\\pasted-32.png)\n\n### Partial Materialization （部分实体化）\n当顶点属性改变时，顶点复制被急切地执行，但是，在边缘分区上的本地join没有实现，以避免重复。 相反，镜像顶点属性存储在每个边界分区上的散列映射中，并在构建三元组时引用。\n\n### Incremental View Maintenacne\n当下一次访问三元组视图时，只有已更改的顶点被重新路由到其边缘分割连接点，并且未更改的顶点的局部Mirror被重用。然后被更改的顶点更新相应的Triplets View视图。\n\n![upload successful](\\blog\\images\\pasted-31.png)\n\n### mrTriplets 优化\n#### 4.3.1 Filtered Index Scanning\nmrTriplets操作的第一阶段就是通过扫描triplets三元组视图，然后应用用户定义的map 函数应用到每个triplets三元组中。然而随着迭代算法的进行，工作集合被收缩，大多数顶点已经收敛。Map function只需要操作那些活跃顶点的triplets三元组视图。直接顺序扫描所有的索引将会变得很浪费。\n\n为了解决这个问题，GraphX提出了Index Scanning对于triplets三元组视图。也就是说应用程序通过使用subgraph运算符来限制图来表示当前活跃顶点。活跃顶点通过route table (查询活跃顶点属于相应的edge partitions)被推送edge partitions，它可以用来使用源顶点id上的CSR索引来快速查找到相应的edge（4.1节）。\n#### 4.3.2 Automatic Join Elimination\n问题：对于triplets三元组视图的某些operator访问来说，可能某些顶点属性没有访问，或则根本一个都没有使用。那么对于triplets三元组视图来说，会造成一部分资源浪费，因为riplets三元组视图被构造的时候所有的source vertex属性和distinction vertex属性都被join构造到triplets视图中。\n\nGraphX使用JVM字节码分析器在运行时检查用户定义的函数，并确定是否引用源或目标顶点属性。如果只引用一个属性，并且三元组视图尚未实现，则GraphX自动重写生成的查询计划 三联视图从三联加入到双向联接。 如果没有引用顶点属性，则GraphX完全消除连接。 这种修改是可能的，因为三元组视图遵循Spark中RDD的惰性语义。 如果用户从不访问三元组视图，则永远不会实现。 因此，对mrTriplets的调用能够重写生成三元组视图的相关部分所需的联接。\n\n### GraphX 容错\nGraph实现容错主要是通过丢失分区的剩余副本或者重新计算它们来恢复","slug":"2014-OSDI-GraphX-Graph-Processing-in-a-Distributed-Dataflow-Framework","published":1,"updated":"2024-05-08T19:47:58.624Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u61s0001doy9fw621nhm","content":"<h2 id=\"解决的问题：\"><a href=\"#解决的问题：\" class=\"headerlink\" title=\"解决的问题：\"></a>解决的问题：</h2><p><img src=\"\\blog\\images\\pasted-26.png\" alt=\"upload successful\"><br>虽然现有的专用图系统能够实现广泛的系统优化，但也是有代价的。 图只是较大的分析过程的一部分，通常将非结构化的图形和表格式数据组合在一起。 因此，分析流水线（例如图11）被迫组成多个系统，这增加了复杂性并导致不必要的数据移动和重复。 此外，为了追求性能，图形处理系统通常会放弃容错，以支持快照恢复。 最后，作为专门的图处理系统，图处理框架通常不能享受分布式数据流框架的广泛支持。</p>\n<p>相比之下，通用分布式数据流框架（例如Map-Reduce [10]，Spark [39]，Dryad [15]）暴露丰富的数据流操作符（例如map，reduce，group-by，join） 用于分析非结构化和表格化数据，并被广泛采用。 但是，直接使用数据流操作符来实现迭代图算法可能具有挑战性，往往需要复杂连接的多个阶段。 此外，分布式数据流框架中定义的通用连接和聚合策略不利用迭代图算法中的常见模式和结构，因此错过了重要的优化机会。</p>\n<p>为了支持这个论点，我们引入了GraphX，一个嵌入到Spark [39]分布式数据流系统中的高效的图形处理框架。</p>\n<p>它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。</p>\n<h2 id=\"3-3-GraphX-operators\"><a href=\"#3-3-GraphX-operators\" class=\"headerlink\" title=\"3.3  GraphX operators\"></a>3.3  GraphX operators</h2><p><strong>GraphX Pregel abstraction</strong>:</p>\n<p>它的主要思想是通过构造出这样一个Triplet 三元组视图这样的一个结构。这个结构是通过将顶点RDD和边RDD进行Join操作得到</p>\n<p>这样一个三元组信息。为什么要得到这样一个Triplet 三元组视图这样的一个结构。最主要的原因是因为这个三元组视图包括源顶点属性、目标顶点属性、以及边属性。这样我们就可以通过一些类似于专业图处理系统的GAS计算模型进行 类似MpaReduce思想的图形计算。<br>     它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。</p>\n<h2 id=\"GraphX优化\"><a href=\"#GraphX优化\" class=\"headerlink\" title=\"GraphX优化\"></a>GraphX优化</h2><h3 id=\"Vertex-Mirroring\"><a href=\"#Vertex-Mirroring\" class=\"headerlink\" title=\"Vertex Mirroring\"></a>Vertex Mirroring</h3><p>由于GraphX的顶点和边属性集合分区都是独立的，然而Join操作需要数据移动。GraphX则通过将顶点属性通过网络传输到边分区上。由于两个原因，这种方法大大减少了通信。 首先，现实世界的图通常比顶点具有更多数量级的边。 其次，单个顶点在同一个分区中可能有许多边，从而实现顶点属性的大量重用。</p>\n<h3 id=\"Multicast-Join-多路广播\"><a href=\"#Multicast-Join-多路广播\" class=\"headerlink\" title=\"Multicast Join(多路广播)\"></a>Multicast Join(多路广播)</h3><p>虽然所有顶点被发送到每个边缘分区的广播连接将确保连接发生在边缘分区上，但是由于大多数分区只需要一小部分顶点来完成连接，所以它仍然是低效的。 因此，GraphX引入了多播连接，其中每个顶点属性仅发送到包含相邻边的边缘分区。</p>\n<p><img src=\"\\blog\\images\\pasted-32.png\" alt=\"upload successful\"></p>\n<h3 id=\"Partial-Materialization-（部分实体化）\"><a href=\"#Partial-Materialization-（部分实体化）\" class=\"headerlink\" title=\"Partial Materialization （部分实体化）\"></a>Partial Materialization （部分实体化）</h3><p>当顶点属性改变时，顶点复制被急切地执行，但是，在边缘分区上的本地join没有实现，以避免重复。 相反，镜像顶点属性存储在每个边界分区上的散列映射中，并在构建三元组时引用。</p>\n<h3 id=\"Incremental-View-Maintenacne\"><a href=\"#Incremental-View-Maintenacne\" class=\"headerlink\" title=\"Incremental View Maintenacne\"></a>Incremental View Maintenacne</h3><p>当下一次访问三元组视图时，只有已更改的顶点被重新路由到其边缘分割连接点，并且未更改的顶点的局部Mirror被重用。然后被更改的顶点更新相应的Triplets View视图。</p>\n<p><img src=\"\\blog\\images\\pasted-31.png\" alt=\"upload successful\"></p>\n<h3 id=\"mrTriplets-优化\"><a href=\"#mrTriplets-优化\" class=\"headerlink\" title=\"mrTriplets 优化\"></a>mrTriplets 优化</h3><h4 id=\"4-3-1-Filtered-Index-Scanning\"><a href=\"#4-3-1-Filtered-Index-Scanning\" class=\"headerlink\" title=\"4.3.1 Filtered Index Scanning\"></a>4.3.1 Filtered Index Scanning</h4><p>mrTriplets操作的第一阶段就是通过扫描triplets三元组视图，然后应用用户定义的map 函数应用到每个triplets三元组中。然而随着迭代算法的进行，工作集合被收缩，大多数顶点已经收敛。Map function只需要操作那些活跃顶点的triplets三元组视图。直接顺序扫描所有的索引将会变得很浪费。</p>\n<p>为了解决这个问题，GraphX提出了Index Scanning对于triplets三元组视图。也就是说应用程序通过使用subgraph运算符来限制图来表示当前活跃顶点。活跃顶点通过route table (查询活跃顶点属于相应的edge partitions)被推送edge partitions，它可以用来使用源顶点id上的CSR索引来快速查找到相应的edge（4.1节）。</p>\n<h4 id=\"4-3-2-Automatic-Join-Elimination\"><a href=\"#4-3-2-Automatic-Join-Elimination\" class=\"headerlink\" title=\"4.3.2 Automatic Join Elimination\"></a>4.3.2 Automatic Join Elimination</h4><p>问题：对于triplets三元组视图的某些operator访问来说，可能某些顶点属性没有访问，或则根本一个都没有使用。那么对于triplets三元组视图来说，会造成一部分资源浪费，因为riplets三元组视图被构造的时候所有的source vertex属性和distinction vertex属性都被join构造到triplets视图中。</p>\n<p>GraphX使用JVM字节码分析器在运行时检查用户定义的函数，并确定是否引用源或目标顶点属性。如果只引用一个属性，并且三元组视图尚未实现，则GraphX自动重写生成的查询计划 三联视图从三联加入到双向联接。 如果没有引用顶点属性，则GraphX完全消除连接。 这种修改是可能的，因为三元组视图遵循Spark中RDD的惰性语义。 如果用户从不访问三元组视图，则永远不会实现。 因此，对mrTriplets的调用能够重写生成三元组视图的相关部分所需的联接。</p>\n<h3 id=\"GraphX-容错\"><a href=\"#GraphX-容错\" class=\"headerlink\" title=\"GraphX 容错\"></a>GraphX 容错</h3><p>Graph实现容错主要是通过丢失分区的剩余副本或者重新计算它们来恢复</p>\n","excerpt":"","more":"<h2 id=\"解决的问题：\"><a href=\"#解决的问题：\" class=\"headerlink\" title=\"解决的问题：\"></a>解决的问题：</h2><p><img src=\"\\blog\\images\\pasted-26.png\" alt=\"upload successful\"><br>虽然现有的专用图系统能够实现广泛的系统优化，但也是有代价的。 图只是较大的分析过程的一部分，通常将非结构化的图形和表格式数据组合在一起。 因此，分析流水线（例如图11）被迫组成多个系统，这增加了复杂性并导致不必要的数据移动和重复。 此外，为了追求性能，图形处理系统通常会放弃容错，以支持快照恢复。 最后，作为专门的图处理系统，图处理框架通常不能享受分布式数据流框架的广泛支持。</p>\n<p>相比之下，通用分布式数据流框架（例如Map-Reduce [10]，Spark [39]，Dryad [15]）暴露丰富的数据流操作符（例如map，reduce，group-by，join） 用于分析非结构化和表格化数据，并被广泛采用。 但是，直接使用数据流操作符来实现迭代图算法可能具有挑战性，往往需要复杂连接的多个阶段。 此外，分布式数据流框架中定义的通用连接和聚合策略不利用迭代图算法中的常见模式和结构，因此错过了重要的优化机会。</p>\n<p>为了支持这个论点，我们引入了GraphX，一个嵌入到Spark [39]分布式数据流系统中的高效的图形处理框架。</p>\n<p>它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。</p>\n<h2 id=\"3-3-GraphX-operators\"><a href=\"#3-3-GraphX-operators\" class=\"headerlink\" title=\"3.3  GraphX operators\"></a>3.3  GraphX operators</h2><p><strong>GraphX Pregel abstraction</strong>:</p>\n<p>它的主要思想是通过构造出这样一个Triplet 三元组视图这样的一个结构。这个结构是通过将顶点RDD和边RDD进行Join操作得到</p>\n<p>这样一个三元组信息。为什么要得到这样一个Triplet 三元组视图这样的一个结构。最主要的原因是因为这个三元组视图包括源顶点属性、目标顶点属性、以及边属性。这样我们就可以通过一些类似于专业图处理系统的GAS计算模型进行 类似MpaReduce思想的图形计算。<br>     它首先对每个Triplet三元组视图的每个元素进行一个MapFunction操作，得到一个消息。这个消息包括，属性数据以及一个目标顶点的ID。就是说你要将这个消息发送到哪个顶点上去。Message Combiners通过累加这些消息，然后将累加结构更新到相应顶点的属性数据。GraphX同这样一个GAS的思想，进行图形迭代计算。这个思想很像MapReduce的思想。通过这样的操作，不停的进行迭代计算。最终图形中每个顶点的属性数据收敛不再变化。整个图形算法最终完成。</p>\n<h2 id=\"GraphX优化\"><a href=\"#GraphX优化\" class=\"headerlink\" title=\"GraphX优化\"></a>GraphX优化</h2><h3 id=\"Vertex-Mirroring\"><a href=\"#Vertex-Mirroring\" class=\"headerlink\" title=\"Vertex Mirroring\"></a>Vertex Mirroring</h3><p>由于GraphX的顶点和边属性集合分区都是独立的，然而Join操作需要数据移动。GraphX则通过将顶点属性通过网络传输到边分区上。由于两个原因，这种方法大大减少了通信。 首先，现实世界的图通常比顶点具有更多数量级的边。 其次，单个顶点在同一个分区中可能有许多边，从而实现顶点属性的大量重用。</p>\n<h3 id=\"Multicast-Join-多路广播\"><a href=\"#Multicast-Join-多路广播\" class=\"headerlink\" title=\"Multicast Join(多路广播)\"></a>Multicast Join(多路广播)</h3><p>虽然所有顶点被发送到每个边缘分区的广播连接将确保连接发生在边缘分区上，但是由于大多数分区只需要一小部分顶点来完成连接，所以它仍然是低效的。 因此，GraphX引入了多播连接，其中每个顶点属性仅发送到包含相邻边的边缘分区。</p>\n<p><img src=\"\\blog\\images\\pasted-32.png\" alt=\"upload successful\"></p>\n<h3 id=\"Partial-Materialization-（部分实体化）\"><a href=\"#Partial-Materialization-（部分实体化）\" class=\"headerlink\" title=\"Partial Materialization （部分实体化）\"></a>Partial Materialization （部分实体化）</h3><p>当顶点属性改变时，顶点复制被急切地执行，但是，在边缘分区上的本地join没有实现，以避免重复。 相反，镜像顶点属性存储在每个边界分区上的散列映射中，并在构建三元组时引用。</p>\n<h3 id=\"Incremental-View-Maintenacne\"><a href=\"#Incremental-View-Maintenacne\" class=\"headerlink\" title=\"Incremental View Maintenacne\"></a>Incremental View Maintenacne</h3><p>当下一次访问三元组视图时，只有已更改的顶点被重新路由到其边缘分割连接点，并且未更改的顶点的局部Mirror被重用。然后被更改的顶点更新相应的Triplets View视图。</p>\n<p><img src=\"\\blog\\images\\pasted-31.png\" alt=\"upload successful\"></p>\n<h3 id=\"mrTriplets-优化\"><a href=\"#mrTriplets-优化\" class=\"headerlink\" title=\"mrTriplets 优化\"></a>mrTriplets 优化</h3><h4 id=\"4-3-1-Filtered-Index-Scanning\"><a href=\"#4-3-1-Filtered-Index-Scanning\" class=\"headerlink\" title=\"4.3.1 Filtered Index Scanning\"></a>4.3.1 Filtered Index Scanning</h4><p>mrTriplets操作的第一阶段就是通过扫描triplets三元组视图，然后应用用户定义的map 函数应用到每个triplets三元组中。然而随着迭代算法的进行，工作集合被收缩，大多数顶点已经收敛。Map function只需要操作那些活跃顶点的triplets三元组视图。直接顺序扫描所有的索引将会变得很浪费。</p>\n<p>为了解决这个问题，GraphX提出了Index Scanning对于triplets三元组视图。也就是说应用程序通过使用subgraph运算符来限制图来表示当前活跃顶点。活跃顶点通过route table (查询活跃顶点属于相应的edge partitions)被推送edge partitions，它可以用来使用源顶点id上的CSR索引来快速查找到相应的edge（4.1节）。</p>\n<h4 id=\"4-3-2-Automatic-Join-Elimination\"><a href=\"#4-3-2-Automatic-Join-Elimination\" class=\"headerlink\" title=\"4.3.2 Automatic Join Elimination\"></a>4.3.2 Automatic Join Elimination</h4><p>问题：对于triplets三元组视图的某些operator访问来说，可能某些顶点属性没有访问，或则根本一个都没有使用。那么对于triplets三元组视图来说，会造成一部分资源浪费，因为riplets三元组视图被构造的时候所有的source vertex属性和distinction vertex属性都被join构造到triplets视图中。</p>\n<p>GraphX使用JVM字节码分析器在运行时检查用户定义的函数，并确定是否引用源或目标顶点属性。如果只引用一个属性，并且三元组视图尚未实现，则GraphX自动重写生成的查询计划 三联视图从三联加入到双向联接。 如果没有引用顶点属性，则GraphX完全消除连接。 这种修改是可能的，因为三元组视图遵循Spark中RDD的惰性语义。 如果用户从不访问三元组视图，则永远不会实现。 因此，对mrTriplets的调用能够重写生成三元组视图的相关部分所需的联接。</p>\n<h3 id=\"GraphX-容错\"><a href=\"#GraphX-容错\" class=\"headerlink\" title=\"GraphX 容错\"></a>GraphX 容错</h3><p>Graph实现容错主要是通过丢失分区的剩余副本或者重新计算它们来恢复</p>\n"},{"title":"Apache Flink 官方文档翻译之 容错机制","author":"Master.TJ","date":"2018-05-29T08:32:59.000Z","_content":"## Introduce\nApache Flink 提供了可以恢复数据流应用到一致状态的容错机制。确保在发生故障时，程序的每条记录只会作用于状态一次（exactly-once），当然也可以降级为至少一次（at-least-once）。\n\n容错机制通过持续创建分布式数据流的快照来实现。对于状态占用空间小的流应用，这些快照非常轻量，可以高频率创建而对性能影响很小。流计算应用的状态保存在一个可配置的环境，如：master 节点或者 HDFS上。\n\n在遇到程序故障时（如机器、网络、软件等故障），Flink 停止分布式数据流。系统重启所有 operator ，重置其到最近成功的 checkpoint。输入重置到相应的状态快照位置。保证被重启的并行数据流中处理的任何一个 record 都不是 checkpoint 状态之前的一部分。\n\n注意：为了容错机制生效，数据源（例如 queue 或者 broker）需要能重放数据流。Apache Kafka 有这个特性，Flink 中 Kafka 的 connector 利用了这个功能。\n\n注意：由于 Flink 的 checkpoint 是通过分布式快照实现的，接下来我们将 snapshot 和 checkpoint 这两个词交替使用。\n## Checkpointing\n\nFlink 容错机制的核心就是持续创建分布式数据流及其状态的一致快照。这些快照在系统遇到故障时，充当可以回退的一致性检查点（checkpoint）。Lightweight Asynchronous Snapshots for Distributed Dataflows 描述了Flink 创建快照的机制。此论文是受分布式快照算法 Chandy-Lamport 启发，并针对 Flink 执行模型量身定制。\n## Barriers\n\nFlink 分布式快照的核心概念之一就是数据栅栏（barrier）。这些 barrier 被插入到数据流中，作为数据流的一部分和数据一起向下流动。Barrier 不会干扰正常数据，数据流严格有序。一个 barrier 把数据流分割成两部分：一部分进入到当前快照，另一部分进入下一个快照。每一个 barrier 都带有快照 ID，并且 barrier 之前的数据都进入了此快照。Barrier 不会干扰数据流处理，所以非常轻量。多个不同快照的多个 barrier 会在流中同时出现，即多个快照可能同时创建。\n\n![upload successful](\\blog\\images\\pasted-50.png)\nBarrier 在数据源端插入，当 snapshot n 的 barrier 插入后，系统会记录当前 snapshot 位置值 n (用Sn表示)。例如，在 Apache Kafka 中，这个变量表示某个分区中最后一条数据的偏移量。这个位置值 Sn 会被发送到一个称为 checkpoint coordinator 的模块。(即 Flink 的 JobManager).\n\n然后 barrier 继续往下流动，当一个 operator 从其输入流接收到所有标识 snapshot n 的 barrier 时，它会向其所有输出流插入一个标识 snapshot n 的 barrier。当 sink operator （DAG 流的终点）从其输入流接收到所有 barrier n 时，它向 the checkpoint coordinator 确认 snapshot n 已完成。当所有 sink 都确认了这个快照，快照就被标识为完成。\n\n![upload successful](\\blog\\images\\pasted-51.png)\n接收超过一个输入流的 operator 需要基于 barrier 对齐（align）输入。参见上图：\n\n1. operator 只要一接收到某个输入流的 barrier n，它就不能继续处理此数据流后续的数据，直到 operator 接收到其余流的 barrier n。否则会将属于 snapshot n 的数据和 snapshot n+1的搞混\n2. barrier n 所属的数据流先不处理，从这些数据流中接收到的数据被放入接收缓存里（input buffer）\n3. 当从最后一个流中提取到 barrier n 时，operator 会发射出所有等待向后发送的数据，然后发射snapshot n 所属的 barrier\n4. 经过以上步骤，operator 恢复所有输入流数据的处理，优先处理输入缓存中的数据\n\n## State\noperator 包含任何形式的状态，这些状态都必须包含在快照中。状态有很多种形式：\n\n* 用户自定义状态：由 transformation 函数例如（ map() 或者 filter())直接创建或者修改的状态。用户自定义状态可以是：转换函数中的 Java 对象的一个简单变量或者函数关联的 key/value 状态。参见 State in Streaming Applications\n\n* 系统状态：这种状态是指作为 operator 计算中一部分缓存数据。典型例子就是： 窗口缓存（window buffers），系统收集窗口对应数据到其中，直到窗口计算和发射。\n\noperator 在收到所有输入数据流中的 barrier 之后，在发射 barrier 到其输出流之前对其状态进行快照。此时，在 barrier 之前的数据对状态的更新已经完成，不会再依赖 barrier 之前数据。由于快照可能非常大，所以后端存储系统可配置。默认是存储到 JobManager 的内存中，但是对于生产系统，需要配置成一个可靠的分布式存储系统（例如 HDFS）。状态存储完成后，operator 会确认其 checkpoint 完成，发射出 barrier 到后续输出流。\n快照现在包含了：\n\n* 对于并行输入数据源：快照创建时数据流中的位置偏移\n\n* 对于 operator：存储在快照中的状态指针\n\n![upload successful](\\blog\\images\\pasted-52.png)\n\n## Exactly Once vs. At Least Once\n对齐操作可能会对流程序增加延迟。通常，这种额外的延迟在几毫秒的数量级，但是我们也遇到过延迟显著增加的异常情况。针对那些需要对所有输入都保持毫秒级的应用，Flink 提供了在 checkpoint 时关闭对齐的方法。当 operator 接收到一个 barrier 时，就会打一个快照，而不会等待其他 barrier。\n\n跳过对齐操作使得即使在 barrier 到达时，Operator 依然继续处理输入。这就是说：operator 在 checkpoint n 创建之前，继续处理属于 checkpoint n+1 的数据。所以当异常恢复时，这部分数据就会重复，因为它们被包含在了 checkpoint n 中，同时也会在之后再次被处理。\n\n注意：对齐操作只会发生在拥有多输入运算（join)或者多个输出的 operator（重分区、分流）的场景下。所以，对于自由 map(), flatmap(), fliter() 等的并行操作即使在至少一次的模式中仍然会保证严格一次。\n\n## Asynchronous State Snapshots\n我们注意到上面描述的机制意味着当 operator 向后端存储快照时，会停止处理输入的数据。这种同步操作会在每次快照创建时引入延迟。\n\n我们完全可以在存储快照时，让 operator 继续处理数据，让快照存储在后台异步运行。为了做到这一点，operator 必须能够生成一个后续修改不影响之前状态的状态对象。例如 RocksDB 中使用的写时复制（ copy-on-write ）类型的数据结构。\n\n接收到输入的 barrier 时，operator 异步快照复制出的状态。然后立即发射 barrier 到输出流，继续正常的流处理。一旦后台异步快照完成，它就会向 checkpoint coordinator（JobManager）确认 checkpoint 完成。现在 checkpoint 完成的充分条件是：所有 sink 接收到了 barrier，所有有状态 operator 都确认完成了状态备份（可能会比 sink 接收到 barrier 晚）。\n更多状态快照参见：state backends\n\n## Recovery\n在这种容错机制下的错误回复很明显：一旦遇到故障，Flink 选择最近一个完成的 checkpoint k。系统重新部署整个分布式数据流，重置所有 operator 的状态到 checkpoint k。数据源被置为从 Sk 位置读取。例如在 Apache Kafka 中，意味着让消费者从 Sk 处偏移开始读取。\n\n如果是增量快照，operator 需要从最新的全量快照回复，然后对此状态进行一系列增量更新。\n## Operator Snapshot Implementation\n当 operator 快照创建时有两部分操作：同步操作和异步操作。\n\noperator 和后端存储将快照以 Java FutureTask 的方式提供。这个 task 包含了同步操作已经完成，异步操作还在等待的状态（state）。异步操作在后台线程中被执行。\n\n完全同步的 operator 返回一个已经完成的 FutureTask 。如果异步操作需要执行，FutureTask 中的 run() 方法会被调用。\n\n为了释放流和其他资源的消耗，可以取消这些 task。","source":"_posts/Apache-Flink-官方文档翻译之-容错机制.md","raw":"title: Apache Flink 官方文档翻译之 容错机制\nauthor: Master.TJ\ndate: 2018-05-29 16:32:59\ntags:\n---\n## Introduce\nApache Flink 提供了可以恢复数据流应用到一致状态的容错机制。确保在发生故障时，程序的每条记录只会作用于状态一次（exactly-once），当然也可以降级为至少一次（at-least-once）。\n\n容错机制通过持续创建分布式数据流的快照来实现。对于状态占用空间小的流应用，这些快照非常轻量，可以高频率创建而对性能影响很小。流计算应用的状态保存在一个可配置的环境，如：master 节点或者 HDFS上。\n\n在遇到程序故障时（如机器、网络、软件等故障），Flink 停止分布式数据流。系统重启所有 operator ，重置其到最近成功的 checkpoint。输入重置到相应的状态快照位置。保证被重启的并行数据流中处理的任何一个 record 都不是 checkpoint 状态之前的一部分。\n\n注意：为了容错机制生效，数据源（例如 queue 或者 broker）需要能重放数据流。Apache Kafka 有这个特性，Flink 中 Kafka 的 connector 利用了这个功能。\n\n注意：由于 Flink 的 checkpoint 是通过分布式快照实现的，接下来我们将 snapshot 和 checkpoint 这两个词交替使用。\n## Checkpointing\n\nFlink 容错机制的核心就是持续创建分布式数据流及其状态的一致快照。这些快照在系统遇到故障时，充当可以回退的一致性检查点（checkpoint）。Lightweight Asynchronous Snapshots for Distributed Dataflows 描述了Flink 创建快照的机制。此论文是受分布式快照算法 Chandy-Lamport 启发，并针对 Flink 执行模型量身定制。\n## Barriers\n\nFlink 分布式快照的核心概念之一就是数据栅栏（barrier）。这些 barrier 被插入到数据流中，作为数据流的一部分和数据一起向下流动。Barrier 不会干扰正常数据，数据流严格有序。一个 barrier 把数据流分割成两部分：一部分进入到当前快照，另一部分进入下一个快照。每一个 barrier 都带有快照 ID，并且 barrier 之前的数据都进入了此快照。Barrier 不会干扰数据流处理，所以非常轻量。多个不同快照的多个 barrier 会在流中同时出现，即多个快照可能同时创建。\n\n![upload successful](\\blog\\images\\pasted-50.png)\nBarrier 在数据源端插入，当 snapshot n 的 barrier 插入后，系统会记录当前 snapshot 位置值 n (用Sn表示)。例如，在 Apache Kafka 中，这个变量表示某个分区中最后一条数据的偏移量。这个位置值 Sn 会被发送到一个称为 checkpoint coordinator 的模块。(即 Flink 的 JobManager).\n\n然后 barrier 继续往下流动，当一个 operator 从其输入流接收到所有标识 snapshot n 的 barrier 时，它会向其所有输出流插入一个标识 snapshot n 的 barrier。当 sink operator （DAG 流的终点）从其输入流接收到所有 barrier n 时，它向 the checkpoint coordinator 确认 snapshot n 已完成。当所有 sink 都确认了这个快照，快照就被标识为完成。\n\n![upload successful](\\blog\\images\\pasted-51.png)\n接收超过一个输入流的 operator 需要基于 barrier 对齐（align）输入。参见上图：\n\n1. operator 只要一接收到某个输入流的 barrier n，它就不能继续处理此数据流后续的数据，直到 operator 接收到其余流的 barrier n。否则会将属于 snapshot n 的数据和 snapshot n+1的搞混\n2. barrier n 所属的数据流先不处理，从这些数据流中接收到的数据被放入接收缓存里（input buffer）\n3. 当从最后一个流中提取到 barrier n 时，operator 会发射出所有等待向后发送的数据，然后发射snapshot n 所属的 barrier\n4. 经过以上步骤，operator 恢复所有输入流数据的处理，优先处理输入缓存中的数据\n\n## State\noperator 包含任何形式的状态，这些状态都必须包含在快照中。状态有很多种形式：\n\n* 用户自定义状态：由 transformation 函数例如（ map() 或者 filter())直接创建或者修改的状态。用户自定义状态可以是：转换函数中的 Java 对象的一个简单变量或者函数关联的 key/value 状态。参见 State in Streaming Applications\n\n* 系统状态：这种状态是指作为 operator 计算中一部分缓存数据。典型例子就是： 窗口缓存（window buffers），系统收集窗口对应数据到其中，直到窗口计算和发射。\n\noperator 在收到所有输入数据流中的 barrier 之后，在发射 barrier 到其输出流之前对其状态进行快照。此时，在 barrier 之前的数据对状态的更新已经完成，不会再依赖 barrier 之前数据。由于快照可能非常大，所以后端存储系统可配置。默认是存储到 JobManager 的内存中，但是对于生产系统，需要配置成一个可靠的分布式存储系统（例如 HDFS）。状态存储完成后，operator 会确认其 checkpoint 完成，发射出 barrier 到后续输出流。\n快照现在包含了：\n\n* 对于并行输入数据源：快照创建时数据流中的位置偏移\n\n* 对于 operator：存储在快照中的状态指针\n\n![upload successful](\\blog\\images\\pasted-52.png)\n\n## Exactly Once vs. At Least Once\n对齐操作可能会对流程序增加延迟。通常，这种额外的延迟在几毫秒的数量级，但是我们也遇到过延迟显著增加的异常情况。针对那些需要对所有输入都保持毫秒级的应用，Flink 提供了在 checkpoint 时关闭对齐的方法。当 operator 接收到一个 barrier 时，就会打一个快照，而不会等待其他 barrier。\n\n跳过对齐操作使得即使在 barrier 到达时，Operator 依然继续处理输入。这就是说：operator 在 checkpoint n 创建之前，继续处理属于 checkpoint n+1 的数据。所以当异常恢复时，这部分数据就会重复，因为它们被包含在了 checkpoint n 中，同时也会在之后再次被处理。\n\n注意：对齐操作只会发生在拥有多输入运算（join)或者多个输出的 operator（重分区、分流）的场景下。所以，对于自由 map(), flatmap(), fliter() 等的并行操作即使在至少一次的模式中仍然会保证严格一次。\n\n## Asynchronous State Snapshots\n我们注意到上面描述的机制意味着当 operator 向后端存储快照时，会停止处理输入的数据。这种同步操作会在每次快照创建时引入延迟。\n\n我们完全可以在存储快照时，让 operator 继续处理数据，让快照存储在后台异步运行。为了做到这一点，operator 必须能够生成一个后续修改不影响之前状态的状态对象。例如 RocksDB 中使用的写时复制（ copy-on-write ）类型的数据结构。\n\n接收到输入的 barrier 时，operator 异步快照复制出的状态。然后立即发射 barrier 到输出流，继续正常的流处理。一旦后台异步快照完成，它就会向 checkpoint coordinator（JobManager）确认 checkpoint 完成。现在 checkpoint 完成的充分条件是：所有 sink 接收到了 barrier，所有有状态 operator 都确认完成了状态备份（可能会比 sink 接收到 barrier 晚）。\n更多状态快照参见：state backends\n\n## Recovery\n在这种容错机制下的错误回复很明显：一旦遇到故障，Flink 选择最近一个完成的 checkpoint k。系统重新部署整个分布式数据流，重置所有 operator 的状态到 checkpoint k。数据源被置为从 Sk 位置读取。例如在 Apache Kafka 中，意味着让消费者从 Sk 处偏移开始读取。\n\n如果是增量快照，operator 需要从最新的全量快照回复，然后对此状态进行一系列增量更新。\n## Operator Snapshot Implementation\n当 operator 快照创建时有两部分操作：同步操作和异步操作。\n\noperator 和后端存储将快照以 Java FutureTask 的方式提供。这个 task 包含了同步操作已经完成，异步操作还在等待的状态（state）。异步操作在后台线程中被执行。\n\n完全同步的 operator 返回一个已经完成的 FutureTask 。如果异步操作需要执行，FutureTask 中的 run() 方法会被调用。\n\n为了释放流和其他资源的消耗，可以取消这些 task。","slug":"Apache-Flink-官方文档翻译之-容错机制","published":1,"updated":"2024-05-08T19:47:58.625Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u61w0003doy97fnqbho6","content":"<h2 id=\"Introduce\"><a href=\"#Introduce\" class=\"headerlink\" title=\"Introduce\"></a>Introduce</h2><p>Apache Flink 提供了可以恢复数据流应用到一致状态的容错机制。确保在发生故障时，程序的每条记录只会作用于状态一次（exactly-once），当然也可以降级为至少一次（at-least-once）。</p>\n<p>容错机制通过持续创建分布式数据流的快照来实现。对于状态占用空间小的流应用，这些快照非常轻量，可以高频率创建而对性能影响很小。流计算应用的状态保存在一个可配置的环境，如：master 节点或者 HDFS上。</p>\n<p>在遇到程序故障时（如机器、网络、软件等故障），Flink 停止分布式数据流。系统重启所有 operator ，重置其到最近成功的 checkpoint。输入重置到相应的状态快照位置。保证被重启的并行数据流中处理的任何一个 record 都不是 checkpoint 状态之前的一部分。</p>\n<p>注意：为了容错机制生效，数据源（例如 queue 或者 broker）需要能重放数据流。Apache Kafka 有这个特性，Flink 中 Kafka 的 connector 利用了这个功能。</p>\n<p>注意：由于 Flink 的 checkpoint 是通过分布式快照实现的，接下来我们将 snapshot 和 checkpoint 这两个词交替使用。</p>\n<h2 id=\"Checkpointing\"><a href=\"#Checkpointing\" class=\"headerlink\" title=\"Checkpointing\"></a>Checkpointing</h2><p>Flink 容错机制的核心就是持续创建分布式数据流及其状态的一致快照。这些快照在系统遇到故障时，充当可以回退的一致性检查点（checkpoint）。Lightweight Asynchronous Snapshots for Distributed Dataflows 描述了Flink 创建快照的机制。此论文是受分布式快照算法 Chandy-Lamport 启发，并针对 Flink 执行模型量身定制。</p>\n<h2 id=\"Barriers\"><a href=\"#Barriers\" class=\"headerlink\" title=\"Barriers\"></a>Barriers</h2><p>Flink 分布式快照的核心概念之一就是数据栅栏（barrier）。这些 barrier 被插入到数据流中，作为数据流的一部分和数据一起向下流动。Barrier 不会干扰正常数据，数据流严格有序。一个 barrier 把数据流分割成两部分：一部分进入到当前快照，另一部分进入下一个快照。每一个 barrier 都带有快照 ID，并且 barrier 之前的数据都进入了此快照。Barrier 不会干扰数据流处理，所以非常轻量。多个不同快照的多个 barrier 会在流中同时出现，即多个快照可能同时创建。</p>\n<p><img src=\"\\blog\\images\\pasted-50.png\" alt=\"upload successful\"><br>Barrier 在数据源端插入，当 snapshot n 的 barrier 插入后，系统会记录当前 snapshot 位置值 n (用Sn表示)。例如，在 Apache Kafka 中，这个变量表示某个分区中最后一条数据的偏移量。这个位置值 Sn 会被发送到一个称为 checkpoint coordinator 的模块。(即 Flink 的 JobManager).</p>\n<p>然后 barrier 继续往下流动，当一个 operator 从其输入流接收到所有标识 snapshot n 的 barrier 时，它会向其所有输出流插入一个标识 snapshot n 的 barrier。当 sink operator （DAG 流的终点）从其输入流接收到所有 barrier n 时，它向 the checkpoint coordinator 确认 snapshot n 已完成。当所有 sink 都确认了这个快照，快照就被标识为完成。</p>\n<p><img src=\"\\blog\\images\\pasted-51.png\" alt=\"upload successful\"><br>接收超过一个输入流的 operator 需要基于 barrier 对齐（align）输入。参见上图：</p>\n<ol>\n<li>operator 只要一接收到某个输入流的 barrier n，它就不能继续处理此数据流后续的数据，直到 operator 接收到其余流的 barrier n。否则会将属于 snapshot n 的数据和 snapshot n+1的搞混</li>\n<li>barrier n 所属的数据流先不处理，从这些数据流中接收到的数据被放入接收缓存里（input buffer）</li>\n<li>当从最后一个流中提取到 barrier n 时，operator 会发射出所有等待向后发送的数据，然后发射snapshot n 所属的 barrier</li>\n<li>经过以上步骤，operator 恢复所有输入流数据的处理，优先处理输入缓存中的数据</li>\n</ol>\n<h2 id=\"State\"><a href=\"#State\" class=\"headerlink\" title=\"State\"></a>State</h2><p>operator 包含任何形式的状态，这些状态都必须包含在快照中。状态有很多种形式：</p>\n<ul>\n<li><p>用户自定义状态：由 transformation 函数例如（ map() 或者 filter())直接创建或者修改的状态。用户自定义状态可以是：转换函数中的 Java 对象的一个简单变量或者函数关联的 key/value 状态。参见 State in Streaming Applications</p>\n</li>\n<li><p>系统状态：这种状态是指作为 operator 计算中一部分缓存数据。典型例子就是： 窗口缓存（window buffers），系统收集窗口对应数据到其中，直到窗口计算和发射。</p>\n</li>\n</ul>\n<p>operator 在收到所有输入数据流中的 barrier 之后，在发射 barrier 到其输出流之前对其状态进行快照。此时，在 barrier 之前的数据对状态的更新已经完成，不会再依赖 barrier 之前数据。由于快照可能非常大，所以后端存储系统可配置。默认是存储到 JobManager 的内存中，但是对于生产系统，需要配置成一个可靠的分布式存储系统（例如 HDFS）。状态存储完成后，operator 会确认其 checkpoint 完成，发射出 barrier 到后续输出流。<br>快照现在包含了：</p>\n<ul>\n<li><p>对于并行输入数据源：快照创建时数据流中的位置偏移</p>\n</li>\n<li><p>对于 operator：存储在快照中的状态指针</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-52.png\" alt=\"upload successful\"></p>\n<h2 id=\"Exactly-Once-vs-At-Least-Once\"><a href=\"#Exactly-Once-vs-At-Least-Once\" class=\"headerlink\" title=\"Exactly Once vs. At Least Once\"></a>Exactly Once vs. At Least Once</h2><p>对齐操作可能会对流程序增加延迟。通常，这种额外的延迟在几毫秒的数量级，但是我们也遇到过延迟显著增加的异常情况。针对那些需要对所有输入都保持毫秒级的应用，Flink 提供了在 checkpoint 时关闭对齐的方法。当 operator 接收到一个 barrier 时，就会打一个快照，而不会等待其他 barrier。</p>\n<p>跳过对齐操作使得即使在 barrier 到达时，Operator 依然继续处理输入。这就是说：operator 在 checkpoint n 创建之前，继续处理属于 checkpoint n+1 的数据。所以当异常恢复时，这部分数据就会重复，因为它们被包含在了 checkpoint n 中，同时也会在之后再次被处理。</p>\n<p>注意：对齐操作只会发生在拥有多输入运算（join)或者多个输出的 operator（重分区、分流）的场景下。所以，对于自由 map(), flatmap(), fliter() 等的并行操作即使在至少一次的模式中仍然会保证严格一次。</p>\n<h2 id=\"Asynchronous-State-Snapshots\"><a href=\"#Asynchronous-State-Snapshots\" class=\"headerlink\" title=\"Asynchronous State Snapshots\"></a>Asynchronous State Snapshots</h2><p>我们注意到上面描述的机制意味着当 operator 向后端存储快照时，会停止处理输入的数据。这种同步操作会在每次快照创建时引入延迟。</p>\n<p>我们完全可以在存储快照时，让 operator 继续处理数据，让快照存储在后台异步运行。为了做到这一点，operator 必须能够生成一个后续修改不影响之前状态的状态对象。例如 RocksDB 中使用的写时复制（ copy-on-write ）类型的数据结构。</p>\n<p>接收到输入的 barrier 时，operator 异步快照复制出的状态。然后立即发射 barrier 到输出流，继续正常的流处理。一旦后台异步快照完成，它就会向 checkpoint coordinator（JobManager）确认 checkpoint 完成。现在 checkpoint 完成的充分条件是：所有 sink 接收到了 barrier，所有有状态 operator 都确认完成了状态备份（可能会比 sink 接收到 barrier 晚）。<br>更多状态快照参见：state backends</p>\n<h2 id=\"Recovery\"><a href=\"#Recovery\" class=\"headerlink\" title=\"Recovery\"></a>Recovery</h2><p>在这种容错机制下的错误回复很明显：一旦遇到故障，Flink 选择最近一个完成的 checkpoint k。系统重新部署整个分布式数据流，重置所有 operator 的状态到 checkpoint k。数据源被置为从 Sk 位置读取。例如在 Apache Kafka 中，意味着让消费者从 Sk 处偏移开始读取。</p>\n<p>如果是增量快照，operator 需要从最新的全量快照回复，然后对此状态进行一系列增量更新。</p>\n<h2 id=\"Operator-Snapshot-Implementation\"><a href=\"#Operator-Snapshot-Implementation\" class=\"headerlink\" title=\"Operator Snapshot Implementation\"></a>Operator Snapshot Implementation</h2><p>当 operator 快照创建时有两部分操作：同步操作和异步操作。</p>\n<p>operator 和后端存储将快照以 Java FutureTask 的方式提供。这个 task 包含了同步操作已经完成，异步操作还在等待的状态（state）。异步操作在后台线程中被执行。</p>\n<p>完全同步的 operator 返回一个已经完成的 FutureTask 。如果异步操作需要执行，FutureTask 中的 run() 方法会被调用。</p>\n<p>为了释放流和其他资源的消耗，可以取消这些 task。</p>\n","excerpt":"","more":"<h2 id=\"Introduce\"><a href=\"#Introduce\" class=\"headerlink\" title=\"Introduce\"></a>Introduce</h2><p>Apache Flink 提供了可以恢复数据流应用到一致状态的容错机制。确保在发生故障时，程序的每条记录只会作用于状态一次（exactly-once），当然也可以降级为至少一次（at-least-once）。</p>\n<p>容错机制通过持续创建分布式数据流的快照来实现。对于状态占用空间小的流应用，这些快照非常轻量，可以高频率创建而对性能影响很小。流计算应用的状态保存在一个可配置的环境，如：master 节点或者 HDFS上。</p>\n<p>在遇到程序故障时（如机器、网络、软件等故障），Flink 停止分布式数据流。系统重启所有 operator ，重置其到最近成功的 checkpoint。输入重置到相应的状态快照位置。保证被重启的并行数据流中处理的任何一个 record 都不是 checkpoint 状态之前的一部分。</p>\n<p>注意：为了容错机制生效，数据源（例如 queue 或者 broker）需要能重放数据流。Apache Kafka 有这个特性，Flink 中 Kafka 的 connector 利用了这个功能。</p>\n<p>注意：由于 Flink 的 checkpoint 是通过分布式快照实现的，接下来我们将 snapshot 和 checkpoint 这两个词交替使用。</p>\n<h2 id=\"Checkpointing\"><a href=\"#Checkpointing\" class=\"headerlink\" title=\"Checkpointing\"></a>Checkpointing</h2><p>Flink 容错机制的核心就是持续创建分布式数据流及其状态的一致快照。这些快照在系统遇到故障时，充当可以回退的一致性检查点（checkpoint）。Lightweight Asynchronous Snapshots for Distributed Dataflows 描述了Flink 创建快照的机制。此论文是受分布式快照算法 Chandy-Lamport 启发，并针对 Flink 执行模型量身定制。</p>\n<h2 id=\"Barriers\"><a href=\"#Barriers\" class=\"headerlink\" title=\"Barriers\"></a>Barriers</h2><p>Flink 分布式快照的核心概念之一就是数据栅栏（barrier）。这些 barrier 被插入到数据流中，作为数据流的一部分和数据一起向下流动。Barrier 不会干扰正常数据，数据流严格有序。一个 barrier 把数据流分割成两部分：一部分进入到当前快照，另一部分进入下一个快照。每一个 barrier 都带有快照 ID，并且 barrier 之前的数据都进入了此快照。Barrier 不会干扰数据流处理，所以非常轻量。多个不同快照的多个 barrier 会在流中同时出现，即多个快照可能同时创建。</p>\n<p><img src=\"\\blog\\images\\pasted-50.png\" alt=\"upload successful\"><br>Barrier 在数据源端插入，当 snapshot n 的 barrier 插入后，系统会记录当前 snapshot 位置值 n (用Sn表示)。例如，在 Apache Kafka 中，这个变量表示某个分区中最后一条数据的偏移量。这个位置值 Sn 会被发送到一个称为 checkpoint coordinator 的模块。(即 Flink 的 JobManager).</p>\n<p>然后 barrier 继续往下流动，当一个 operator 从其输入流接收到所有标识 snapshot n 的 barrier 时，它会向其所有输出流插入一个标识 snapshot n 的 barrier。当 sink operator （DAG 流的终点）从其输入流接收到所有 barrier n 时，它向 the checkpoint coordinator 确认 snapshot n 已完成。当所有 sink 都确认了这个快照，快照就被标识为完成。</p>\n<p><img src=\"\\blog\\images\\pasted-51.png\" alt=\"upload successful\"><br>接收超过一个输入流的 operator 需要基于 barrier 对齐（align）输入。参见上图：</p>\n<ol>\n<li>operator 只要一接收到某个输入流的 barrier n，它就不能继续处理此数据流后续的数据，直到 operator 接收到其余流的 barrier n。否则会将属于 snapshot n 的数据和 snapshot n+1的搞混</li>\n<li>barrier n 所属的数据流先不处理，从这些数据流中接收到的数据被放入接收缓存里（input buffer）</li>\n<li>当从最后一个流中提取到 barrier n 时，operator 会发射出所有等待向后发送的数据，然后发射snapshot n 所属的 barrier</li>\n<li>经过以上步骤，operator 恢复所有输入流数据的处理，优先处理输入缓存中的数据</li>\n</ol>\n<h2 id=\"State\"><a href=\"#State\" class=\"headerlink\" title=\"State\"></a>State</h2><p>operator 包含任何形式的状态，这些状态都必须包含在快照中。状态有很多种形式：</p>\n<ul>\n<li><p>用户自定义状态：由 transformation 函数例如（ map() 或者 filter())直接创建或者修改的状态。用户自定义状态可以是：转换函数中的 Java 对象的一个简单变量或者函数关联的 key/value 状态。参见 State in Streaming Applications</p>\n</li>\n<li><p>系统状态：这种状态是指作为 operator 计算中一部分缓存数据。典型例子就是： 窗口缓存（window buffers），系统收集窗口对应数据到其中，直到窗口计算和发射。</p>\n</li>\n</ul>\n<p>operator 在收到所有输入数据流中的 barrier 之后，在发射 barrier 到其输出流之前对其状态进行快照。此时，在 barrier 之前的数据对状态的更新已经完成，不会再依赖 barrier 之前数据。由于快照可能非常大，所以后端存储系统可配置。默认是存储到 JobManager 的内存中，但是对于生产系统，需要配置成一个可靠的分布式存储系统（例如 HDFS）。状态存储完成后，operator 会确认其 checkpoint 完成，发射出 barrier 到后续输出流。<br>快照现在包含了：</p>\n<ul>\n<li><p>对于并行输入数据源：快照创建时数据流中的位置偏移</p>\n</li>\n<li><p>对于 operator：存储在快照中的状态指针</p>\n</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-52.png\" alt=\"upload successful\"></p>\n<h2 id=\"Exactly-Once-vs-At-Least-Once\"><a href=\"#Exactly-Once-vs-At-Least-Once\" class=\"headerlink\" title=\"Exactly Once vs. At Least Once\"></a>Exactly Once vs. At Least Once</h2><p>对齐操作可能会对流程序增加延迟。通常，这种额外的延迟在几毫秒的数量级，但是我们也遇到过延迟显著增加的异常情况。针对那些需要对所有输入都保持毫秒级的应用，Flink 提供了在 checkpoint 时关闭对齐的方法。当 operator 接收到一个 barrier 时，就会打一个快照，而不会等待其他 barrier。</p>\n<p>跳过对齐操作使得即使在 barrier 到达时，Operator 依然继续处理输入。这就是说：operator 在 checkpoint n 创建之前，继续处理属于 checkpoint n+1 的数据。所以当异常恢复时，这部分数据就会重复，因为它们被包含在了 checkpoint n 中，同时也会在之后再次被处理。</p>\n<p>注意：对齐操作只会发生在拥有多输入运算（join)或者多个输出的 operator（重分区、分流）的场景下。所以，对于自由 map(), flatmap(), fliter() 等的并行操作即使在至少一次的模式中仍然会保证严格一次。</p>\n<h2 id=\"Asynchronous-State-Snapshots\"><a href=\"#Asynchronous-State-Snapshots\" class=\"headerlink\" title=\"Asynchronous State Snapshots\"></a>Asynchronous State Snapshots</h2><p>我们注意到上面描述的机制意味着当 operator 向后端存储快照时，会停止处理输入的数据。这种同步操作会在每次快照创建时引入延迟。</p>\n<p>我们完全可以在存储快照时，让 operator 继续处理数据，让快照存储在后台异步运行。为了做到这一点，operator 必须能够生成一个后续修改不影响之前状态的状态对象。例如 RocksDB 中使用的写时复制（ copy-on-write ）类型的数据结构。</p>\n<p>接收到输入的 barrier 时，operator 异步快照复制出的状态。然后立即发射 barrier 到输出流，继续正常的流处理。一旦后台异步快照完成，它就会向 checkpoint coordinator（JobManager）确认 checkpoint 完成。现在 checkpoint 完成的充分条件是：所有 sink 接收到了 barrier，所有有状态 operator 都确认完成了状态备份（可能会比 sink 接收到 barrier 晚）。<br>更多状态快照参见：state backends</p>\n<h2 id=\"Recovery\"><a href=\"#Recovery\" class=\"headerlink\" title=\"Recovery\"></a>Recovery</h2><p>在这种容错机制下的错误回复很明显：一旦遇到故障，Flink 选择最近一个完成的 checkpoint k。系统重新部署整个分布式数据流，重置所有 operator 的状态到 checkpoint k。数据源被置为从 Sk 位置读取。例如在 Apache Kafka 中，意味着让消费者从 Sk 处偏移开始读取。</p>\n<p>如果是增量快照，operator 需要从最新的全量快照回复，然后对此状态进行一系列增量更新。</p>\n<h2 id=\"Operator-Snapshot-Implementation\"><a href=\"#Operator-Snapshot-Implementation\" class=\"headerlink\" title=\"Operator Snapshot Implementation\"></a>Operator Snapshot Implementation</h2><p>当 operator 快照创建时有两部分操作：同步操作和异步操作。</p>\n<p>operator 和后端存储将快照以 Java FutureTask 的方式提供。这个 task 包含了同步操作已经完成，异步操作还在等待的状态（state）。异步操作在后台线程中被执行。</p>\n<p>完全同步的 operator 返回一个已经完成的 FutureTask 。如果异步操作需要执行，FutureTask 中的 run() 方法会被调用。</p>\n<p>为了释放流和其他资源的消耗，可以取消这些 task。</p>\n"},{"title":"Apache Flink 官方文档翻译之编程模型","author":"Master.TJ","date":"2018-05-29T08:49:24.000Z","_content":"## 抽象层次\nFlink 能够为流式计算或批处理应用提供多种层次的抽象接口。\n![upload successful](\\blog\\images\\pasted-53.png)\n* 最低级的抽象接口是状态化的数据流接口。这个接口是通过 ProcessFunction 集成到 数据流 API 中的。此类接口让用户可以使用连续的容错状态，并且可以不受限制地处理多个数据流中的事件。另外，用户也可以通过注册事件时间和时间处理回调函数的方法来实现复杂的计算程序。\n\n* 实际上，大部分程序通常会使用以数据流 API（有界/无界数据流）、数据集 API（有界数据集）为代表的核心 API，而并不会使用前述低级抽象接口。这些核心 API 为数据处理提供了大量的通用构建模块，包括用户定义的各种各样的变换、连接、聚集、窗口、状态等等。在编程语言中，这些 API 处理的数据类型通常会表现为相应的类的形式。\n\n由于数据流 API 集成了低级处理函数，因此可以通过数据流API为某些特定操作应用低级处理接口。此外，数据集 API 也为诸如循环、迭代之类的有界数据集提供了一些补充的编程原语。\n\n* 数据表 API 是一种以数据表为核心地声明式 DSL，能够动态地修改那些表征数据流的表。数据表 API 的工作模式是一种（扩展的）关系型模型：每个数据表都依附于一个 schema（类似于关系型数据库中的表结构），相应的 API 就可以实现很多类似的操作，例如 select，project，join，group by，aggregate，等等。数据表 API 程序定义的仅仅是如何在逻辑上实现各种程序操作，而不是直接指定程序代码运行的具体步骤。尽管数据表 API 可以通过各式各样的自定义函数进行扩展，但是它在表达能力上仍然比不上核心 API，不过数据表 API 的优势是在使用上更简练（相对于核心 API 可以减少很多代码）。此外，数据表 API 程序在运行之前也会使用一个优化器对程序进行优化。\n\n由于用户可以在数据表与数据流/数据集之间进行无缝切换，程序也可以混合使用数据表 API 和数据流/数据集 API。\n\n* Flink 提供的最高级接口是 SQL。这个层次的抽象接口和数据表 API 非常相似，包括语法和接口的表现能力，唯一的区别是通过 SQL 查询语言实现程序。实际上，SQL 抽象接口和数据表 API 的交互非常紧密，而且 SQL 查询也可以在数据表 API 中定义的表上执行。\n\n## 程序与数据流\nFlink 程序的基础构建单元是（数据）流与变换（注意，数据集 API 中使用的数据集也是一种内置的流，这一点我们以后会细说）。顾名思义，一个数据流就是一组数据记录组成的（可能永远不会停止的）流，而变换就是一种接受若干数据流作为输入，然后再输出结果数据流的过程。\n\nFlink 程序在运行的时候会被映射到数据流图中，这个数据流图就是由程序中的数据流和相应的变换操作组成的。数据流图开始于一个或多个数据源（source），结束于另外一些汇聚点（sink）。数据流图类似于有向无环图（DAG）。虽然可以通过迭代构造器生成某些特殊形式的环，但为了简化说明，大部分情况下我们不考虑这种结构。\n\n![upload successful](\\blog\\images\\pasted-54.png)\n\n通常情况下程序中的变换和数据流图中的运算符是一一对应的。不过有的时候也会出现一个变换由多个变换运算符组成的情况。\n\n数据源和汇聚点的相关文档在数据流连接器和批处理连接器的说明文档中。变换的相关文档在数据流变换和数据集变换的说明文档中。\n\n## 并发数据流图\n本质上说，Flink 程序是分布式、并发执行的。在程序运行过程中，一个数据流可能会有一个或多个流分区，而一个运算符也可能会有一个或多个运算子任务。每个运算子任务与另外一个运算子任务之间都是相互独立的，他们是在不同的线程中运行的，甚至有可能所运行的机器或者容器都完全不同。\n\n运算子任务的数量由运算符的并发数确定。数据流的并发数就是它所生成的运算符的个数。程序中不同的运算符可以有不同等级的并发量。\n\n![upload successful](\\blog\\images\\pasted-55.png)\n\n在两个运算符之间传输数据流既可以使用一对一的直接型模式，也可以使用重分发模式：\n\n1. 一对一 模式的数据流（例如上图中 Source 和 map() 运算符之间的数据流）中元素的分组和顺序会保持不变，也就是说，map() 运算符的子任务[1]所看见的元素与 Source 运算符的子任务[1]所生成的元素的顺序完全一致。\n\n2. 分发 模式的数据流（例如上图中 map() 和 keyBy/window 运算符之间的数据流，以及 keyby/window 和 Sink 运算符之间的数据流）会改变数据流所在的分区。根据所选的变换的不同，每个运算子任务会将数据发送到不同的目标子任务中去。keyBy()（通过对 key 进行哈希计算来重分区）、boradcast() 和 rebalance()（随机重分区）就是重分发模式的几个例子。在重分发模式下，元素之间的先后次序在每对发送——接收子任务（例如 map() 的子任务[1]和 keyBy/window 的子任务[2]）中是保持不变的。因此，在上图的例子中，尽管在子任务之间每个 key 的顺序都是确定的，但是由于程序的并发过程引入了不确定性，最终到达 Sink 的元素顺序就不能保证与一开始的元素顺序完全一致。\n\n关于配置并发的更多信息可以参阅并发执行文档。\n\n## 窗口\n\n计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。\n\n窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。\n计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。\n\n窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。\n\n![upload successful](\\blog\\images\\pasted-56.png)\n这篇文章介绍了很多窗口的例子。另外，也可以查阅窗口文档了解更多内容。\n\n## 时间\n流式计算程序中的时间概念（例如在定义窗口时经常会用到时间）有以下几种含义：\n\n* 事件时间（Event Time），是指事件创建时的时间。这种类型时间一般会表示为事件的时间戳，再通过事件生成传感器或者事件生成服务等附到事件中。Flink 通过时间戳指定器获取事件的时间戳。\n* 摄入时间（Ingestion Time），是指事件在源运算符中进入Flink的数据流的时间。\n* 处理时间（Processing Time），是指运算符在执行时间类操作时的本地时间。\n\n![upload successful](\\blog\\images\\pasted-57.png)\n\n## 有状态操作\n虽然数据流中有很多运算符每次只需要考虑当前所处理的唯一的事件（例如事件分析器），但是仍然存在很多需要记录多个事件的信息的场景（窗口操作符就是个很好的例子），这种需要记录信息的操作就称为有状态的操作。\n\n有状态操作的状态可以理解成是以键值对（key/value）形式储存的。这个状态的分区和分发过程是和数据流严格绑定在一起的，随后有状态运算符读取数据流就可以获取状态了。因此，在 keyBy() 函数执行之后，只能在带键的数据流中访问 key/value 状态，而且也只能获取与当前事件的主键相对应的值。数据流的键和值的对应确保了所有状态更新都是本地操作，同时也保证了事务的一致性。这个对应也使得Flink可以透明地重分发状态，并调整数据流地分区。\n\n有关状态地更多内容请参阅有状态操作文档。\n## 容错性检查点\n\nFlink 通过数据重发和校验检查机制相结合的方式实现了容错能力。检查点和运算符中的相应的状态一样直接关联到输入数据流中的特定的某个点。为了维护数据一致性（一次处理的语义），可以让数据流从检查点恢复，这是通过恢复运算符的状态并对检查点对应的事件进行重发的方式实现的。\n\n检查点区间是对程序的容错能力与恢复时间（需要重发的事件数量）的折衷。\n\n容错区间文档中有关于Flink如何处理检查点以及其他相关主题的详细说明。更多关于配置启用检查点的资料请参阅检查点API文档。\n\n## 批处理操作\n\nFlink 将批处理程序看成流式计算程序的一种有界数据流（即元素数量是可数的）的特例。这里，数据集（DataSet）也被看作一种数据流。因此，上面流式计算程序中的很多概念也能应用到批处理程序中，除了以下几处不同：\n\n批处理程序的容错性不使用检查点机制。由于输入数据本身是有界的，批处理的恢复是通过完全重发所有数据流实现的。这样，恢复过程中的开销可能更大一些，但是由于没有了检查点，正常处理过程的开销反而更小了点。\n数据集API中的有状态操作没有使用键/值（key/value）索引结构，而是使用了简化的内存/外存数据结构。\n数据集API引入了特殊的同步（基于超步算法的）迭代接口，该接口仅能用于有界数据流。更多内容请参考迭代文档。\n\n\n","source":"_posts/Apache-Flink-官方文档翻译之编程模型.md","raw":"title: Apache Flink 官方文档翻译之编程模型\nauthor: Master.TJ\ndate: 2018-05-29 16:49:24\ntags:\n---\n## 抽象层次\nFlink 能够为流式计算或批处理应用提供多种层次的抽象接口。\n![upload successful](\\blog\\images\\pasted-53.png)\n* 最低级的抽象接口是状态化的数据流接口。这个接口是通过 ProcessFunction 集成到 数据流 API 中的。此类接口让用户可以使用连续的容错状态，并且可以不受限制地处理多个数据流中的事件。另外，用户也可以通过注册事件时间和时间处理回调函数的方法来实现复杂的计算程序。\n\n* 实际上，大部分程序通常会使用以数据流 API（有界/无界数据流）、数据集 API（有界数据集）为代表的核心 API，而并不会使用前述低级抽象接口。这些核心 API 为数据处理提供了大量的通用构建模块，包括用户定义的各种各样的变换、连接、聚集、窗口、状态等等。在编程语言中，这些 API 处理的数据类型通常会表现为相应的类的形式。\n\n由于数据流 API 集成了低级处理函数，因此可以通过数据流API为某些特定操作应用低级处理接口。此外，数据集 API 也为诸如循环、迭代之类的有界数据集提供了一些补充的编程原语。\n\n* 数据表 API 是一种以数据表为核心地声明式 DSL，能够动态地修改那些表征数据流的表。数据表 API 的工作模式是一种（扩展的）关系型模型：每个数据表都依附于一个 schema（类似于关系型数据库中的表结构），相应的 API 就可以实现很多类似的操作，例如 select，project，join，group by，aggregate，等等。数据表 API 程序定义的仅仅是如何在逻辑上实现各种程序操作，而不是直接指定程序代码运行的具体步骤。尽管数据表 API 可以通过各式各样的自定义函数进行扩展，但是它在表达能力上仍然比不上核心 API，不过数据表 API 的优势是在使用上更简练（相对于核心 API 可以减少很多代码）。此外，数据表 API 程序在运行之前也会使用一个优化器对程序进行优化。\n\n由于用户可以在数据表与数据流/数据集之间进行无缝切换，程序也可以混合使用数据表 API 和数据流/数据集 API。\n\n* Flink 提供的最高级接口是 SQL。这个层次的抽象接口和数据表 API 非常相似，包括语法和接口的表现能力，唯一的区别是通过 SQL 查询语言实现程序。实际上，SQL 抽象接口和数据表 API 的交互非常紧密，而且 SQL 查询也可以在数据表 API 中定义的表上执行。\n\n## 程序与数据流\nFlink 程序的基础构建单元是（数据）流与变换（注意，数据集 API 中使用的数据集也是一种内置的流，这一点我们以后会细说）。顾名思义，一个数据流就是一组数据记录组成的（可能永远不会停止的）流，而变换就是一种接受若干数据流作为输入，然后再输出结果数据流的过程。\n\nFlink 程序在运行的时候会被映射到数据流图中，这个数据流图就是由程序中的数据流和相应的变换操作组成的。数据流图开始于一个或多个数据源（source），结束于另外一些汇聚点（sink）。数据流图类似于有向无环图（DAG）。虽然可以通过迭代构造器生成某些特殊形式的环，但为了简化说明，大部分情况下我们不考虑这种结构。\n\n![upload successful](\\blog\\images\\pasted-54.png)\n\n通常情况下程序中的变换和数据流图中的运算符是一一对应的。不过有的时候也会出现一个变换由多个变换运算符组成的情况。\n\n数据源和汇聚点的相关文档在数据流连接器和批处理连接器的说明文档中。变换的相关文档在数据流变换和数据集变换的说明文档中。\n\n## 并发数据流图\n本质上说，Flink 程序是分布式、并发执行的。在程序运行过程中，一个数据流可能会有一个或多个流分区，而一个运算符也可能会有一个或多个运算子任务。每个运算子任务与另外一个运算子任务之间都是相互独立的，他们是在不同的线程中运行的，甚至有可能所运行的机器或者容器都完全不同。\n\n运算子任务的数量由运算符的并发数确定。数据流的并发数就是它所生成的运算符的个数。程序中不同的运算符可以有不同等级的并发量。\n\n![upload successful](\\blog\\images\\pasted-55.png)\n\n在两个运算符之间传输数据流既可以使用一对一的直接型模式，也可以使用重分发模式：\n\n1. 一对一 模式的数据流（例如上图中 Source 和 map() 运算符之间的数据流）中元素的分组和顺序会保持不变，也就是说，map() 运算符的子任务[1]所看见的元素与 Source 运算符的子任务[1]所生成的元素的顺序完全一致。\n\n2. 分发 模式的数据流（例如上图中 map() 和 keyBy/window 运算符之间的数据流，以及 keyby/window 和 Sink 运算符之间的数据流）会改变数据流所在的分区。根据所选的变换的不同，每个运算子任务会将数据发送到不同的目标子任务中去。keyBy()（通过对 key 进行哈希计算来重分区）、boradcast() 和 rebalance()（随机重分区）就是重分发模式的几个例子。在重分发模式下，元素之间的先后次序在每对发送——接收子任务（例如 map() 的子任务[1]和 keyBy/window 的子任务[2]）中是保持不变的。因此，在上图的例子中，尽管在子任务之间每个 key 的顺序都是确定的，但是由于程序的并发过程引入了不确定性，最终到达 Sink 的元素顺序就不能保证与一开始的元素顺序完全一致。\n\n关于配置并发的更多信息可以参阅并发执行文档。\n\n## 窗口\n\n计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。\n\n窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。\n计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。\n\n窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。\n\n![upload successful](\\blog\\images\\pasted-56.png)\n这篇文章介绍了很多窗口的例子。另外，也可以查阅窗口文档了解更多内容。\n\n## 时间\n流式计算程序中的时间概念（例如在定义窗口时经常会用到时间）有以下几种含义：\n\n* 事件时间（Event Time），是指事件创建时的时间。这种类型时间一般会表示为事件的时间戳，再通过事件生成传感器或者事件生成服务等附到事件中。Flink 通过时间戳指定器获取事件的时间戳。\n* 摄入时间（Ingestion Time），是指事件在源运算符中进入Flink的数据流的时间。\n* 处理时间（Processing Time），是指运算符在执行时间类操作时的本地时间。\n\n![upload successful](\\blog\\images\\pasted-57.png)\n\n## 有状态操作\n虽然数据流中有很多运算符每次只需要考虑当前所处理的唯一的事件（例如事件分析器），但是仍然存在很多需要记录多个事件的信息的场景（窗口操作符就是个很好的例子），这种需要记录信息的操作就称为有状态的操作。\n\n有状态操作的状态可以理解成是以键值对（key/value）形式储存的。这个状态的分区和分发过程是和数据流严格绑定在一起的，随后有状态运算符读取数据流就可以获取状态了。因此，在 keyBy() 函数执行之后，只能在带键的数据流中访问 key/value 状态，而且也只能获取与当前事件的主键相对应的值。数据流的键和值的对应确保了所有状态更新都是本地操作，同时也保证了事务的一致性。这个对应也使得Flink可以透明地重分发状态，并调整数据流地分区。\n\n有关状态地更多内容请参阅有状态操作文档。\n## 容错性检查点\n\nFlink 通过数据重发和校验检查机制相结合的方式实现了容错能力。检查点和运算符中的相应的状态一样直接关联到输入数据流中的特定的某个点。为了维护数据一致性（一次处理的语义），可以让数据流从检查点恢复，这是通过恢复运算符的状态并对检查点对应的事件进行重发的方式实现的。\n\n检查点区间是对程序的容错能力与恢复时间（需要重发的事件数量）的折衷。\n\n容错区间文档中有关于Flink如何处理检查点以及其他相关主题的详细说明。更多关于配置启用检查点的资料请参阅检查点API文档。\n\n## 批处理操作\n\nFlink 将批处理程序看成流式计算程序的一种有界数据流（即元素数量是可数的）的特例。这里，数据集（DataSet）也被看作一种数据流。因此，上面流式计算程序中的很多概念也能应用到批处理程序中，除了以下几处不同：\n\n批处理程序的容错性不使用检查点机制。由于输入数据本身是有界的，批处理的恢复是通过完全重发所有数据流实现的。这样，恢复过程中的开销可能更大一些，但是由于没有了检查点，正常处理过程的开销反而更小了点。\n数据集API中的有状态操作没有使用键/值（key/value）索引结构，而是使用了简化的内存/外存数据结构。\n数据集API引入了特殊的同步（基于超步算法的）迭代接口，该接口仅能用于有界数据流。更多内容请参考迭代文档。\n\n\n","slug":"Apache-Flink-官方文档翻译之编程模型","published":1,"updated":"2024-05-08T19:47:58.625Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u61x0005doy9gbz2hl59","content":"<h2 id=\"抽象层次\"><a href=\"#抽象层次\" class=\"headerlink\" title=\"抽象层次\"></a>抽象层次</h2><p>Flink 能够为流式计算或批处理应用提供多种层次的抽象接口。<br><img src=\"\\blog\\images\\pasted-53.png\" alt=\"upload successful\"></p>\n<ul>\n<li><p>最低级的抽象接口是状态化的数据流接口。这个接口是通过 ProcessFunction 集成到 数据流 API 中的。此类接口让用户可以使用连续的容错状态，并且可以不受限制地处理多个数据流中的事件。另外，用户也可以通过注册事件时间和时间处理回调函数的方法来实现复杂的计算程序。</p>\n</li>\n<li><p>实际上，大部分程序通常会使用以数据流 API（有界/无界数据流）、数据集 API（有界数据集）为代表的核心 API，而并不会使用前述低级抽象接口。这些核心 API 为数据处理提供了大量的通用构建模块，包括用户定义的各种各样的变换、连接、聚集、窗口、状态等等。在编程语言中，这些 API 处理的数据类型通常会表现为相应的类的形式。</p>\n</li>\n</ul>\n<p>由于数据流 API 集成了低级处理函数，因此可以通过数据流API为某些特定操作应用低级处理接口。此外，数据集 API 也为诸如循环、迭代之类的有界数据集提供了一些补充的编程原语。</p>\n<ul>\n<li>数据表 API 是一种以数据表为核心地声明式 DSL，能够动态地修改那些表征数据流的表。数据表 API 的工作模式是一种（扩展的）关系型模型：每个数据表都依附于一个 schema（类似于关系型数据库中的表结构），相应的 API 就可以实现很多类似的操作，例如 select，project，join，group by，aggregate，等等。数据表 API 程序定义的仅仅是如何在逻辑上实现各种程序操作，而不是直接指定程序代码运行的具体步骤。尽管数据表 API 可以通过各式各样的自定义函数进行扩展，但是它在表达能力上仍然比不上核心 API，不过数据表 API 的优势是在使用上更简练（相对于核心 API 可以减少很多代码）。此外，数据表 API 程序在运行之前也会使用一个优化器对程序进行优化。</li>\n</ul>\n<p>由于用户可以在数据表与数据流/数据集之间进行无缝切换，程序也可以混合使用数据表 API 和数据流/数据集 API。</p>\n<ul>\n<li>Flink 提供的最高级接口是 SQL。这个层次的抽象接口和数据表 API 非常相似，包括语法和接口的表现能力，唯一的区别是通过 SQL 查询语言实现程序。实际上，SQL 抽象接口和数据表 API 的交互非常紧密，而且 SQL 查询也可以在数据表 API 中定义的表上执行。</li>\n</ul>\n<h2 id=\"程序与数据流\"><a href=\"#程序与数据流\" class=\"headerlink\" title=\"程序与数据流\"></a>程序与数据流</h2><p>Flink 程序的基础构建单元是（数据）流与变换（注意，数据集 API 中使用的数据集也是一种内置的流，这一点我们以后会细说）。顾名思义，一个数据流就是一组数据记录组成的（可能永远不会停止的）流，而变换就是一种接受若干数据流作为输入，然后再输出结果数据流的过程。</p>\n<p>Flink 程序在运行的时候会被映射到数据流图中，这个数据流图就是由程序中的数据流和相应的变换操作组成的。数据流图开始于一个或多个数据源（source），结束于另外一些汇聚点（sink）。数据流图类似于有向无环图（DAG）。虽然可以通过迭代构造器生成某些特殊形式的环，但为了简化说明，大部分情况下我们不考虑这种结构。</p>\n<p><img src=\"\\blog\\images\\pasted-54.png\" alt=\"upload successful\"></p>\n<p>通常情况下程序中的变换和数据流图中的运算符是一一对应的。不过有的时候也会出现一个变换由多个变换运算符组成的情况。</p>\n<p>数据源和汇聚点的相关文档在数据流连接器和批处理连接器的说明文档中。变换的相关文档在数据流变换和数据集变换的说明文档中。</p>\n<h2 id=\"并发数据流图\"><a href=\"#并发数据流图\" class=\"headerlink\" title=\"并发数据流图\"></a>并发数据流图</h2><p>本质上说，Flink 程序是分布式、并发执行的。在程序运行过程中，一个数据流可能会有一个或多个流分区，而一个运算符也可能会有一个或多个运算子任务。每个运算子任务与另外一个运算子任务之间都是相互独立的，他们是在不同的线程中运行的，甚至有可能所运行的机器或者容器都完全不同。</p>\n<p>运算子任务的数量由运算符的并发数确定。数据流的并发数就是它所生成的运算符的个数。程序中不同的运算符可以有不同等级的并发量。</p>\n<p><img src=\"\\blog\\images\\pasted-55.png\" alt=\"upload successful\"></p>\n<p>在两个运算符之间传输数据流既可以使用一对一的直接型模式，也可以使用重分发模式：</p>\n<ol>\n<li><p>一对一 模式的数据流（例如上图中 Source 和 map() 运算符之间的数据流）中元素的分组和顺序会保持不变，也就是说，map() 运算符的子任务[1]所看见的元素与 Source 运算符的子任务[1]所生成的元素的顺序完全一致。</p>\n</li>\n<li><p>分发 模式的数据流（例如上图中 map() 和 keyBy/window 运算符之间的数据流，以及 keyby/window 和 Sink 运算符之间的数据流）会改变数据流所在的分区。根据所选的变换的不同，每个运算子任务会将数据发送到不同的目标子任务中去。keyBy()（通过对 key 进行哈希计算来重分区）、boradcast() 和 rebalance()（随机重分区）就是重分发模式的几个例子。在重分发模式下，元素之间的先后次序在每对发送——接收子任务（例如 map() 的子任务[1]和 keyBy/window 的子任务[2]）中是保持不变的。因此，在上图的例子中，尽管在子任务之间每个 key 的顺序都是确定的，但是由于程序的并发过程引入了不确定性，最终到达 Sink 的元素顺序就不能保证与一开始的元素顺序完全一致。</p>\n</li>\n</ol>\n<p>关于配置并发的更多信息可以参阅并发执行文档。</p>\n<h2 id=\"窗口\"><a href=\"#窗口\" class=\"headerlink\" title=\"窗口\"></a>窗口</h2><p>计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。</p>\n<p>窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。<br>计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。</p>\n<p>窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。</p>\n<p><img src=\"\\blog\\images\\pasted-56.png\" alt=\"upload successful\"><br>这篇文章介绍了很多窗口的例子。另外，也可以查阅窗口文档了解更多内容。</p>\n<h2 id=\"时间\"><a href=\"#时间\" class=\"headerlink\" title=\"时间\"></a>时间</h2><p>流式计算程序中的时间概念（例如在定义窗口时经常会用到时间）有以下几种含义：</p>\n<ul>\n<li>事件时间（Event Time），是指事件创建时的时间。这种类型时间一般会表示为事件的时间戳，再通过事件生成传感器或者事件生成服务等附到事件中。Flink 通过时间戳指定器获取事件的时间戳。</li>\n<li>摄入时间（Ingestion Time），是指事件在源运算符中进入Flink的数据流的时间。</li>\n<li>处理时间（Processing Time），是指运算符在执行时间类操作时的本地时间。</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-57.png\" alt=\"upload successful\"></p>\n<h2 id=\"有状态操作\"><a href=\"#有状态操作\" class=\"headerlink\" title=\"有状态操作\"></a>有状态操作</h2><p>虽然数据流中有很多运算符每次只需要考虑当前所处理的唯一的事件（例如事件分析器），但是仍然存在很多需要记录多个事件的信息的场景（窗口操作符就是个很好的例子），这种需要记录信息的操作就称为有状态的操作。</p>\n<p>有状态操作的状态可以理解成是以键值对（key/value）形式储存的。这个状态的分区和分发过程是和数据流严格绑定在一起的，随后有状态运算符读取数据流就可以获取状态了。因此，在 keyBy() 函数执行之后，只能在带键的数据流中访问 key/value 状态，而且也只能获取与当前事件的主键相对应的值。数据流的键和值的对应确保了所有状态更新都是本地操作，同时也保证了事务的一致性。这个对应也使得Flink可以透明地重分发状态，并调整数据流地分区。</p>\n<p>有关状态地更多内容请参阅有状态操作文档。</p>\n<h2 id=\"容错性检查点\"><a href=\"#容错性检查点\" class=\"headerlink\" title=\"容错性检查点\"></a>容错性检查点</h2><p>Flink 通过数据重发和校验检查机制相结合的方式实现了容错能力。检查点和运算符中的相应的状态一样直接关联到输入数据流中的特定的某个点。为了维护数据一致性（一次处理的语义），可以让数据流从检查点恢复，这是通过恢复运算符的状态并对检查点对应的事件进行重发的方式实现的。</p>\n<p>检查点区间是对程序的容错能力与恢复时间（需要重发的事件数量）的折衷。</p>\n<p>容错区间文档中有关于Flink如何处理检查点以及其他相关主题的详细说明。更多关于配置启用检查点的资料请参阅检查点API文档。</p>\n<h2 id=\"批处理操作\"><a href=\"#批处理操作\" class=\"headerlink\" title=\"批处理操作\"></a>批处理操作</h2><p>Flink 将批处理程序看成流式计算程序的一种有界数据流（即元素数量是可数的）的特例。这里，数据集（DataSet）也被看作一种数据流。因此，上面流式计算程序中的很多概念也能应用到批处理程序中，除了以下几处不同：</p>\n<p>批处理程序的容错性不使用检查点机制。由于输入数据本身是有界的，批处理的恢复是通过完全重发所有数据流实现的。这样，恢复过程中的开销可能更大一些，但是由于没有了检查点，正常处理过程的开销反而更小了点。<br>数据集API中的有状态操作没有使用键/值（key/value）索引结构，而是使用了简化的内存/外存数据结构。<br>数据集API引入了特殊的同步（基于超步算法的）迭代接口，该接口仅能用于有界数据流。更多内容请参考迭代文档。</p>\n","excerpt":"","more":"<h2 id=\"抽象层次\"><a href=\"#抽象层次\" class=\"headerlink\" title=\"抽象层次\"></a>抽象层次</h2><p>Flink 能够为流式计算或批处理应用提供多种层次的抽象接口。<br><img src=\"\\blog\\images\\pasted-53.png\" alt=\"upload successful\"></p>\n<ul>\n<li><p>最低级的抽象接口是状态化的数据流接口。这个接口是通过 ProcessFunction 集成到 数据流 API 中的。此类接口让用户可以使用连续的容错状态，并且可以不受限制地处理多个数据流中的事件。另外，用户也可以通过注册事件时间和时间处理回调函数的方法来实现复杂的计算程序。</p>\n</li>\n<li><p>实际上，大部分程序通常会使用以数据流 API（有界/无界数据流）、数据集 API（有界数据集）为代表的核心 API，而并不会使用前述低级抽象接口。这些核心 API 为数据处理提供了大量的通用构建模块，包括用户定义的各种各样的变换、连接、聚集、窗口、状态等等。在编程语言中，这些 API 处理的数据类型通常会表现为相应的类的形式。</p>\n</li>\n</ul>\n<p>由于数据流 API 集成了低级处理函数，因此可以通过数据流API为某些特定操作应用低级处理接口。此外，数据集 API 也为诸如循环、迭代之类的有界数据集提供了一些补充的编程原语。</p>\n<ul>\n<li>数据表 API 是一种以数据表为核心地声明式 DSL，能够动态地修改那些表征数据流的表。数据表 API 的工作模式是一种（扩展的）关系型模型：每个数据表都依附于一个 schema（类似于关系型数据库中的表结构），相应的 API 就可以实现很多类似的操作，例如 select，project，join，group by，aggregate，等等。数据表 API 程序定义的仅仅是如何在逻辑上实现各种程序操作，而不是直接指定程序代码运行的具体步骤。尽管数据表 API 可以通过各式各样的自定义函数进行扩展，但是它在表达能力上仍然比不上核心 API，不过数据表 API 的优势是在使用上更简练（相对于核心 API 可以减少很多代码）。此外，数据表 API 程序在运行之前也会使用一个优化器对程序进行优化。</li>\n</ul>\n<p>由于用户可以在数据表与数据流/数据集之间进行无缝切换，程序也可以混合使用数据表 API 和数据流/数据集 API。</p>\n<ul>\n<li>Flink 提供的最高级接口是 SQL。这个层次的抽象接口和数据表 API 非常相似，包括语法和接口的表现能力，唯一的区别是通过 SQL 查询语言实现程序。实际上，SQL 抽象接口和数据表 API 的交互非常紧密，而且 SQL 查询也可以在数据表 API 中定义的表上执行。</li>\n</ul>\n<h2 id=\"程序与数据流\"><a href=\"#程序与数据流\" class=\"headerlink\" title=\"程序与数据流\"></a>程序与数据流</h2><p>Flink 程序的基础构建单元是（数据）流与变换（注意，数据集 API 中使用的数据集也是一种内置的流，这一点我们以后会细说）。顾名思义，一个数据流就是一组数据记录组成的（可能永远不会停止的）流，而变换就是一种接受若干数据流作为输入，然后再输出结果数据流的过程。</p>\n<p>Flink 程序在运行的时候会被映射到数据流图中，这个数据流图就是由程序中的数据流和相应的变换操作组成的。数据流图开始于一个或多个数据源（source），结束于另外一些汇聚点（sink）。数据流图类似于有向无环图（DAG）。虽然可以通过迭代构造器生成某些特殊形式的环，但为了简化说明，大部分情况下我们不考虑这种结构。</p>\n<p><img src=\"\\blog\\images\\pasted-54.png\" alt=\"upload successful\"></p>\n<p>通常情况下程序中的变换和数据流图中的运算符是一一对应的。不过有的时候也会出现一个变换由多个变换运算符组成的情况。</p>\n<p>数据源和汇聚点的相关文档在数据流连接器和批处理连接器的说明文档中。变换的相关文档在数据流变换和数据集变换的说明文档中。</p>\n<h2 id=\"并发数据流图\"><a href=\"#并发数据流图\" class=\"headerlink\" title=\"并发数据流图\"></a>并发数据流图</h2><p>本质上说，Flink 程序是分布式、并发执行的。在程序运行过程中，一个数据流可能会有一个或多个流分区，而一个运算符也可能会有一个或多个运算子任务。每个运算子任务与另外一个运算子任务之间都是相互独立的，他们是在不同的线程中运行的，甚至有可能所运行的机器或者容器都完全不同。</p>\n<p>运算子任务的数量由运算符的并发数确定。数据流的并发数就是它所生成的运算符的个数。程序中不同的运算符可以有不同等级的并发量。</p>\n<p><img src=\"\\blog\\images\\pasted-55.png\" alt=\"upload successful\"></p>\n<p>在两个运算符之间传输数据流既可以使用一对一的直接型模式，也可以使用重分发模式：</p>\n<ol>\n<li><p>一对一 模式的数据流（例如上图中 Source 和 map() 运算符之间的数据流）中元素的分组和顺序会保持不变，也就是说，map() 运算符的子任务[1]所看见的元素与 Source 运算符的子任务[1]所生成的元素的顺序完全一致。</p>\n</li>\n<li><p>分发 模式的数据流（例如上图中 map() 和 keyBy/window 运算符之间的数据流，以及 keyby/window 和 Sink 运算符之间的数据流）会改变数据流所在的分区。根据所选的变换的不同，每个运算子任务会将数据发送到不同的目标子任务中去。keyBy()（通过对 key 进行哈希计算来重分区）、boradcast() 和 rebalance()（随机重分区）就是重分发模式的几个例子。在重分发模式下，元素之间的先后次序在每对发送——接收子任务（例如 map() 的子任务[1]和 keyBy/window 的子任务[2]）中是保持不变的。因此，在上图的例子中，尽管在子任务之间每个 key 的顺序都是确定的，但是由于程序的并发过程引入了不确定性，最终到达 Sink 的元素顺序就不能保证与一开始的元素顺序完全一致。</p>\n</li>\n</ol>\n<p>关于配置并发的更多信息可以参阅并发执行文档。</p>\n<h2 id=\"窗口\"><a href=\"#窗口\" class=\"headerlink\" title=\"窗口\"></a>窗口</h2><p>计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。</p>\n<p>窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。<br>计数（counts）、求和（sums）等聚合事件和批处理过程的工作模式完全不同。举个例子，由于数据流在理论上是无限的，因此直接计算数据流中的所有元素的个数基本上是无法实现的。因此，数据流的聚合操作（计数、求和等）都是由窗口（window）限定了范围的，例如“计算前五分钟的元素个数”，“对前100个元素求和”等。</p>\n<p>窗口可以通过时间（例如以30秒为单位）或者数据（例如以100个元素为单位）来定义。有多种不同类型的窗口，例如数据不重叠的滚动窗口（tumbling window）、数据重叠的滑动窗口（sliding window），以及以非活动状态为间隔的会话窗口（session window）。</p>\n<p><img src=\"\\blog\\images\\pasted-56.png\" alt=\"upload successful\"><br>这篇文章介绍了很多窗口的例子。另外，也可以查阅窗口文档了解更多内容。</p>\n<h2 id=\"时间\"><a href=\"#时间\" class=\"headerlink\" title=\"时间\"></a>时间</h2><p>流式计算程序中的时间概念（例如在定义窗口时经常会用到时间）有以下几种含义：</p>\n<ul>\n<li>事件时间（Event Time），是指事件创建时的时间。这种类型时间一般会表示为事件的时间戳，再通过事件生成传感器或者事件生成服务等附到事件中。Flink 通过时间戳指定器获取事件的时间戳。</li>\n<li>摄入时间（Ingestion Time），是指事件在源运算符中进入Flink的数据流的时间。</li>\n<li>处理时间（Processing Time），是指运算符在执行时间类操作时的本地时间。</li>\n</ul>\n<p><img src=\"\\blog\\images\\pasted-57.png\" alt=\"upload successful\"></p>\n<h2 id=\"有状态操作\"><a href=\"#有状态操作\" class=\"headerlink\" title=\"有状态操作\"></a>有状态操作</h2><p>虽然数据流中有很多运算符每次只需要考虑当前所处理的唯一的事件（例如事件分析器），但是仍然存在很多需要记录多个事件的信息的场景（窗口操作符就是个很好的例子），这种需要记录信息的操作就称为有状态的操作。</p>\n<p>有状态操作的状态可以理解成是以键值对（key/value）形式储存的。这个状态的分区和分发过程是和数据流严格绑定在一起的，随后有状态运算符读取数据流就可以获取状态了。因此，在 keyBy() 函数执行之后，只能在带键的数据流中访问 key/value 状态，而且也只能获取与当前事件的主键相对应的值。数据流的键和值的对应确保了所有状态更新都是本地操作，同时也保证了事务的一致性。这个对应也使得Flink可以透明地重分发状态，并调整数据流地分区。</p>\n<p>有关状态地更多内容请参阅有状态操作文档。</p>\n<h2 id=\"容错性检查点\"><a href=\"#容错性检查点\" class=\"headerlink\" title=\"容错性检查点\"></a>容错性检查点</h2><p>Flink 通过数据重发和校验检查机制相结合的方式实现了容错能力。检查点和运算符中的相应的状态一样直接关联到输入数据流中的特定的某个点。为了维护数据一致性（一次处理的语义），可以让数据流从检查点恢复，这是通过恢复运算符的状态并对检查点对应的事件进行重发的方式实现的。</p>\n<p>检查点区间是对程序的容错能力与恢复时间（需要重发的事件数量）的折衷。</p>\n<p>容错区间文档中有关于Flink如何处理检查点以及其他相关主题的详细说明。更多关于配置启用检查点的资料请参阅检查点API文档。</p>\n<h2 id=\"批处理操作\"><a href=\"#批处理操作\" class=\"headerlink\" title=\"批处理操作\"></a>批处理操作</h2><p>Flink 将批处理程序看成流式计算程序的一种有界数据流（即元素数量是可数的）的特例。这里，数据集（DataSet）也被看作一种数据流。因此，上面流式计算程序中的很多概念也能应用到批处理程序中，除了以下几处不同：</p>\n<p>批处理程序的容错性不使用检查点机制。由于输入数据本身是有界的，批处理的恢复是通过完全重发所有数据流实现的。这样，恢复过程中的开销可能更大一些，但是由于没有了检查点，正常处理过程的开销反而更小了点。<br>数据集API中的有状态操作没有使用键/值（key/value）索引结构，而是使用了简化的内存/外存数据结构。<br>数据集API引入了特殊的同步（基于超步算法的）迭代接口，该接口仅能用于有界数据流。更多内容请参考迭代文档。</p>\n"},{"title":"Bipartite_graph 二分图","author":"Master.TJ","date":"2018-05-25T07:57:00.000Z","_content":"（bigraph）是有两个相互独立的位置图和连接图构成。二分图的概念是由图灵奖获得者Milner提出的，其目的为普适计算提供统一的元模型。\n\n 若无向图G = <V,E>的结点集V能够划分为两个子集V1,V2，满足V1∩V2 = F(空集)，且V1∪V2 = V（全集），使得G中任意一条边的两个端点，一个属于V1，另一个属于V2，则称G为偶图（Bipartite Graph）或二分图（Bigraph）。V1和V2称为互补结点子集，偶图也可记为G = <V1,E,V2>。\n\n  二分图，二部图，偶图，是图论中一种特殊模型。指顶点可以分成两个不相交的集使得在同一个集内的顶点不相邻（没有共同边）的图。\n  \n  \n![upload successful](\\blog\\images\\pasted-12.png)\n\n![upload successful](\\blog\\images\\pasted-13.png)","source":"_posts/Bipartite-graph-二分图.md","raw":"title: Bipartite_graph 二分图\nauthor: Master.TJ\ntags:\n  - 图计算\ncategories: []\ndate: 2018-05-25 15:57:00\n---\n（bigraph）是有两个相互独立的位置图和连接图构成。二分图的概念是由图灵奖获得者Milner提出的，其目的为普适计算提供统一的元模型。\n\n 若无向图G = <V,E>的结点集V能够划分为两个子集V1,V2，满足V1∩V2 = F(空集)，且V1∪V2 = V（全集），使得G中任意一条边的两个端点，一个属于V1，另一个属于V2，则称G为偶图（Bipartite Graph）或二分图（Bigraph）。V1和V2称为互补结点子集，偶图也可记为G = <V1,E,V2>。\n\n  二分图，二部图，偶图，是图论中一种特殊模型。指顶点可以分成两个不相交的集使得在同一个集内的顶点不相邻（没有共同边）的图。\n  \n  \n![upload successful](\\blog\\images\\pasted-12.png)\n\n![upload successful](\\blog\\images\\pasted-13.png)","slug":"Bipartite-graph-二分图","published":1,"updated":"2024-05-08T19:47:58.625Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u6220007doy9fi7j993u","content":"<p>（bigraph）是有两个相互独立的位置图和连接图构成。二分图的概念是由图灵奖获得者Milner提出的，其目的为普适计算提供统一的元模型。</p>\n<p> 若无向图G = <V,E>的结点集V能够划分为两个子集V1,V2，满足V1∩V2 = F(空集)，且V1∪V2 = V（全集），使得G中任意一条边的两个端点，一个属于V1，另一个属于V2，则称G为偶图（Bipartite Graph）或二分图（Bigraph）。V1和V2称为互补结点子集，偶图也可记为G = <V1,E,V2>。</p>\n<p>  二分图，二部图，偶图，是图论中一种特殊模型。指顶点可以分成两个不相交的集使得在同一个集内的顶点不相邻（没有共同边）的图。</p>\n<p><img src=\"\\blog\\images\\pasted-12.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-13.png\" alt=\"upload successful\"></p>\n","excerpt":"","more":"<p>（bigraph）是有两个相互独立的位置图和连接图构成。二分图的概念是由图灵奖获得者Milner提出的，其目的为普适计算提供统一的元模型。</p>\n<p> 若无向图G = <V,E>的结点集V能够划分为两个子集V1,V2，满足V1∩V2 = F(空集)，且V1∪V2 = V（全集），使得G中任意一条边的两个端点，一个属于V1，另一个属于V2，则称G为偶图（Bipartite Graph）或二分图（Bigraph）。V1和V2称为互补结点子集，偶图也可记为G = <V1,E,V2>。</p>\n<p>  二分图，二部图，偶图，是图论中一种特殊模型。指顶点可以分成两个不相交的集使得在同一个集内的顶点不相邻（没有共同边）的图。</p>\n<p><img src=\"\\blog\\images\\pasted-12.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-13.png\" alt=\"upload successful\"></p>\n"},{"title":" Design Guidelines for High Performance RDMA Systems","author":"Master.TJ","date":"2018-05-23T03:11:00.000Z","_content":"## Introduction\n随着RDMA技术的发展，RDMA技术越来越被数据中心采用。尽管RDMA的新知名度，使用他们的先进功能以达到最佳效果仍然是软件设计师的挑战。</br>\n找到RDMA功能与应用程序之间的有效匹配非常重要。没有一种方法能够适合所有的应用场景，比如说RDMA一个参数的最佳和最差选择在它们的总吞吐量中变化了70倍，并且它们消耗的主机CPU的量变化了3.2倍。在不同的设计中，应用需求的小的变化显著影响RDMA的相对性能。</br>\n1. 首先这篇文章的第一个贡献就是它提供了由一组开源的度量工具支持的指导方针，用于评估和优化在使用RDMA NICs时影响端到端吞吐量的最重要的系统因素。对于每个指导方针。作者就如何确定本指南是否相关提供了深入的见解，并讨论了使用NIC的哪些模式最有可能缓解问题。\n2. 其次，作者通过第三代RDMA硬件将这些指南应用于微基准和实际系统来评估这些指南的功效。\n---\n\n## Background\n![upload successful](\\blog\\images\\pasted-1.png)</br>\n图显示了RDMA Cluster硬件组件。其中NIC网卡连接的一个或则多个端口连接到PCIe控制器且连接到多核CPU的服务器上。PCIe恐控制器用来接受NIC网卡的PCIe请求到L3 cache中。在现代的Intel 服务器架构中，这个L3 Cache 提供PCIe 事件控制器。\n### PCI Express","source":"_posts/Design-Guidelines-for-High-Performance-RDMA-Systems.md","raw":"title: ' Design Guidelines for High Performance RDMA Systems'\nauthor: Master.TJ\ntags:\n  - RDMA\ncategories:\n  - 研究生论文研读\n  - RDMA论文研读\ndate: 2018-05-23 11:11:00\n---\n## Introduction\n随着RDMA技术的发展，RDMA技术越来越被数据中心采用。尽管RDMA的新知名度，使用他们的先进功能以达到最佳效果仍然是软件设计师的挑战。</br>\n找到RDMA功能与应用程序之间的有效匹配非常重要。没有一种方法能够适合所有的应用场景，比如说RDMA一个参数的最佳和最差选择在它们的总吞吐量中变化了70倍，并且它们消耗的主机CPU的量变化了3.2倍。在不同的设计中，应用需求的小的变化显著影响RDMA的相对性能。</br>\n1. 首先这篇文章的第一个贡献就是它提供了由一组开源的度量工具支持的指导方针，用于评估和优化在使用RDMA NICs时影响端到端吞吐量的最重要的系统因素。对于每个指导方针。作者就如何确定本指南是否相关提供了深入的见解，并讨论了使用NIC的哪些模式最有可能缓解问题。\n2. 其次，作者通过第三代RDMA硬件将这些指南应用于微基准和实际系统来评估这些指南的功效。\n---\n\n## Background\n![upload successful](\\blog\\images\\pasted-1.png)</br>\n图显示了RDMA Cluster硬件组件。其中NIC网卡连接的一个或则多个端口连接到PCIe控制器且连接到多核CPU的服务器上。PCIe恐控制器用来接受NIC网卡的PCIe请求到L3 cache中。在现代的Intel 服务器架构中，这个L3 Cache 提供PCIe 事件控制器。\n### PCI Express","slug":"Design-Guidelines-for-High-Performance-RDMA-Systems","published":1,"updated":"2024-05-08T19:47:58.625Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u6250008doy92x7wdeoo","content":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><p>随着RDMA技术的发展，RDMA技术越来越被数据中心采用。尽管RDMA的新知名度，使用他们的先进功能以达到最佳效果仍然是软件设计师的挑战。</br><br>找到RDMA功能与应用程序之间的有效匹配非常重要。没有一种方法能够适合所有的应用场景，比如说RDMA一个参数的最佳和最差选择在它们的总吞吐量中变化了70倍，并且它们消耗的主机CPU的量变化了3.2倍。在不同的设计中，应用需求的小的变化显著影响RDMA的相对性能。</br></p>\n<ol>\n<li>首先这篇文章的第一个贡献就是它提供了由一组开源的度量工具支持的指导方针，用于评估和优化在使用RDMA NICs时影响端到端吞吐量的最重要的系统因素。对于每个指导方针。作者就如何确定本指南是否相关提供了深入的见解，并讨论了使用NIC的哪些模式最有可能缓解问题。</li>\n<li>其次，作者通过第三代RDMA硬件将这些指南应用于微基准和实际系统来评估这些指南的功效。</li>\n</ol>\n<hr>\n<h2 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h2><p><img src=\"\\blog\\images\\pasted-1.png\" alt=\"upload successful\"></br><br>图显示了RDMA Cluster硬件组件。其中NIC网卡连接的一个或则多个端口连接到PCIe控制器且连接到多核CPU的服务器上。PCIe恐控制器用来接受NIC网卡的PCIe请求到L3 cache中。在现代的Intel 服务器架构中，这个L3 Cache 提供PCIe 事件控制器。</p>\n<h3 id=\"PCI-Express\"><a href=\"#PCI-Express\" class=\"headerlink\" title=\"PCI Express\"></a>PCI Express</h3>","excerpt":"","more":"<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><p>随着RDMA技术的发展，RDMA技术越来越被数据中心采用。尽管RDMA的新知名度，使用他们的先进功能以达到最佳效果仍然是软件设计师的挑战。</br><br>找到RDMA功能与应用程序之间的有效匹配非常重要。没有一种方法能够适合所有的应用场景，比如说RDMA一个参数的最佳和最差选择在它们的总吞吐量中变化了70倍，并且它们消耗的主机CPU的量变化了3.2倍。在不同的设计中，应用需求的小的变化显著影响RDMA的相对性能。</br></p>\n<ol>\n<li>首先这篇文章的第一个贡献就是它提供了由一组开源的度量工具支持的指导方针，用于评估和优化在使用RDMA NICs时影响端到端吞吐量的最重要的系统因素。对于每个指导方针。作者就如何确定本指南是否相关提供了深入的见解，并讨论了使用NIC的哪些模式最有可能缓解问题。</li>\n<li>其次，作者通过第三代RDMA硬件将这些指南应用于微基准和实际系统来评估这些指南的功效。</li>\n</ol>\n<hr>\n<h2 id=\"Background\"><a href=\"#Background\" class=\"headerlink\" title=\"Background\"></a>Background</h2><p><img src=\"\\blog\\images\\pasted-1.png\" alt=\"upload successful\"></br><br>图显示了RDMA Cluster硬件组件。其中NIC网卡连接的一个或则多个端口连接到PCIe控制器且连接到多核CPU的服务器上。PCIe恐控制器用来接受NIC网卡的PCIe请求到L3 cache中。在现代的Intel 服务器架构中，这个L3 Cache 提供PCIe 事件控制器。</p>\n<h3 id=\"PCI-Express\"><a href=\"#PCI-Express\" class=\"headerlink\" title=\"PCI Express\"></a>PCI Express</h3>"},{"title":"Linux服务管理","date":"2017-04-25T11:11:03.000Z","_content":"\n# Linux服务器管理\n## 第一章简介与分类\n### 1-1系统运行级别\n\n- 0关机\n- 1单用户模式\n- 2不完全的命令行模式\n- 3完全的命令行模式\n- 4系统保留\n- 5图像模式\n- 6重启动\n\n修改系统默认允许级别方法 vim /etc/inittab \n系统开机后直接进入哪个运行级别\n\n### 1-2服务的分类\n* rpm包默认安装的服务 \n    * 独立的服务\n    * 基于xinetd的服务\n* 源码包安装的服务\n\n### 1-3启动与自启动\n* 服务启动：就是在当前系统中让服务运行，并且提供功能\n* 服务自启动：自启动就是指在系统开机或者重启动以后，随着系统启动而自启动服务。\n\n### 1-4查看系统中启动的服务\n* RPM包安装的服务\n    * chkconfig --list\n    * 查看服务启动状态，可以看到所有RPM包安装的服务.RPM包安装位置在/etc/init/init.d 目录下\n* 源码包安装的服务\n    * 查看服务安装的位置一般在 /usr/local 目录下\n    \n### 1-5 服务和端口\n* 端口和服务相对应\n* 查询系统中开启的服务\n \n    netstat -tlunp\n    \n\n---\n\n## 第二章RPM包服务管理","source":"_posts/Linux服务管理.md","raw":"---\ntitle: Linux服务管理\ndate: 2017-04-25 19:11:03\ncategories:\n  -Linux\ntags:\n  -linux\n---\n\n# Linux服务器管理\n## 第一章简介与分类\n### 1-1系统运行级别\n\n- 0关机\n- 1单用户模式\n- 2不完全的命令行模式\n- 3完全的命令行模式\n- 4系统保留\n- 5图像模式\n- 6重启动\n\n修改系统默认允许级别方法 vim /etc/inittab \n系统开机后直接进入哪个运行级别\n\n### 1-2服务的分类\n* rpm包默认安装的服务 \n    * 独立的服务\n    * 基于xinetd的服务\n* 源码包安装的服务\n\n### 1-3启动与自启动\n* 服务启动：就是在当前系统中让服务运行，并且提供功能\n* 服务自启动：自启动就是指在系统开机或者重启动以后，随着系统启动而自启动服务。\n\n### 1-4查看系统中启动的服务\n* RPM包安装的服务\n    * chkconfig --list\n    * 查看服务启动状态，可以看到所有RPM包安装的服务.RPM包安装位置在/etc/init/init.d 目录下\n* 源码包安装的服务\n    * 查看服务安装的位置一般在 /usr/local 目录下\n    \n### 1-5 服务和端口\n* 端口和服务相对应\n* 查询系统中开启的服务\n \n    netstat -tlunp\n    \n\n---\n\n## 第二章RPM包服务管理","slug":"Linux服务管理","published":1,"updated":"2024-05-08T19:47:58.625Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u6260009doy94wpnfozd","content":"<h1 id=\"Linux服务器管理\"><a href=\"#Linux服务器管理\" class=\"headerlink\" title=\"Linux服务器管理\"></a>Linux服务器管理</h1><h2 id=\"第一章简介与分类\"><a href=\"#第一章简介与分类\" class=\"headerlink\" title=\"第一章简介与分类\"></a>第一章简介与分类</h2><h3 id=\"1-1系统运行级别\"><a href=\"#1-1系统运行级别\" class=\"headerlink\" title=\"1-1系统运行级别\"></a>1-1系统运行级别</h3><ul>\n<li>0关机</li>\n<li>1单用户模式</li>\n<li>2不完全的命令行模式</li>\n<li>3完全的命令行模式</li>\n<li>4系统保留</li>\n<li>5图像模式</li>\n<li>6重启动</li>\n</ul>\n<p>修改系统默认允许级别方法 vim /etc/inittab<br>系统开机后直接进入哪个运行级别</p>\n<h3 id=\"1-2服务的分类\"><a href=\"#1-2服务的分类\" class=\"headerlink\" title=\"1-2服务的分类\"></a>1-2服务的分类</h3><ul>\n<li>rpm包默认安装的服务 <ul>\n<li>独立的服务</li>\n<li>基于xinetd的服务</li>\n</ul>\n</li>\n<li>源码包安装的服务</li>\n</ul>\n<h3 id=\"1-3启动与自启动\"><a href=\"#1-3启动与自启动\" class=\"headerlink\" title=\"1-3启动与自启动\"></a>1-3启动与自启动</h3><ul>\n<li>服务启动：就是在当前系统中让服务运行，并且提供功能</li>\n<li>服务自启动：自启动就是指在系统开机或者重启动以后，随着系统启动而自启动服务。</li>\n</ul>\n<h3 id=\"1-4查看系统中启动的服务\"><a href=\"#1-4查看系统中启动的服务\" class=\"headerlink\" title=\"1-4查看系统中启动的服务\"></a>1-4查看系统中启动的服务</h3><ul>\n<li>RPM包安装的服务<ul>\n<li>chkconfig –list</li>\n<li>查看服务启动状态，可以看到所有RPM包安装的服务.RPM包安装位置在/etc/init/init.d 目录下</li>\n</ul>\n</li>\n<li>源码包安装的服务<ul>\n<li>查看服务安装的位置一般在 /usr/local 目录下</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-5-服务和端口\"><a href=\"#1-5-服务和端口\" class=\"headerlink\" title=\"1-5 服务和端口\"></a>1-5 服务和端口</h3><ul>\n<li>端口和服务相对应</li>\n<li><p>查询系统中开启的服务</p>\n<p>  netstat -tlunp</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"第二章RPM包服务管理\"><a href=\"#第二章RPM包服务管理\" class=\"headerlink\" title=\"第二章RPM包服务管理\"></a>第二章RPM包服务管理</h2>","excerpt":"","more":"<h1 id=\"Linux服务器管理\"><a href=\"#Linux服务器管理\" class=\"headerlink\" title=\"Linux服务器管理\"></a>Linux服务器管理</h1><h2 id=\"第一章简介与分类\"><a href=\"#第一章简介与分类\" class=\"headerlink\" title=\"第一章简介与分类\"></a>第一章简介与分类</h2><h3 id=\"1-1系统运行级别\"><a href=\"#1-1系统运行级别\" class=\"headerlink\" title=\"1-1系统运行级别\"></a>1-1系统运行级别</h3><ul>\n<li>0关机</li>\n<li>1单用户模式</li>\n<li>2不完全的命令行模式</li>\n<li>3完全的命令行模式</li>\n<li>4系统保留</li>\n<li>5图像模式</li>\n<li>6重启动</li>\n</ul>\n<p>修改系统默认允许级别方法 vim /etc/inittab<br>系统开机后直接进入哪个运行级别</p>\n<h3 id=\"1-2服务的分类\"><a href=\"#1-2服务的分类\" class=\"headerlink\" title=\"1-2服务的分类\"></a>1-2服务的分类</h3><ul>\n<li>rpm包默认安装的服务 <ul>\n<li>独立的服务</li>\n<li>基于xinetd的服务</li>\n</ul>\n</li>\n<li>源码包安装的服务</li>\n</ul>\n<h3 id=\"1-3启动与自启动\"><a href=\"#1-3启动与自启动\" class=\"headerlink\" title=\"1-3启动与自启动\"></a>1-3启动与自启动</h3><ul>\n<li>服务启动：就是在当前系统中让服务运行，并且提供功能</li>\n<li>服务自启动：自启动就是指在系统开机或者重启动以后，随着系统启动而自启动服务。</li>\n</ul>\n<h3 id=\"1-4查看系统中启动的服务\"><a href=\"#1-4查看系统中启动的服务\" class=\"headerlink\" title=\"1-4查看系统中启动的服务\"></a>1-4查看系统中启动的服务</h3><ul>\n<li>RPM包安装的服务<ul>\n<li>chkconfig –list</li>\n<li>查看服务启动状态，可以看到所有RPM包安装的服务.RPM包安装位置在/etc/init/init.d 目录下</li>\n</ul>\n</li>\n<li>源码包安装的服务<ul>\n<li>查看服务安装的位置一般在 /usr/local 目录下</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"1-5-服务和端口\"><a href=\"#1-5-服务和端口\" class=\"headerlink\" title=\"1-5 服务和端口\"></a>1-5 服务和端口</h3><ul>\n<li>端口和服务相对应</li>\n<li><p>查询系统中开启的服务</p>\n<p>  netstat -tlunp</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"第二章RPM包服务管理\"><a href=\"#第二章RPM包服务管理\" class=\"headerlink\" title=\"第二章RPM包服务管理\"></a>第二章RPM包服务管理</h2>"},{"title":"PCIE和PCI 计算机总线","author":"Master.TJ","date":"2018-05-23T08:10:00.000Z","_content":"## PCIE\nPCI Express是新一代的总线接口。早在2001年的春季，英特尔公司就提出了要用新一代的技术取代PCI总线和多种芯片的内部连接，并称之为第三代I/O总线技术。随后在2001年底，包括Intel、AMD、DELL、IBM在内的20多家业界主导公司开始起草新技术的规范，并在2002年完成，对其正式命名为PCI Express。它采用了目前业内流行的点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把数据传输率提高到一个很高的频率，达到PCI所不能提供的高带宽。\n## 基本概念\nPCI Express的接口根据总线位宽不同而有所差异，包括X1、X4、X8以及X16（X2模式将用于内部接口而非插\n槽模式）。较短的PCI Express卡可以插入较长的PCI Express插槽中使用。PCI Express接口能够支持热拔插，这也是个不小的飞跃。PCI Express卡支持的三种电压分别为+3.3V、3.3Vaux以及+12V。用于取代AGP接口的PCI Express接口位宽为X16，将能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。\n\n![upload successful](\\blog\\images\\pasted-2.png)\n\nPCI Express规格从1条通道连接到32条通道连接，有非常强的伸缩性，以满足不同系统设备对数据传输带宽不同的需求。例如，PCI Express X1规格支持双向数据传输，每向数据传输带宽250MB/s，PCI Express X1已经可以满足主流声效芯片、网卡芯片和存储设备对数据传输带宽的需求，但是远远无法满足图形芯片对数据传输带宽的需求。因此，必须采用PCI Express X16，即16条点对点数据传输通道连接来取代传统的AGP总线。PCI Express X16也支持双向数据传输，每向数据传输带宽高达4GB/s，双向数据传输带宽有8GB/s之多，相比之下，广泛采用的AGP 8X数据传输只提供2.1GB/s的数据传输带宽。\n\n尽管PCI Express技术规格允许实现X1（250MB/秒），X2，X4，X8，X12，X16和X32通道规格，但是依形式来看，PCI Express X1和PCI Express X16将成为PCI Express主流规格，同时芯片组厂商将在南桥芯片当中添加对PCI Express X1的支持，在北桥芯片当中添加对PCI Express X16的支持。除去提供极高数据传输带宽之外，PCI Express因为采用串行数据包方式传递数据，所以PCI Express接口每个针脚可以获得比传统I/O标准更多的带宽，这样就可以降低PCI Express设备生产成本和体积。另外，PCI Express也支持高阶电源管理，支持热插拔，支持数据同步传输，为优先传输数据进行带宽优化。\n\n![upload successful](\\blog\\images\\pasted-3.png)\n\n在兼容性方面，PCI Express在软件层面上兼容的PCI技术和设备，支持PCI设备和内存模组的初始化，也就是说驱动程序、操作系统无需推倒重来，就可以支持PCI Express设备。PCI Express是新一代能够提供大量带宽和丰富功能以实现令人激动的新式图形应用的全新架构。PCI Express可以为带宽渴求型应用分配相应的带宽，大幅提高中央处理器（CPU）和图形处理器（GPU）之间的带宽。对最终用户而言，他们可以感受影院级图象效果，并获得无缝多媒体体验。\n\nPCI Express的主要优势就是数据传输速率高，目前最高的16X 2.0版本可达到10GB/s，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，能满足一定时间内出现的低速设备和高速设备的需求。PCI-Express最新的接口是PCIe 3.0接口，其比特率为8GT/s，约为上一代产品带宽的两倍，并且包含发射器和接收器均衡、PLL改善以及时钟数据恢复等一系列重要的新功能，用以改善数据传输和数据保护性能。像INTEL、IBM、、LSI、OCZ、、三星(计划中)、SanDisk、STEC、SuperTalent和东芝(计划中)等，而针对海量的数据增长使得用户对规模更大、可扩展性更强的系统所应用，PCIe 3.0技术的加入最新的LSI MegaRAID控制器及HBA产品的出色性能，就可以实现更大的系统设计灵活性。\n\nPCI Express采用串行方式传输Data。它和原有的ISA、PCI和AGP总线不同。这种传输方式，不必因为某个硬件的频率而影响到整个系统性能的发挥。当然了，整个系统依然是一个整体，但是我们可以方便的提高某一频率低的硬件的频率，以便系统在没有瓶颈的环境下使用。以串行方式提升频率增进效能，关键的限制在于采用什么样的物理传输介质。人们普遍采用铜线路，而理论上铜这个材质可以提供的传输极限是10 Gbps。这也就是为什么PCI Express的极限传输速度的答案。\n\n因为PCI Express工作模式是一种称之为“电压差式传输”的方式。两条铜线，通过相互间的电压差来表示逻辑符号0和1。以这种方式进行资料传输，可以支持极高的运行频率。所以在速度达到10Gbps后，只需换用光纤（Fibre Channel）就可以使之效能倍增。\n\nPCI Express是下一阶段的主要传输总线带宽技术。然而，GPU对总线带宽的需求是子系统中最高的，显而易见的是，视频在PCI Express应占有一定的分量。显然，PCI Express的提出，并非是总线形式的一个结束。恰恰相反，其技术的成熟仍旧需要这个时间。当然了，趁这个时间，那些芯片、主板、视频等厂家是否能出来支持是PCI Express发展的关键。\n\nPCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”。这个新标准将全面取代现行的PCI和AGP，最终实现总线标准的统一。它的主要优势就是数据传输速率高，目前最高可达到10GB/s以上，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，芯片组。当然要实现全面取代PCI和AGP也需要一个相当长的过程，就象当初PCI取代ISA一样，都会有个过渡的过程。\n\n## PCI和PCIE有什么区别\n1. 在兼容性方面，PCI-E在软件层面上兼容目前的PCI技术和设备，支持PCI设备和内存模组的初始。\n2. 由于PCI总线只有133MB/s 的带宽，对声卡、网卡、视频卡等绝大多数输入/输出设备显得绰绰有余，但对性能日益强大的显卡则无法满足其需求。\n3. 目前PCI接口的显卡已经不多见了，只有较老的PC上才有，厂商也很少推出此类接口的产品。PCI显卡性能受到极大限制，并且由于数量稀少，因此价格也并不便宜，只有在不得已的情况才考虑使用PCI显卡。\n4. 因此，用于取代AGP接口的PCI-E接口位宽为X16，能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供约为4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。\n\nPCI(Peripheral Component Interconnect)外部设备互连总线是 英特尔（Intel）公司1991年下半年首先提出的，并得到IBM、Compad、AST、HP、和DEC等100多家计算机公司的响应，于1993年正式推出了PCI局部总线标准。此标准允许在计算机内安装多达10个遵从PCI标准的扩展卡。\n\nPCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”，简称“PCI-E”。","source":"_posts/PCIE和PCI-计算机总线.md","raw":"title: PCIE和PCI 计算机总线\nauthor: Master.TJ\ntags:\n  - 计算机硬件\ncategories:\n  - 计算机硬件\ndate: 2018-05-23 16:10:00\n---\n## PCIE\nPCI Express是新一代的总线接口。早在2001年的春季，英特尔公司就提出了要用新一代的技术取代PCI总线和多种芯片的内部连接，并称之为第三代I/O总线技术。随后在2001年底，包括Intel、AMD、DELL、IBM在内的20多家业界主导公司开始起草新技术的规范，并在2002年完成，对其正式命名为PCI Express。它采用了目前业内流行的点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把数据传输率提高到一个很高的频率，达到PCI所不能提供的高带宽。\n## 基本概念\nPCI Express的接口根据总线位宽不同而有所差异，包括X1、X4、X8以及X16（X2模式将用于内部接口而非插\n槽模式）。较短的PCI Express卡可以插入较长的PCI Express插槽中使用。PCI Express接口能够支持热拔插，这也是个不小的飞跃。PCI Express卡支持的三种电压分别为+3.3V、3.3Vaux以及+12V。用于取代AGP接口的PCI Express接口位宽为X16，将能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。\n\n![upload successful](\\blog\\images\\pasted-2.png)\n\nPCI Express规格从1条通道连接到32条通道连接，有非常强的伸缩性，以满足不同系统设备对数据传输带宽不同的需求。例如，PCI Express X1规格支持双向数据传输，每向数据传输带宽250MB/s，PCI Express X1已经可以满足主流声效芯片、网卡芯片和存储设备对数据传输带宽的需求，但是远远无法满足图形芯片对数据传输带宽的需求。因此，必须采用PCI Express X16，即16条点对点数据传输通道连接来取代传统的AGP总线。PCI Express X16也支持双向数据传输，每向数据传输带宽高达4GB/s，双向数据传输带宽有8GB/s之多，相比之下，广泛采用的AGP 8X数据传输只提供2.1GB/s的数据传输带宽。\n\n尽管PCI Express技术规格允许实现X1（250MB/秒），X2，X4，X8，X12，X16和X32通道规格，但是依形式来看，PCI Express X1和PCI Express X16将成为PCI Express主流规格，同时芯片组厂商将在南桥芯片当中添加对PCI Express X1的支持，在北桥芯片当中添加对PCI Express X16的支持。除去提供极高数据传输带宽之外，PCI Express因为采用串行数据包方式传递数据，所以PCI Express接口每个针脚可以获得比传统I/O标准更多的带宽，这样就可以降低PCI Express设备生产成本和体积。另外，PCI Express也支持高阶电源管理，支持热插拔，支持数据同步传输，为优先传输数据进行带宽优化。\n\n![upload successful](\\blog\\images\\pasted-3.png)\n\n在兼容性方面，PCI Express在软件层面上兼容的PCI技术和设备，支持PCI设备和内存模组的初始化，也就是说驱动程序、操作系统无需推倒重来，就可以支持PCI Express设备。PCI Express是新一代能够提供大量带宽和丰富功能以实现令人激动的新式图形应用的全新架构。PCI Express可以为带宽渴求型应用分配相应的带宽，大幅提高中央处理器（CPU）和图形处理器（GPU）之间的带宽。对最终用户而言，他们可以感受影院级图象效果，并获得无缝多媒体体验。\n\nPCI Express的主要优势就是数据传输速率高，目前最高的16X 2.0版本可达到10GB/s，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，能满足一定时间内出现的低速设备和高速设备的需求。PCI-Express最新的接口是PCIe 3.0接口，其比特率为8GT/s，约为上一代产品带宽的两倍，并且包含发射器和接收器均衡、PLL改善以及时钟数据恢复等一系列重要的新功能，用以改善数据传输和数据保护性能。像INTEL、IBM、、LSI、OCZ、、三星(计划中)、SanDisk、STEC、SuperTalent和东芝(计划中)等，而针对海量的数据增长使得用户对规模更大、可扩展性更强的系统所应用，PCIe 3.0技术的加入最新的LSI MegaRAID控制器及HBA产品的出色性能，就可以实现更大的系统设计灵活性。\n\nPCI Express采用串行方式传输Data。它和原有的ISA、PCI和AGP总线不同。这种传输方式，不必因为某个硬件的频率而影响到整个系统性能的发挥。当然了，整个系统依然是一个整体，但是我们可以方便的提高某一频率低的硬件的频率，以便系统在没有瓶颈的环境下使用。以串行方式提升频率增进效能，关键的限制在于采用什么样的物理传输介质。人们普遍采用铜线路，而理论上铜这个材质可以提供的传输极限是10 Gbps。这也就是为什么PCI Express的极限传输速度的答案。\n\n因为PCI Express工作模式是一种称之为“电压差式传输”的方式。两条铜线，通过相互间的电压差来表示逻辑符号0和1。以这种方式进行资料传输，可以支持极高的运行频率。所以在速度达到10Gbps后，只需换用光纤（Fibre Channel）就可以使之效能倍增。\n\nPCI Express是下一阶段的主要传输总线带宽技术。然而，GPU对总线带宽的需求是子系统中最高的，显而易见的是，视频在PCI Express应占有一定的分量。显然，PCI Express的提出，并非是总线形式的一个结束。恰恰相反，其技术的成熟仍旧需要这个时间。当然了，趁这个时间，那些芯片、主板、视频等厂家是否能出来支持是PCI Express发展的关键。\n\nPCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”。这个新标准将全面取代现行的PCI和AGP，最终实现总线标准的统一。它的主要优势就是数据传输速率高，目前最高可达到10GB/s以上，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，芯片组。当然要实现全面取代PCI和AGP也需要一个相当长的过程，就象当初PCI取代ISA一样，都会有个过渡的过程。\n\n## PCI和PCIE有什么区别\n1. 在兼容性方面，PCI-E在软件层面上兼容目前的PCI技术和设备，支持PCI设备和内存模组的初始。\n2. 由于PCI总线只有133MB/s 的带宽，对声卡、网卡、视频卡等绝大多数输入/输出设备显得绰绰有余，但对性能日益强大的显卡则无法满足其需求。\n3. 目前PCI接口的显卡已经不多见了，只有较老的PC上才有，厂商也很少推出此类接口的产品。PCI显卡性能受到极大限制，并且由于数量稀少，因此价格也并不便宜，只有在不得已的情况才考虑使用PCI显卡。\n4. 因此，用于取代AGP接口的PCI-E接口位宽为X16，能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供约为4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。\n\nPCI(Peripheral Component Interconnect)外部设备互连总线是 英特尔（Intel）公司1991年下半年首先提出的，并得到IBM、Compad、AST、HP、和DEC等100多家计算机公司的响应，于1993年正式推出了PCI局部总线标准。此标准允许在计算机内安装多达10个遵从PCI标准的扩展卡。\n\nPCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”，简称“PCI-E”。","slug":"PCIE和PCI-计算机总线","published":1,"updated":"2024-05-08T19:47:58.626Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u628000adoy9djet2drv","content":"<h2 id=\"PCIE\"><a href=\"#PCIE\" class=\"headerlink\" title=\"PCIE\"></a>PCIE</h2><p>PCI Express是新一代的总线接口。早在2001年的春季，英特尔公司就提出了要用新一代的技术取代PCI总线和多种芯片的内部连接，并称之为第三代I/O总线技术。随后在2001年底，包括Intel、AMD、DELL、IBM在内的20多家业界主导公司开始起草新技术的规范，并在2002年完成，对其正式命名为PCI Express。它采用了目前业内流行的点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把数据传输率提高到一个很高的频率，达到PCI所不能提供的高带宽。</p>\n<h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>PCI Express的接口根据总线位宽不同而有所差异，包括X1、X4、X8以及X16（X2模式将用于内部接口而非插<br>槽模式）。较短的PCI Express卡可以插入较长的PCI Express插槽中使用。PCI Express接口能够支持热拔插，这也是个不小的飞跃。PCI Express卡支持的三种电压分别为+3.3V、3.3Vaux以及+12V。用于取代AGP接口的PCI Express接口位宽为X16，将能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。</p>\n<p><img src=\"\\blog\\images\\pasted-2.png\" alt=\"upload successful\"></p>\n<p>PCI Express规格从1条通道连接到32条通道连接，有非常强的伸缩性，以满足不同系统设备对数据传输带宽不同的需求。例如，PCI Express X1规格支持双向数据传输，每向数据传输带宽250MB/s，PCI Express X1已经可以满足主流声效芯片、网卡芯片和存储设备对数据传输带宽的需求，但是远远无法满足图形芯片对数据传输带宽的需求。因此，必须采用PCI Express X16，即16条点对点数据传输通道连接来取代传统的AGP总线。PCI Express X16也支持双向数据传输，每向数据传输带宽高达4GB/s，双向数据传输带宽有8GB/s之多，相比之下，广泛采用的AGP 8X数据传输只提供2.1GB/s的数据传输带宽。</p>\n<p>尽管PCI Express技术规格允许实现X1（250MB/秒），X2，X4，X8，X12，X16和X32通道规格，但是依形式来看，PCI Express X1和PCI Express X16将成为PCI Express主流规格，同时芯片组厂商将在南桥芯片当中添加对PCI Express X1的支持，在北桥芯片当中添加对PCI Express X16的支持。除去提供极高数据传输带宽之外，PCI Express因为采用串行数据包方式传递数据，所以PCI Express接口每个针脚可以获得比传统I/O标准更多的带宽，这样就可以降低PCI Express设备生产成本和体积。另外，PCI Express也支持高阶电源管理，支持热插拔，支持数据同步传输，为优先传输数据进行带宽优化。</p>\n<p><img src=\"\\blog\\images\\pasted-3.png\" alt=\"upload successful\"></p>\n<p>在兼容性方面，PCI Express在软件层面上兼容的PCI技术和设备，支持PCI设备和内存模组的初始化，也就是说驱动程序、操作系统无需推倒重来，就可以支持PCI Express设备。PCI Express是新一代能够提供大量带宽和丰富功能以实现令人激动的新式图形应用的全新架构。PCI Express可以为带宽渴求型应用分配相应的带宽，大幅提高中央处理器（CPU）和图形处理器（GPU）之间的带宽。对最终用户而言，他们可以感受影院级图象效果，并获得无缝多媒体体验。</p>\n<p>PCI Express的主要优势就是数据传输速率高，目前最高的16X 2.0版本可达到10GB/s，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，能满足一定时间内出现的低速设备和高速设备的需求。PCI-Express最新的接口是PCIe 3.0接口，其比特率为8GT/s，约为上一代产品带宽的两倍，并且包含发射器和接收器均衡、PLL改善以及时钟数据恢复等一系列重要的新功能，用以改善数据传输和数据保护性能。像INTEL、IBM、、LSI、OCZ、、三星(计划中)、SanDisk、STEC、SuperTalent和东芝(计划中)等，而针对海量的数据增长使得用户对规模更大、可扩展性更强的系统所应用，PCIe 3.0技术的加入最新的LSI MegaRAID控制器及HBA产品的出色性能，就可以实现更大的系统设计灵活性。</p>\n<p>PCI Express采用串行方式传输Data。它和原有的ISA、PCI和AGP总线不同。这种传输方式，不必因为某个硬件的频率而影响到整个系统性能的发挥。当然了，整个系统依然是一个整体，但是我们可以方便的提高某一频率低的硬件的频率，以便系统在没有瓶颈的环境下使用。以串行方式提升频率增进效能，关键的限制在于采用什么样的物理传输介质。人们普遍采用铜线路，而理论上铜这个材质可以提供的传输极限是10 Gbps。这也就是为什么PCI Express的极限传输速度的答案。</p>\n<p>因为PCI Express工作模式是一种称之为“电压差式传输”的方式。两条铜线，通过相互间的电压差来表示逻辑符号0和1。以这种方式进行资料传输，可以支持极高的运行频率。所以在速度达到10Gbps后，只需换用光纤（Fibre Channel）就可以使之效能倍增。</p>\n<p>PCI Express是下一阶段的主要传输总线带宽技术。然而，GPU对总线带宽的需求是子系统中最高的，显而易见的是，视频在PCI Express应占有一定的分量。显然，PCI Express的提出，并非是总线形式的一个结束。恰恰相反，其技术的成熟仍旧需要这个时间。当然了，趁这个时间，那些芯片、主板、视频等厂家是否能出来支持是PCI Express发展的关键。</p>\n<p>PCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”。这个新标准将全面取代现行的PCI和AGP，最终实现总线标准的统一。它的主要优势就是数据传输速率高，目前最高可达到10GB/s以上，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，芯片组。当然要实现全面取代PCI和AGP也需要一个相当长的过程，就象当初PCI取代ISA一样，都会有个过渡的过程。</p>\n<h2 id=\"PCI和PCIE有什么区别\"><a href=\"#PCI和PCIE有什么区别\" class=\"headerlink\" title=\"PCI和PCIE有什么区别\"></a>PCI和PCIE有什么区别</h2><ol>\n<li>在兼容性方面，PCI-E在软件层面上兼容目前的PCI技术和设备，支持PCI设备和内存模组的初始。</li>\n<li>由于PCI总线只有133MB/s 的带宽，对声卡、网卡、视频卡等绝大多数输入/输出设备显得绰绰有余，但对性能日益强大的显卡则无法满足其需求。</li>\n<li>目前PCI接口的显卡已经不多见了，只有较老的PC上才有，厂商也很少推出此类接口的产品。PCI显卡性能受到极大限制，并且由于数量稀少，因此价格也并不便宜，只有在不得已的情况才考虑使用PCI显卡。</li>\n<li>因此，用于取代AGP接口的PCI-E接口位宽为X16，能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供约为4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。</li>\n</ol>\n<p>PCI(Peripheral Component Interconnect)外部设备互连总线是 英特尔（Intel）公司1991年下半年首先提出的，并得到IBM、Compad、AST、HP、和DEC等100多家计算机公司的响应，于1993年正式推出了PCI局部总线标准。此标准允许在计算机内安装多达10个遵从PCI标准的扩展卡。</p>\n<p>PCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”，简称“PCI-E”。</p>\n","excerpt":"","more":"<h2 id=\"PCIE\"><a href=\"#PCIE\" class=\"headerlink\" title=\"PCIE\"></a>PCIE</h2><p>PCI Express是新一代的总线接口。早在2001年的春季，英特尔公司就提出了要用新一代的技术取代PCI总线和多种芯片的内部连接，并称之为第三代I/O总线技术。随后在2001年底，包括Intel、AMD、DELL、IBM在内的20多家业界主导公司开始起草新技术的规范，并在2002年完成，对其正式命名为PCI Express。它采用了目前业内流行的点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把数据传输率提高到一个很高的频率，达到PCI所不能提供的高带宽。</p>\n<h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>PCI Express的接口根据总线位宽不同而有所差异，包括X1、X4、X8以及X16（X2模式将用于内部接口而非插<br>槽模式）。较短的PCI Express卡可以插入较长的PCI Express插槽中使用。PCI Express接口能够支持热拔插，这也是个不小的飞跃。PCI Express卡支持的三种电压分别为+3.3V、3.3Vaux以及+12V。用于取代AGP接口的PCI Express接口位宽为X16，将能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。</p>\n<p><img src=\"\\blog\\images\\pasted-2.png\" alt=\"upload successful\"></p>\n<p>PCI Express规格从1条通道连接到32条通道连接，有非常强的伸缩性，以满足不同系统设备对数据传输带宽不同的需求。例如，PCI Express X1规格支持双向数据传输，每向数据传输带宽250MB/s，PCI Express X1已经可以满足主流声效芯片、网卡芯片和存储设备对数据传输带宽的需求，但是远远无法满足图形芯片对数据传输带宽的需求。因此，必须采用PCI Express X16，即16条点对点数据传输通道连接来取代传统的AGP总线。PCI Express X16也支持双向数据传输，每向数据传输带宽高达4GB/s，双向数据传输带宽有8GB/s之多，相比之下，广泛采用的AGP 8X数据传输只提供2.1GB/s的数据传输带宽。</p>\n<p>尽管PCI Express技术规格允许实现X1（250MB/秒），X2，X4，X8，X12，X16和X32通道规格，但是依形式来看，PCI Express X1和PCI Express X16将成为PCI Express主流规格，同时芯片组厂商将在南桥芯片当中添加对PCI Express X1的支持，在北桥芯片当中添加对PCI Express X16的支持。除去提供极高数据传输带宽之外，PCI Express因为采用串行数据包方式传递数据，所以PCI Express接口每个针脚可以获得比传统I/O标准更多的带宽，这样就可以降低PCI Express设备生产成本和体积。另外，PCI Express也支持高阶电源管理，支持热插拔，支持数据同步传输，为优先传输数据进行带宽优化。</p>\n<p><img src=\"\\blog\\images\\pasted-3.png\" alt=\"upload successful\"></p>\n<p>在兼容性方面，PCI Express在软件层面上兼容的PCI技术和设备，支持PCI设备和内存模组的初始化，也就是说驱动程序、操作系统无需推倒重来，就可以支持PCI Express设备。PCI Express是新一代能够提供大量带宽和丰富功能以实现令人激动的新式图形应用的全新架构。PCI Express可以为带宽渴求型应用分配相应的带宽，大幅提高中央处理器（CPU）和图形处理器（GPU）之间的带宽。对最终用户而言，他们可以感受影院级图象效果，并获得无缝多媒体体验。</p>\n<p>PCI Express的主要优势就是数据传输速率高，目前最高的16X 2.0版本可达到10GB/s，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，能满足一定时间内出现的低速设备和高速设备的需求。PCI-Express最新的接口是PCIe 3.0接口，其比特率为8GT/s，约为上一代产品带宽的两倍，并且包含发射器和接收器均衡、PLL改善以及时钟数据恢复等一系列重要的新功能，用以改善数据传输和数据保护性能。像INTEL、IBM、、LSI、OCZ、、三星(计划中)、SanDisk、STEC、SuperTalent和东芝(计划中)等，而针对海量的数据增长使得用户对规模更大、可扩展性更强的系统所应用，PCIe 3.0技术的加入最新的LSI MegaRAID控制器及HBA产品的出色性能，就可以实现更大的系统设计灵活性。</p>\n<p>PCI Express采用串行方式传输Data。它和原有的ISA、PCI和AGP总线不同。这种传输方式，不必因为某个硬件的频率而影响到整个系统性能的发挥。当然了，整个系统依然是一个整体，但是我们可以方便的提高某一频率低的硬件的频率，以便系统在没有瓶颈的环境下使用。以串行方式提升频率增进效能，关键的限制在于采用什么样的物理传输介质。人们普遍采用铜线路，而理论上铜这个材质可以提供的传输极限是10 Gbps。这也就是为什么PCI Express的极限传输速度的答案。</p>\n<p>因为PCI Express工作模式是一种称之为“电压差式传输”的方式。两条铜线，通过相互间的电压差来表示逻辑符号0和1。以这种方式进行资料传输，可以支持极高的运行频率。所以在速度达到10Gbps后，只需换用光纤（Fibre Channel）就可以使之效能倍增。</p>\n<p>PCI Express是下一阶段的主要传输总线带宽技术。然而，GPU对总线带宽的需求是子系统中最高的，显而易见的是，视频在PCI Express应占有一定的分量。显然，PCI Express的提出，并非是总线形式的一个结束。恰恰相反，其技术的成熟仍旧需要这个时间。当然了，趁这个时间，那些芯片、主板、视频等厂家是否能出来支持是PCI Express发展的关键。</p>\n<p>PCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”。这个新标准将全面取代现行的PCI和AGP，最终实现总线标准的统一。它的主要优势就是数据传输速率高，目前最高可达到10GB/s以上，而且还有相当大的发展潜力。PCI Express也有多种规格，从PCI Express 1X到PCI Express 16X，芯片组。当然要实现全面取代PCI和AGP也需要一个相当长的过程，就象当初PCI取代ISA一样，都会有个过渡的过程。</p>\n<h2 id=\"PCI和PCIE有什么区别\"><a href=\"#PCI和PCIE有什么区别\" class=\"headerlink\" title=\"PCI和PCIE有什么区别\"></a>PCI和PCIE有什么区别</h2><ol>\n<li>在兼容性方面，PCI-E在软件层面上兼容目前的PCI技术和设备，支持PCI设备和内存模组的初始。</li>\n<li>由于PCI总线只有133MB/s 的带宽，对声卡、网卡、视频卡等绝大多数输入/输出设备显得绰绰有余，但对性能日益强大的显卡则无法满足其需求。</li>\n<li>目前PCI接口的显卡已经不多见了，只有较老的PC上才有，厂商也很少推出此类接口的产品。PCI显卡性能受到极大限制，并且由于数量稀少，因此价格也并不便宜，只有在不得已的情况才考虑使用PCI显卡。</li>\n<li>因此，用于取代AGP接口的PCI-E接口位宽为X16，能够提供5GB/s的带宽，即便有编码上的损耗但仍能够提供约为4GB/s左右的实际带宽，远远超过AGP 8X的2.1GB/s的带宽。</li>\n</ol>\n<p>PCI(Peripheral Component Interconnect)外部设备互连总线是 英特尔（Intel）公司1991年下半年首先提出的，并得到IBM、Compad、AST、HP、和DEC等100多家计算机公司的响应，于1993年正式推出了PCI局部总线标准。此标准允许在计算机内安装多达10个遵从PCI标准的扩展卡。</p>\n<p>PCI-Express是最新的总线和接口标准，它原来的名称为“3GIO”，是由英特尔提出的，很明显英特尔的意思是它代表着下一代I/O接口标准。交由PCI-SIG（PCI特殊兴趣组织）认证发布后才改名为“PCI-Express”，简称“PCI-E”。</p>\n"},{"title":"RDMA技术详解","author":"Master.TJ","date":"2018-05-25T07:51:00.000Z","_content":"面对高性能计算、大数据分析和浪涌型IO高并发、低时延应用，现有TCP/IP软硬件架构和应用高CPU消耗的技术特征根本不能满足应用的需求。这要有体现在处理延时过大，数十微秒；多次内存拷贝、中断处理，上下文切换、复杂的TCP/IP协议处理、网络延时过大、存储转发模式和丢包导致额外延时。接下来我们继续讨论RDMA技术、原理和优势，看完文章你就会找到为什么RDMA可以更好的解决这一系列问题。\n\n![upload successful](\\blog\\images\\pasted-5.png)\n\nDMA是一种远端内存直接访问技术，详细介绍请参看文章。RDMA最早专属于Infiniband架构，随着在网络融合大趋势下出现的RoCE和iWARP，这使高速、超低延时、极低CPU使用率的RDMA得以部署在目前使用最广泛的以太网上。\n \nRDMAC（RDMA Consortium）和IBTA（InfiniBand Trade Association）主导了RDMA发展，RDMAC是IETF的一个补充并主要定义的是iWRAP和iSER，IBTA是infiniband的全部标准制定者，并补充了RoCE v1 v2的标准化。IBTA解释了RDMA传输过程中应具备的特性行为，而传输相关的Verbs接口和数据结构原型是由另一个组织OFA（Open Fabric Alliance）来完成。\n \n相比传统DMA的内部总线IO，RDMA通过网络在两个端点的应用软件之间实现Buffer的直接传递；相比比传统的网络传输，RDMA又无需操作系统和协议栈的介入。RDMA可以轻易实现端点间的超低延时、超高吞吐量传输，而且基本不需要CPU、OS等资源介入，也不必再为网络数据的处理和搬移耗费过多其他资源。   \n\n![upload successful](\\blog\\images\\pasted-6.png)\nInfiniBand通过以下技术保证网络转发的低时延（亚微秒级），采用Cut-Through转发模式，减少转发时延；基于Credit的流控机制，保证无丢包；硬件卸载；Buffer尽可能小，减少报文被缓冲的时延 。\n\n![upload successful](\\blog\\images\\pasted-7.png)\niWARP(RDMA over TCP/IP) 利用成熟的IP网络；继承RDMA的优点；TCP/IP硬件实现成本高，但如果采用传统IP网络丢包对性能影响大。\n\nRoCE性能与IB网络相当；DCB特性保证无丢包；需要以太网支持DCB特性；以太交换机时延比IB交换机时延要稍高一些。\n\n![upload successful](\\blog\\images\\pasted-8.png)\nRoCEv2针对RoCE进行了一些改进，如引入IP解决扩展性问题，可以跨二层组网；引入UDP解决ECMP负载分担等问题。\n\n![upload successful](\\blog\\images\\pasted-9.png)\n基于InfiniBand的RDMA是在2000年发布规范，属于原生RDMA；基于TCP/IP的RDMA称作iWARP，在 2007年形成标准，主要包括MPA/DDP/RDMAP三层子协议；基于Ethernet的RDMA叫做RoCE，在2010年发布协议，基于增强型以太网并将传输层换成IB传输层实现。\n \n扩展RDMA API接口以兼容现有协议/应用，OFED(Open Fabrics Enterprise Distribution)协议栈由OpenFabric联盟发布，分为Linux和windows版本，可以无缝兼容已有应用。通过使已有应用与RDMA结合后，性能成倍提升。\n\n![upload successful](\\blog\\images\\pasted-10.png)\n\n应用和RNIC（RDMA-aware network interface controller）之间的传输接口层（Software Transport Interface）被称为Verbs。OFA(Open Fabric Alliance)提供了RDMA传输的一系列Verbs API。OFA开发了OFED（Open Fabric Enterprise Distribution）协议栈，支持多种RDMA传输层协议。\n\n OFED向下除了提供RNIC(实现 RDMA 和LLP( Lower Layer Protocol))基本的队列消息服务外，向上还提供了ULP（Upper Layer Protocols），通过ULP上层应用不需直接和Verbs API对接，而是借助于ULP与应用对接，这样使得常见的应用不需要做修改就可以跑在RDMA传输层上。\n \n在Infiniband/RDMA的模型中，核心是如何实现应用之间最简单、高效和直接的通信。RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。\n\n消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP），每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。\n\n![upload successful](\\blog\\images\\pasted-11.png)\n\nRDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue（WQ）。在WQ中，用户的WR被转化为Work Queue Ellement（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。\n \nRDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。\n    \n对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：\n1. 首先，A和B都要创建并初始化好各自的QP，CQ\n2. A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。\n3. A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。\n4. AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。\n双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。\n \n对于单边操作，以存储网络环境下的存储为例(A作为文件系统，B作为存储介质)，数据的流程如下（RDMA READ）：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据被存档在A的buffer地址VA，注意VA应该提前注册到A的RNIC，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   A把数据地址VA，key封装到专用的报文传送到B，这相当于A把数据buffer的操作权交给了B。同时A在它的WQ中注册进一个WR，以用于接收数据传输的B返回的状态。\n4.   B在收到A的送过来的数据VA和R_key后，RNIC会把它们连同存储地址VB到封装RDMA READ，这个过程A、B两端不需要任何软件参与，就可以将A的数据存储到B的VB虚拟地址。\n5.   B在存储完成后，会向A返回整个数据传输的状态信息。\n\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n\nInfiniband的成功取决于两个因素，一是主机侧采用RDMA技术，可以把主机内数据处理的时延从几十微秒降低到几微秒，同时不占用CPU；二是InfiniBand网络的采用高带宽（40G/56G）、低时延（几百纳秒）和无丢包特性\n\n随着以太网的发展，也具备高带宽和无丢包能力，在时延方面也能接近InfiniBand交换机的性能，所以RDMA over Ethernet（RoCE）成为必然，且RoCE组网成本更低。未来RoCE、iWARP和Infiniband等基于RDMA技术产品都会得到长足的发展。","source":"_posts/RDMA技术详解.md","raw":"title: RDMA技术详解\nauthor: Master.TJ\ntags:\n  - RDMA\ncategories: []\ndate: 2018-05-25 15:51:00\n---\n面对高性能计算、大数据分析和浪涌型IO高并发、低时延应用，现有TCP/IP软硬件架构和应用高CPU消耗的技术特征根本不能满足应用的需求。这要有体现在处理延时过大，数十微秒；多次内存拷贝、中断处理，上下文切换、复杂的TCP/IP协议处理、网络延时过大、存储转发模式和丢包导致额外延时。接下来我们继续讨论RDMA技术、原理和优势，看完文章你就会找到为什么RDMA可以更好的解决这一系列问题。\n\n![upload successful](\\blog\\images\\pasted-5.png)\n\nDMA是一种远端内存直接访问技术，详细介绍请参看文章。RDMA最早专属于Infiniband架构，随着在网络融合大趋势下出现的RoCE和iWARP，这使高速、超低延时、极低CPU使用率的RDMA得以部署在目前使用最广泛的以太网上。\n \nRDMAC（RDMA Consortium）和IBTA（InfiniBand Trade Association）主导了RDMA发展，RDMAC是IETF的一个补充并主要定义的是iWRAP和iSER，IBTA是infiniband的全部标准制定者，并补充了RoCE v1 v2的标准化。IBTA解释了RDMA传输过程中应具备的特性行为，而传输相关的Verbs接口和数据结构原型是由另一个组织OFA（Open Fabric Alliance）来完成。\n \n相比传统DMA的内部总线IO，RDMA通过网络在两个端点的应用软件之间实现Buffer的直接传递；相比比传统的网络传输，RDMA又无需操作系统和协议栈的介入。RDMA可以轻易实现端点间的超低延时、超高吞吐量传输，而且基本不需要CPU、OS等资源介入，也不必再为网络数据的处理和搬移耗费过多其他资源。   \n\n![upload successful](\\blog\\images\\pasted-6.png)\nInfiniBand通过以下技术保证网络转发的低时延（亚微秒级），采用Cut-Through转发模式，减少转发时延；基于Credit的流控机制，保证无丢包；硬件卸载；Buffer尽可能小，减少报文被缓冲的时延 。\n\n![upload successful](\\blog\\images\\pasted-7.png)\niWARP(RDMA over TCP/IP) 利用成熟的IP网络；继承RDMA的优点；TCP/IP硬件实现成本高，但如果采用传统IP网络丢包对性能影响大。\n\nRoCE性能与IB网络相当；DCB特性保证无丢包；需要以太网支持DCB特性；以太交换机时延比IB交换机时延要稍高一些。\n\n![upload successful](\\blog\\images\\pasted-8.png)\nRoCEv2针对RoCE进行了一些改进，如引入IP解决扩展性问题，可以跨二层组网；引入UDP解决ECMP负载分担等问题。\n\n![upload successful](\\blog\\images\\pasted-9.png)\n基于InfiniBand的RDMA是在2000年发布规范，属于原生RDMA；基于TCP/IP的RDMA称作iWARP，在 2007年形成标准，主要包括MPA/DDP/RDMAP三层子协议；基于Ethernet的RDMA叫做RoCE，在2010年发布协议，基于增强型以太网并将传输层换成IB传输层实现。\n \n扩展RDMA API接口以兼容现有协议/应用，OFED(Open Fabrics Enterprise Distribution)协议栈由OpenFabric联盟发布，分为Linux和windows版本，可以无缝兼容已有应用。通过使已有应用与RDMA结合后，性能成倍提升。\n\n![upload successful](\\blog\\images\\pasted-10.png)\n\n应用和RNIC（RDMA-aware network interface controller）之间的传输接口层（Software Transport Interface）被称为Verbs。OFA(Open Fabric Alliance)提供了RDMA传输的一系列Verbs API。OFA开发了OFED（Open Fabric Enterprise Distribution）协议栈，支持多种RDMA传输层协议。\n\n OFED向下除了提供RNIC(实现 RDMA 和LLP( Lower Layer Protocol))基本的队列消息服务外，向上还提供了ULP（Upper Layer Protocols），通过ULP上层应用不需直接和Verbs API对接，而是借助于ULP与应用对接，这样使得常见的应用不需要做修改就可以跑在RDMA传输层上。\n \n在Infiniband/RDMA的模型中，核心是如何实现应用之间最简单、高效和直接的通信。RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。\n\n消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP），每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。\n\n![upload successful](\\blog\\images\\pasted-11.png)\n\nRDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue（WQ）。在WQ中，用户的WR被转化为Work Queue Ellement（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。\n \nRDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。\n    \n对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：\n1. 首先，A和B都要创建并初始化好各自的QP，CQ\n2. A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。\n3. A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。\n4. AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。\n双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。\n \n对于单边操作，以存储网络环境下的存储为例(A作为文件系统，B作为存储介质)，数据的流程如下（RDMA READ）：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据被存档在A的buffer地址VA，注意VA应该提前注册到A的RNIC，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   A把数据地址VA，key封装到专用的报文传送到B，这相当于A把数据buffer的操作权交给了B。同时A在它的WQ中注册进一个WR，以用于接收数据传输的B返回的状态。\n4.   B在收到A的送过来的数据VA和R_key后，RNIC会把它们连同存储地址VB到封装RDMA READ，这个过程A、B两端不需要任何软件参与，就可以将A的数据存储到B的VB虚拟地址。\n5.   B在存储完成后，会向A返回整个数据传输的状态信息。\n\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n\nInfiniband的成功取决于两个因素，一是主机侧采用RDMA技术，可以把主机内数据处理的时延从几十微秒降低到几微秒，同时不占用CPU；二是InfiniBand网络的采用高带宽（40G/56G）、低时延（几百纳秒）和无丢包特性\n\n随着以太网的发展，也具备高带宽和无丢包能力，在时延方面也能接近InfiniBand交换机的性能，所以RDMA over Ethernet（RoCE）成为必然，且RoCE组网成本更低。未来RoCE、iWARP和Infiniband等基于RDMA技术产品都会得到长足的发展。","slug":"RDMA技术详解","published":1,"updated":"2024-05-08T19:47:58.626Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u629000bdoy9b0goa7g2","content":"<p>面对高性能计算、大数据分析和浪涌型IO高并发、低时延应用，现有TCP/IP软硬件架构和应用高CPU消耗的技术特征根本不能满足应用的需求。这要有体现在处理延时过大，数十微秒；多次内存拷贝、中断处理，上下文切换、复杂的TCP/IP协议处理、网络延时过大、存储转发模式和丢包导致额外延时。接下来我们继续讨论RDMA技术、原理和优势，看完文章你就会找到为什么RDMA可以更好的解决这一系列问题。</p>\n<p><img src=\"\\blog\\images\\pasted-5.png\" alt=\"upload successful\"></p>\n<p>DMA是一种远端内存直接访问技术，详细介绍请参看文章。RDMA最早专属于Infiniband架构，随着在网络融合大趋势下出现的RoCE和iWARP，这使高速、超低延时、极低CPU使用率的RDMA得以部署在目前使用最广泛的以太网上。</p>\n<p>RDMAC（RDMA Consortium）和IBTA（InfiniBand Trade Association）主导了RDMA发展，RDMAC是IETF的一个补充并主要定义的是iWRAP和iSER，IBTA是infiniband的全部标准制定者，并补充了RoCE v1 v2的标准化。IBTA解释了RDMA传输过程中应具备的特性行为，而传输相关的Verbs接口和数据结构原型是由另一个组织OFA（Open Fabric Alliance）来完成。</p>\n<p>相比传统DMA的内部总线IO，RDMA通过网络在两个端点的应用软件之间实现Buffer的直接传递；相比比传统的网络传输，RDMA又无需操作系统和协议栈的介入。RDMA可以轻易实现端点间的超低延时、超高吞吐量传输，而且基本不需要CPU、OS等资源介入，也不必再为网络数据的处理和搬移耗费过多其他资源。   </p>\n<p><img src=\"\\blog\\images\\pasted-6.png\" alt=\"upload successful\"><br>InfiniBand通过以下技术保证网络转发的低时延（亚微秒级），采用Cut-Through转发模式，减少转发时延；基于Credit的流控机制，保证无丢包；硬件卸载；Buffer尽可能小，减少报文被缓冲的时延 。</p>\n<p><img src=\"\\blog\\images\\pasted-7.png\" alt=\"upload successful\"><br>iWARP(RDMA over TCP/IP) 利用成熟的IP网络；继承RDMA的优点；TCP/IP硬件实现成本高，但如果采用传统IP网络丢包对性能影响大。</p>\n<p>RoCE性能与IB网络相当；DCB特性保证无丢包；需要以太网支持DCB特性；以太交换机时延比IB交换机时延要稍高一些。</p>\n<p><img src=\"\\blog\\images\\pasted-8.png\" alt=\"upload successful\"><br>RoCEv2针对RoCE进行了一些改进，如引入IP解决扩展性问题，可以跨二层组网；引入UDP解决ECMP负载分担等问题。</p>\n<p><img src=\"\\blog\\images\\pasted-9.png\" alt=\"upload successful\"><br>基于InfiniBand的RDMA是在2000年发布规范，属于原生RDMA；基于TCP/IP的RDMA称作iWARP，在 2007年形成标准，主要包括MPA/DDP/RDMAP三层子协议；基于Ethernet的RDMA叫做RoCE，在2010年发布协议，基于增强型以太网并将传输层换成IB传输层实现。</p>\n<p>扩展RDMA API接口以兼容现有协议/应用，OFED(Open Fabrics Enterprise Distribution)协议栈由OpenFabric联盟发布，分为Linux和windows版本，可以无缝兼容已有应用。通过使已有应用与RDMA结合后，性能成倍提升。</p>\n<p><img src=\"\\blog\\images\\pasted-10.png\" alt=\"upload successful\"></p>\n<p>应用和RNIC（RDMA-aware network interface controller）之间的传输接口层（Software Transport Interface）被称为Verbs。OFA(Open Fabric Alliance)提供了RDMA传输的一系列Verbs API。OFA开发了OFED（Open Fabric Enterprise Distribution）协议栈，支持多种RDMA传输层协议。</p>\n<p> OFED向下除了提供RNIC(实现 RDMA 和LLP( Lower Layer Protocol))基本的队列消息服务外，向上还提供了ULP（Upper Layer Protocols），通过ULP上层应用不需直接和Verbs API对接，而是借助于ULP与应用对接，这样使得常见的应用不需要做修改就可以跑在RDMA传输层上。</p>\n<p>在Infiniband/RDMA的模型中，核心是如何实现应用之间最简单、高效和直接的通信。RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。</p>\n<p>消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP），每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。</p>\n<p><img src=\"\\blog\\images\\pasted-11.png\" alt=\"upload successful\"></p>\n<p>RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue（WQ）。在WQ中，用户的WR被转化为Work Queue Ellement（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。</p>\n<p>RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。</p>\n<p>对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：</p>\n<ol>\n<li>首先，A和B都要创建并初始化好各自的QP，CQ</li>\n<li>A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。</li>\n<li>A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。</li>\n<li>AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。<br>双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。</li>\n</ol>\n<p>对于单边操作，以存储网络环境下的存储为例(A作为文件系统，B作为存储介质)，数据的流程如下（RDMA READ）：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据被存档在A的buffer地址VA，注意VA应该提前注册到A的RNIC，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>A把数据地址VA，key封装到专用的报文传送到B，这相当于A把数据buffer的操作权交给了B。同时A在它的WQ中注册进一个WR，以用于接收数据传输的B返回的状态。</li>\n<li>B在收到A的送过来的数据VA和R_key后，RNIC会把它们连同存储地址VB到封装RDMA READ，这个过程A、B两端不需要任何软件参与，就可以将A的数据存储到B的VB虚拟地址。</li>\n<li>B在存储完成后，会向A返回整个数据传输的状态信息。</li>\n</ol>\n<p>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>Infiniband的成功取决于两个因素，一是主机侧采用RDMA技术，可以把主机内数据处理的时延从几十微秒降低到几微秒，同时不占用CPU；二是InfiniBand网络的采用高带宽（40G/56G）、低时延（几百纳秒）和无丢包特性</p>\n<p>随着以太网的发展，也具备高带宽和无丢包能力，在时延方面也能接近InfiniBand交换机的性能，所以RDMA over Ethernet（RoCE）成为必然，且RoCE组网成本更低。未来RoCE、iWARP和Infiniband等基于RDMA技术产品都会得到长足的发展。</p>\n","excerpt":"","more":"<p>面对高性能计算、大数据分析和浪涌型IO高并发、低时延应用，现有TCP/IP软硬件架构和应用高CPU消耗的技术特征根本不能满足应用的需求。这要有体现在处理延时过大，数十微秒；多次内存拷贝、中断处理，上下文切换、复杂的TCP/IP协议处理、网络延时过大、存储转发模式和丢包导致额外延时。接下来我们继续讨论RDMA技术、原理和优势，看完文章你就会找到为什么RDMA可以更好的解决这一系列问题。</p>\n<p><img src=\"\\blog\\images\\pasted-5.png\" alt=\"upload successful\"></p>\n<p>DMA是一种远端内存直接访问技术，详细介绍请参看文章。RDMA最早专属于Infiniband架构，随着在网络融合大趋势下出现的RoCE和iWARP，这使高速、超低延时、极低CPU使用率的RDMA得以部署在目前使用最广泛的以太网上。</p>\n<p>RDMAC（RDMA Consortium）和IBTA（InfiniBand Trade Association）主导了RDMA发展，RDMAC是IETF的一个补充并主要定义的是iWRAP和iSER，IBTA是infiniband的全部标准制定者，并补充了RoCE v1 v2的标准化。IBTA解释了RDMA传输过程中应具备的特性行为，而传输相关的Verbs接口和数据结构原型是由另一个组织OFA（Open Fabric Alliance）来完成。</p>\n<p>相比传统DMA的内部总线IO，RDMA通过网络在两个端点的应用软件之间实现Buffer的直接传递；相比比传统的网络传输，RDMA又无需操作系统和协议栈的介入。RDMA可以轻易实现端点间的超低延时、超高吞吐量传输，而且基本不需要CPU、OS等资源介入，也不必再为网络数据的处理和搬移耗费过多其他资源。   </p>\n<p><img src=\"\\blog\\images\\pasted-6.png\" alt=\"upload successful\"><br>InfiniBand通过以下技术保证网络转发的低时延（亚微秒级），采用Cut-Through转发模式，减少转发时延；基于Credit的流控机制，保证无丢包；硬件卸载；Buffer尽可能小，减少报文被缓冲的时延 。</p>\n<p><img src=\"\\blog\\images\\pasted-7.png\" alt=\"upload successful\"><br>iWARP(RDMA over TCP/IP) 利用成熟的IP网络；继承RDMA的优点；TCP/IP硬件实现成本高，但如果采用传统IP网络丢包对性能影响大。</p>\n<p>RoCE性能与IB网络相当；DCB特性保证无丢包；需要以太网支持DCB特性；以太交换机时延比IB交换机时延要稍高一些。</p>\n<p><img src=\"\\blog\\images\\pasted-8.png\" alt=\"upload successful\"><br>RoCEv2针对RoCE进行了一些改进，如引入IP解决扩展性问题，可以跨二层组网；引入UDP解决ECMP负载分担等问题。</p>\n<p><img src=\"\\blog\\images\\pasted-9.png\" alt=\"upload successful\"><br>基于InfiniBand的RDMA是在2000年发布规范，属于原生RDMA；基于TCP/IP的RDMA称作iWARP，在 2007年形成标准，主要包括MPA/DDP/RDMAP三层子协议；基于Ethernet的RDMA叫做RoCE，在2010年发布协议，基于增强型以太网并将传输层换成IB传输层实现。</p>\n<p>扩展RDMA API接口以兼容现有协议/应用，OFED(Open Fabrics Enterprise Distribution)协议栈由OpenFabric联盟发布，分为Linux和windows版本，可以无缝兼容已有应用。通过使已有应用与RDMA结合后，性能成倍提升。</p>\n<p><img src=\"\\blog\\images\\pasted-10.png\" alt=\"upload successful\"></p>\n<p>应用和RNIC（RDMA-aware network interface controller）之间的传输接口层（Software Transport Interface）被称为Verbs。OFA(Open Fabric Alliance)提供了RDMA传输的一系列Verbs API。OFA开发了OFED（Open Fabric Enterprise Distribution）协议栈，支持多种RDMA传输层协议。</p>\n<p> OFED向下除了提供RNIC(实现 RDMA 和LLP( Lower Layer Protocol))基本的队列消息服务外，向上还提供了ULP（Upper Layer Protocols），通过ULP上层应用不需直接和Verbs API对接，而是借助于ULP与应用对接，这样使得常见的应用不需要做修改就可以跑在RDMA传输层上。</p>\n<p>在Infiniband/RDMA的模型中，核心是如何实现应用之间最简单、高效和直接的通信。RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。</p>\n<p>消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP），每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。</p>\n<p><img src=\"\\blog\\images\\pasted-11.png\" alt=\"upload successful\"></p>\n<p>RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue（WQ）。在WQ中，用户的WR被转化为Work Queue Ellement（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。</p>\n<p>RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。</p>\n<p>对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：</p>\n<ol>\n<li>首先，A和B都要创建并初始化好各自的QP，CQ</li>\n<li>A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。</li>\n<li>A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。</li>\n<li>AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。<br>双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。</li>\n</ol>\n<p>对于单边操作，以存储网络环境下的存储为例(A作为文件系统，B作为存储介质)，数据的流程如下（RDMA READ）：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据被存档在A的buffer地址VA，注意VA应该提前注册到A的RNIC，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>A把数据地址VA，key封装到专用的报文传送到B，这相当于A把数据buffer的操作权交给了B。同时A在它的WQ中注册进一个WR，以用于接收数据传输的B返回的状态。</li>\n<li>B在收到A的送过来的数据VA和R_key后，RNIC会把它们连同存储地址VB到封装RDMA READ，这个过程A、B两端不需要任何软件参与，就可以将A的数据存储到B的VB虚拟地址。</li>\n<li>B在存储完成后，会向A返回整个数据传输的状态信息。</li>\n</ol>\n<p>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>Infiniband的成功取决于两个因素，一是主机侧采用RDMA技术，可以把主机内数据处理的时延从几十微秒降低到几微秒，同时不占用CPU；二是InfiniBand网络的采用高带宽（40G/56G）、低时延（几百纳秒）和无丢包特性</p>\n<p>随着以太网的发展，也具备高带宽和无丢包能力，在时延方面也能接近InfiniBand交换机的性能，所以RDMA over Ethernet（RoCE）成为必然，且RoCE组网成本更低。未来RoCE、iWARP和Infiniband等基于RDMA技术产品都会得到长足的发展。</p>\n"},{"title":"Sub-millisecond Stateful Stream Querying over Fast-evolving Linked Data","author":"Master.TJ","date":"2018-05-25T08:01:00.000Z","_content":"### ABSTRACT\n场景：社交网络，城市监控和市场馈送处理等应用需要有状态的流式查询，状态流查询不仅要查询流式数据，还要查询存储的数据来及时提取有用的信息。实时流数据提供的有用信息，也需要持续不断地整合到存储的数据中，以便为上述和未来提供查询服务。\n然而，先前的流式处理系统或者侧重于流计算，或者不是有状态的，或者不能提供低延迟和高吞吐量来处理快速发展的Linked数据，并且能够支持不断增加的查询并发性。\nWukong + S采用集成设计，将流处理和持久化存储相结合，实现高效的状态共享，避免了传统复合设计（如Storm / Heron + Wukong）中的跨系统成本和次优查询性能。 Wukong + S使用混合存储来区分管理持久的数据和瞬时数据，并提供有效的流索引和本地分区，以便快速访问流数据。 Wukong + S进一步提供分散的矢量时间戳和有界的快照标量化，以节省内存使用量的节点和大量查询。\n\n### INTRODUCTION：\n\n#### 问题提出场景：\n随着流数据和存储数据量的不断增加，及时查询有用的信息十分重要。对于公共数据集合数据流，可能有大量的用户不同的数据流查询请求，因此需要支持高并发的查询。而且流数据通常包含巨大的有用信息， 这样的数据应该被一致地和立即地整合到存储系统，以用于将来的连续查询。\n现有的工作：然而目前现有的系统对于正在变化的数据集的侧重点在于流计算。流计算和流查询不同的是 前者通常倾向于对大部分流数据进行序列化计算，而后者侧重于对流和存储数据的特定集合的并发查询。大多数先前的系统也没有集成流数据为了并发的查询中，或者不查询持久化存储的历史数据来获得基础知识，因此是无状态的。 尽管大多数流处理数据库都明确支持语义和SQL接口，但是他们在快速演化的Linked 数据下，当面临大量并发的查询请求下，由于高昂的Join操作开销和一些ACID的语义，他们的查询性能是低效的。\n\n#### 解决方案：\n1. Wukong-S为了尊重数据本地化并最大限度地减少数据传输，它使用由基于时间的临时存储和连续持久化存储组成的混合存储，为正在到来的数据和持久化的数据提供不同的存储管理。\n2. Wukong + S提供了流数据的快速访问流索引。流数据通过局部感知分区进行分片，其中一些流索引在节点间动态复制。这节省了查询成本并提供高效的负载平衡。\n3. 为了在多个不同规模的流数据上提供一致的流查询，Wukong + S使用分散的矢量时间戳来推导出最近一致性状态的流式数据插入。Wukong + S使用有限的标量化方案将矢量时间戳投影到标量快照数量中，通过协调多个流的更新到底层持久存储区。这样的设计在有效的内存使用情况下扩展了Wukong + S节点和大量查询。\n\n### MOTIVATION\n根据工作负载特性，提出了一条流旨在支持大量的查询系统(连续的和一次性的)对流和存储的查询数据。有几种独特的需求可以区分来自其他流系统的流查询系统。\n\n![upload successful](\\blog\\images\\pasted-16.png)\n\n![upload successful](\\blog\\images\\pasted-17.png)\n\t\t\t\t\t\t\t\t\t\t\t\n### APPROACH ANN OVERVIEW\n\n![upload successful](\\blog\\images\\pasted-18.png)\n\n目前存在的系统采用的是讲流处理系统和以查询为主导的存储系统简单结合。简单的组合设计会造成性能低效的结果。比如讲Esper和Apahe Jena组合\n1. Issue1. Cross-system Cost\n2. Issue2. Sub-optimal query plan \n3. Issue3. Limited scalability\n\nWukong+S做的就是一个整体设计。Wukong+ S使用了一个内置的设计，目标是对流和存储数据进行连续和一次性的查询。关键的设计原则就是对待持久化的存储作为关键的解决方案\n\n","source":"_posts/Sub-millisecond-Stateful-Stream-Querying-over-Fast-evolving-Linked-Data.md","raw":"title: Sub-millisecond Stateful Stream Querying over Fast-evolving Linked Data\nauthor: Master.TJ\ntags: []\ncategories:\n  - 研究生论文研读\ndate: 2018-05-25 16:01:00\n---\n### ABSTRACT\n场景：社交网络，城市监控和市场馈送处理等应用需要有状态的流式查询，状态流查询不仅要查询流式数据，还要查询存储的数据来及时提取有用的信息。实时流数据提供的有用信息，也需要持续不断地整合到存储的数据中，以便为上述和未来提供查询服务。\n然而，先前的流式处理系统或者侧重于流计算，或者不是有状态的，或者不能提供低延迟和高吞吐量来处理快速发展的Linked数据，并且能够支持不断增加的查询并发性。\nWukong + S采用集成设计，将流处理和持久化存储相结合，实现高效的状态共享，避免了传统复合设计（如Storm / Heron + Wukong）中的跨系统成本和次优查询性能。 Wukong + S使用混合存储来区分管理持久的数据和瞬时数据，并提供有效的流索引和本地分区，以便快速访问流数据。 Wukong + S进一步提供分散的矢量时间戳和有界的快照标量化，以节省内存使用量的节点和大量查询。\n\n### INTRODUCTION：\n\n#### 问题提出场景：\n随着流数据和存储数据量的不断增加，及时查询有用的信息十分重要。对于公共数据集合数据流，可能有大量的用户不同的数据流查询请求，因此需要支持高并发的查询。而且流数据通常包含巨大的有用信息， 这样的数据应该被一致地和立即地整合到存储系统，以用于将来的连续查询。\n现有的工作：然而目前现有的系统对于正在变化的数据集的侧重点在于流计算。流计算和流查询不同的是 前者通常倾向于对大部分流数据进行序列化计算，而后者侧重于对流和存储数据的特定集合的并发查询。大多数先前的系统也没有集成流数据为了并发的查询中，或者不查询持久化存储的历史数据来获得基础知识，因此是无状态的。 尽管大多数流处理数据库都明确支持语义和SQL接口，但是他们在快速演化的Linked 数据下，当面临大量并发的查询请求下，由于高昂的Join操作开销和一些ACID的语义，他们的查询性能是低效的。\n\n#### 解决方案：\n1. Wukong-S为了尊重数据本地化并最大限度地减少数据传输，它使用由基于时间的临时存储和连续持久化存储组成的混合存储，为正在到来的数据和持久化的数据提供不同的存储管理。\n2. Wukong + S提供了流数据的快速访问流索引。流数据通过局部感知分区进行分片，其中一些流索引在节点间动态复制。这节省了查询成本并提供高效的负载平衡。\n3. 为了在多个不同规模的流数据上提供一致的流查询，Wukong + S使用分散的矢量时间戳来推导出最近一致性状态的流式数据插入。Wukong + S使用有限的标量化方案将矢量时间戳投影到标量快照数量中，通过协调多个流的更新到底层持久存储区。这样的设计在有效的内存使用情况下扩展了Wukong + S节点和大量查询。\n\n### MOTIVATION\n根据工作负载特性，提出了一条流旨在支持大量的查询系统(连续的和一次性的)对流和存储的查询数据。有几种独特的需求可以区分来自其他流系统的流查询系统。\n\n![upload successful](\\blog\\images\\pasted-16.png)\n\n![upload successful](\\blog\\images\\pasted-17.png)\n\t\t\t\t\t\t\t\t\t\t\t\n### APPROACH ANN OVERVIEW\n\n![upload successful](\\blog\\images\\pasted-18.png)\n\n目前存在的系统采用的是讲流处理系统和以查询为主导的存储系统简单结合。简单的组合设计会造成性能低效的结果。比如讲Esper和Apahe Jena组合\n1. Issue1. Cross-system Cost\n2. Issue2. Sub-optimal query plan \n3. Issue3. Limited scalability\n\nWukong+S做的就是一个整体设计。Wukong+ S使用了一个内置的设计，目标是对流和存储数据进行连续和一次性的查询。关键的设计原则就是对待持久化的存储作为关键的解决方案\n\n","slug":"Sub-millisecond-Stateful-Stream-Querying-over-Fast-evolving-Linked-Data","published":1,"updated":"2024-05-08T19:47:58.626Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62a000cdoy9gj1x6hsx","content":"<h3 id=\"ABSTRACT\"><a href=\"#ABSTRACT\" class=\"headerlink\" title=\"ABSTRACT\"></a>ABSTRACT</h3><p>场景：社交网络，城市监控和市场馈送处理等应用需要有状态的流式查询，状态流查询不仅要查询流式数据，还要查询存储的数据来及时提取有用的信息。实时流数据提供的有用信息，也需要持续不断地整合到存储的数据中，以便为上述和未来提供查询服务。<br>然而，先前的流式处理系统或者侧重于流计算，或者不是有状态的，或者不能提供低延迟和高吞吐量来处理快速发展的Linked数据，并且能够支持不断增加的查询并发性。<br>Wukong + S采用集成设计，将流处理和持久化存储相结合，实现高效的状态共享，避免了传统复合设计（如Storm / Heron + Wukong）中的跨系统成本和次优查询性能。 Wukong + S使用混合存储来区分管理持久的数据和瞬时数据，并提供有效的流索引和本地分区，以便快速访问流数据。 Wukong + S进一步提供分散的矢量时间戳和有界的快照标量化，以节省内存使用量的节点和大量查询。</p>\n<h3 id=\"INTRODUCTION：\"><a href=\"#INTRODUCTION：\" class=\"headerlink\" title=\"INTRODUCTION：\"></a>INTRODUCTION：</h3><h4 id=\"问题提出场景：\"><a href=\"#问题提出场景：\" class=\"headerlink\" title=\"问题提出场景：\"></a>问题提出场景：</h4><p>随着流数据和存储数据量的不断增加，及时查询有用的信息十分重要。对于公共数据集合数据流，可能有大量的用户不同的数据流查询请求，因此需要支持高并发的查询。而且流数据通常包含巨大的有用信息， 这样的数据应该被一致地和立即地整合到存储系统，以用于将来的连续查询。<br>现有的工作：然而目前现有的系统对于正在变化的数据集的侧重点在于流计算。流计算和流查询不同的是 前者通常倾向于对大部分流数据进行序列化计算，而后者侧重于对流和存储数据的特定集合的并发查询。大多数先前的系统也没有集成流数据为了并发的查询中，或者不查询持久化存储的历史数据来获得基础知识，因此是无状态的。 尽管大多数流处理数据库都明确支持语义和SQL接口，但是他们在快速演化的Linked 数据下，当面临大量并发的查询请求下，由于高昂的Join操作开销和一些ACID的语义，他们的查询性能是低效的。</p>\n<h4 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h4><ol>\n<li>Wukong-S为了尊重数据本地化并最大限度地减少数据传输，它使用由基于时间的临时存储和连续持久化存储组成的混合存储，为正在到来的数据和持久化的数据提供不同的存储管理。</li>\n<li>Wukong + S提供了流数据的快速访问流索引。流数据通过局部感知分区进行分片，其中一些流索引在节点间动态复制。这节省了查询成本并提供高效的负载平衡。</li>\n<li>为了在多个不同规模的流数据上提供一致的流查询，Wukong + S使用分散的矢量时间戳来推导出最近一致性状态的流式数据插入。Wukong + S使用有限的标量化方案将矢量时间戳投影到标量快照数量中，通过协调多个流的更新到底层持久存储区。这样的设计在有效的内存使用情况下扩展了Wukong + S节点和大量查询。</li>\n</ol>\n<h3 id=\"MOTIVATION\"><a href=\"#MOTIVATION\" class=\"headerlink\" title=\"MOTIVATION\"></a>MOTIVATION</h3><p>根据工作负载特性，提出了一条流旨在支持大量的查询系统(连续的和一次性的)对流和存储的查询数据。有几种独特的需求可以区分来自其他流系统的流查询系统。</p>\n<p><img src=\"\\blog\\images\\pasted-16.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-17.png\" alt=\"upload successful\"></p>\n<h3 id=\"APPROACH-ANN-OVERVIEW\"><a href=\"#APPROACH-ANN-OVERVIEW\" class=\"headerlink\" title=\"APPROACH ANN OVERVIEW\"></a>APPROACH ANN OVERVIEW</h3><p><img src=\"\\blog\\images\\pasted-18.png\" alt=\"upload successful\"></p>\n<p>目前存在的系统采用的是讲流处理系统和以查询为主导的存储系统简单结合。简单的组合设计会造成性能低效的结果。比如讲Esper和Apahe Jena组合</p>\n<ol>\n<li>Issue1. Cross-system Cost</li>\n<li>Issue2. Sub-optimal query plan </li>\n<li>Issue3. Limited scalability</li>\n</ol>\n<p>Wukong+S做的就是一个整体设计。Wukong+ S使用了一个内置的设计，目标是对流和存储数据进行连续和一次性的查询。关键的设计原则就是对待持久化的存储作为关键的解决方案</p>\n","excerpt":"","more":"<h3 id=\"ABSTRACT\"><a href=\"#ABSTRACT\" class=\"headerlink\" title=\"ABSTRACT\"></a>ABSTRACT</h3><p>场景：社交网络，城市监控和市场馈送处理等应用需要有状态的流式查询，状态流查询不仅要查询流式数据，还要查询存储的数据来及时提取有用的信息。实时流数据提供的有用信息，也需要持续不断地整合到存储的数据中，以便为上述和未来提供查询服务。<br>然而，先前的流式处理系统或者侧重于流计算，或者不是有状态的，或者不能提供低延迟和高吞吐量来处理快速发展的Linked数据，并且能够支持不断增加的查询并发性。<br>Wukong + S采用集成设计，将流处理和持久化存储相结合，实现高效的状态共享，避免了传统复合设计（如Storm / Heron + Wukong）中的跨系统成本和次优查询性能。 Wukong + S使用混合存储来区分管理持久的数据和瞬时数据，并提供有效的流索引和本地分区，以便快速访问流数据。 Wukong + S进一步提供分散的矢量时间戳和有界的快照标量化，以节省内存使用量的节点和大量查询。</p>\n<h3 id=\"INTRODUCTION：\"><a href=\"#INTRODUCTION：\" class=\"headerlink\" title=\"INTRODUCTION：\"></a>INTRODUCTION：</h3><h4 id=\"问题提出场景：\"><a href=\"#问题提出场景：\" class=\"headerlink\" title=\"问题提出场景：\"></a>问题提出场景：</h4><p>随着流数据和存储数据量的不断增加，及时查询有用的信息十分重要。对于公共数据集合数据流，可能有大量的用户不同的数据流查询请求，因此需要支持高并发的查询。而且流数据通常包含巨大的有用信息， 这样的数据应该被一致地和立即地整合到存储系统，以用于将来的连续查询。<br>现有的工作：然而目前现有的系统对于正在变化的数据集的侧重点在于流计算。流计算和流查询不同的是 前者通常倾向于对大部分流数据进行序列化计算，而后者侧重于对流和存储数据的特定集合的并发查询。大多数先前的系统也没有集成流数据为了并发的查询中，或者不查询持久化存储的历史数据来获得基础知识，因此是无状态的。 尽管大多数流处理数据库都明确支持语义和SQL接口，但是他们在快速演化的Linked 数据下，当面临大量并发的查询请求下，由于高昂的Join操作开销和一些ACID的语义，他们的查询性能是低效的。</p>\n<h4 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h4><ol>\n<li>Wukong-S为了尊重数据本地化并最大限度地减少数据传输，它使用由基于时间的临时存储和连续持久化存储组成的混合存储，为正在到来的数据和持久化的数据提供不同的存储管理。</li>\n<li>Wukong + S提供了流数据的快速访问流索引。流数据通过局部感知分区进行分片，其中一些流索引在节点间动态复制。这节省了查询成本并提供高效的负载平衡。</li>\n<li>为了在多个不同规模的流数据上提供一致的流查询，Wukong + S使用分散的矢量时间戳来推导出最近一致性状态的流式数据插入。Wukong + S使用有限的标量化方案将矢量时间戳投影到标量快照数量中，通过协调多个流的更新到底层持久存储区。这样的设计在有效的内存使用情况下扩展了Wukong + S节点和大量查询。</li>\n</ol>\n<h3 id=\"MOTIVATION\"><a href=\"#MOTIVATION\" class=\"headerlink\" title=\"MOTIVATION\"></a>MOTIVATION</h3><p>根据工作负载特性，提出了一条流旨在支持大量的查询系统(连续的和一次性的)对流和存储的查询数据。有几种独特的需求可以区分来自其他流系统的流查询系统。</p>\n<p><img src=\"\\blog\\images\\pasted-16.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-17.png\" alt=\"upload successful\"></p>\n<h3 id=\"APPROACH-ANN-OVERVIEW\"><a href=\"#APPROACH-ANN-OVERVIEW\" class=\"headerlink\" title=\"APPROACH ANN OVERVIEW\"></a>APPROACH ANN OVERVIEW</h3><p><img src=\"\\blog\\images\\pasted-18.png\" alt=\"upload successful\"></p>\n<p>目前存在的系统采用的是讲流处理系统和以查询为主导的存储系统简单结合。简单的组合设计会造成性能低效的结果。比如讲Esper和Apahe Jena组合</p>\n<ol>\n<li>Issue1. Cross-system Cost</li>\n<li>Issue2. Sub-optimal query plan </li>\n<li>Issue3. Limited scalability</li>\n</ol>\n<p>Wukong+S做的就是一个整体设计。Wukong+ S使用了一个内置的设计，目标是对流和存储数据进行连续和一次性的查询。关键的设计原则就是对待持久化的存储作为关键的解决方案</p>\n"},{"title":"TUX2: Distributed Graph Computation for Machine Learning","author":"Master.TJ","date":"2018-05-25T09:27:00.000Z","_content":"## Introduce\n在图形引擎（如GraphLab [29]）上的早期工作是基于机器学习的动机，基于观察到许多机器学习问题可以用图形自然而有效地建模，并通过迭代收敛算法解决。\n\n### 问题：\n然而，大多数后续的图形引擎工作都采用简单的图计算模型，由PageRank等基本图形基准测试驱动。 由此产生的图形引擎缺乏高效分布式机器学习的灵活性和其他关键功能。\n\n1. Heterogeneous vertices：在机器学习中，顶点都有不同的属性。然而在图计算中，图引擎一般都只含有一个属性的顶点。这样对于机器学习算法来说，会带来更多的编程复杂性和性能低下。\n2. Mini-Batch：Mini-Batch是一个十分重要的概念在机器学习中。但是在图计算中缺没有这样的概念，Min-Batch意味着在机器学习中，训练一部分子集然后更新整个模型。\n![upload successful](\\blog\\images\\pasted-19.png)\n3. Flexible consistency\n 在分布式图处理系统中，多个Worker一起工作处理整个图。在每次迭代的结束，图引擎会有一个很严重的Barrier限制。然而在Min-Bach中，Hard Barrier在多个Mini-Batch中会造成太多的同步开销。由于机器算法可以容忍这样的状态。所以它们使用这样一种Soft Barrier的机制 进行局部同步。\n![upload successful](\\blog\\images\\pasted-20.png)\n\n作者提出TUX2，一个分布式图形引擎，用于在图模型中表示的机器学习算法。 TUX2保留了图计算的好处，同时还支持过时同步并行（SSP）模型[20,11,42,13]，异构数据模型和新的MEGA（小批量，Exchange，GlobalSync和 应用）图形模型以实现高效的分布式机器学习.\n\n## TuX2 Desgin\nTUX2旨在保留图形引擎的优势，同时将其数据模型，编程模型和调度方法扩展到分布式机器学习。\n\nTUX2使用顶点切割方法(vertex-cut)，其中（高度）顶点的边集可以分成多个分区，每个分区保持顶点的副本。其中一个副本被指定为Master顶点;它维护顶点数据的主版本。所有剩余的副本都称为Mirror顶点，并且每个副本都维护一个本地缓存副本。我们采用顶点切割是因为它在处理幂律图中被证明是有效的，并且它自然地连接到参数服务器模型（paraemter-server model）[26,11]：所有顶点数据的主版本可以被视为（分布式）全局状态存储在参数服务器中。在每个分区中，TUX2将顶点和边保持在单独的数组中。Edge数组中的Edge按source vertex分组。每个顶点都有一个索引，给出它在Edge数组中的边集的偏移量。每条边都包含诸如包含目标顶点的分区的ID和相应顶点数组中该顶点的索引等信息。该图形数据结构适用于遍历，并且使用查找表优于顶点索引。\n\n每个分区都由一个进程管理，该进程在逻辑上同时扮演一个Worker角色，计算分区中的顶点并沿着Edge传播顶点数据，以及一个Server角色，以同步镜像顶点与其相对应Master顶点之间的状态。 在进程内部，TUX2使用多个线程进行并行化，并将分区的Server角色和Worker角色分配给同一个线程。 然后每个线程负责计算用于本地计算的Mirrors顶点子集，并维护进程拥有的分区中Master顶点子集的状态。 图2显示了数据在TUX2中如何分区，存储和分配给执行角色。\n\n![upload successful](\\blog\\images\\pasted-21.png)\n### Heterogenous Data Layout\n\n虽然传统图形引擎简单地假设了一个同质图，但TUX2支持多种数据布局维度的异构性，包括顶点类型和分区方法; 它甚至支持主点和镜像顶点数据类型之间的异构性。 \n\nTux2重点介绍二分图上的优化，因为许多机器学习问题自然地映射为具有两个不相交顶点集的二部图，例如MF中的用户和项目，LR中的特征和样本等等。 因此这两组顶点通常具有不同的属性。 例如，在LR的情况下，只有特征顶点包含权重字段，并且只有样本顶点包含目标标签字段。 而且，在像BlockPG [27]这样的LR变体中，特征顶点也维护着过去的历史信息。因此，TUX2允许用户定义不同的顶点类型，并将不同类型的顶点放置在不同的数组中。 这导致紧凑的数据表示，从而改善计算过程中的数据局部性。此外不同的顶点类型可能包含不同的顶点度数。例如，在用户项目图中，项目顶点可以链接到数千个用户，但用户顶点通常仅链接到数十个项目。TUX2使用PowerLyra [7]和BiGraph [8]中提出的二分图感知分区算法，以便只有高度顶点才具有Mirror 顶点。\n\n在二分图中，TUX2可以通过扫描一个类型的顶点来列举所有的边。列举边类型的选择有时具有显著的性能影响。用Mini-Batch来扫描镜像顶点会导致更有效的同步步骤，只要TUX2能够识别有更新的镜像集合，这些镜像会与它们的Master同步，因为这些顶点被连续地放置在数组中。相比之下，如果TUX2在一个Mini-Batch中扫描没有镜像的顶点，那么在扫描过程中为其他顶点类型更新的镜像将被分散，从而更昂贵的定位。因此，TUX2允许用户指定在计算过程中需要计算的顶点集。\n\n![upload successful](\\blog\\images\\pasted-22.png)\nFigure3 显示了如何在二分图下组织顶点数据，并以用户-项目图中的MF为例。由于用户顶点的度数一般都比较小，所有只有项目顶点使用点划分方法切割顶点。因此，Server角色中的Master顶点数组只包含项目顶点，而worker角色只管理用户顶点。这样，用户顶点也就没有镜像副本，也不需要分布式同步。在工作者角色中，项目和用户顶点的镜像存储在两个独立的数组中。\n\n另一种类型的异质性来自顶点的主副本副本上执行的不同计算，这可能需要不同的数据结构以实现同步效率。 例如，BlockPG算法访问和更新小批量中的一组特征的权重，而在采样顶点计算的目标函数可能取决于不在该块中的特征的权重。 这导致镜像上的辅助特征顶点属性，以记录特征权重的历史增量以递增地计算目标函数的值。 但是，主属性上不需要此增量属性，因此不需要在同步期间进行交换。 同样，主顶点也维护一些镜像上不需要的额外属性。 因此，TUX2允许用户为同一个顶点的主副镜像定义不同的数据结构。\n\n### Scheduling with SSP\n\nTUX2支持过时的同步并行(SSP)模型[11]，有有界的过时和小批量。SSP是基于每个clock的概念，其中一个clock对应于一个mini-Batch的迭代，并且由一组并发任务完成。迭代批处理可以看作是一个特殊的情况，每个迭代都使用所有的输入数据。SSP引入了一个显式的松弛参数，它指定了一个clock全局共享状态的视图的停顿。因此，这一空缺决定了任何任务可能取得进展的最慢的任务。随着s的松弛，时钟t上的任务保证会看到从时钟1到t-s-的所有更新，它可能会看到从时钟t-s到t-1的更新。图4展示了一个SSP执行，其松弛度为1。\n\n![upload successful](\\blog\\images\\pasted-25.png)\nTUX2在具有指定大小的Mini-Batch上执行每个迭代。每个工作人员首先选择一组顶点或边作为当前的小批量执行。在小批处理完成后，TUX2通过继续列举顶点或边缘数组的连续段，获取下一个小批量的另一组顶点或边。TUX2在小批处理粒度中支持SSP。它跟踪每个小批量迭代的进度，以便计算时钟。如果在所有的工作人员上完成相应的小批处理(包括主和镜像之间的同步)，并且如果结果更新被应用到并在状态中反映出来，那么工作人员就会认为时钟t已经完成了。一个工人可以执行一个任务在时钟t只有它知道所有时钟t -s -1已经完成,其中s是允许松懈。\n\n### MEGA Model in TUX2 TUX2\nTUX2引入了一个新的基于Stage的MEGA模型，其中每个阶段是对一组顶点及其Edge的计算。 每个阶段都有用户定义的函数（UDF）应用于在其中访问的顶点或边。 TUX2支持四种类型的阶段：Mini-Batch，Exchange，GlobalSync和Apply（因此命名为MEGA）; 它允许用户构建任意阶段的顺序。 该引擎负责调度每个阶段中多个CPU core或机器上的UDF并行执行。\n\nMEGA模型保留了GAS模型的简单性，同时引入了更多的灵活性来解决支持机器学习算法的GAS模型的缺陷。 例如，在诸如MF和LDA的算法中，处理一条边涉及更新两个顶点。 这需要两个GAS阶段，但是可以在我们的模型的一个Exchange阶段中完成。 对于LR，两个方向上的顶点数据传播之后应该跟一个Apply阶段，但是不需要Scatter阶段; 这可以在MEGA模型中避免，因为MEGA允许任意阶段的顺序。 接下来我们详细阐述不同类型的阶段。\n\n**Exchange** \n\nExchange（）在每个列举的边上执行。 Du和Dv分别是顶点u和v的数据。 D（u，v）是与边缘（u，v）相关的数据。 au，av和a（u，v）是顶点数据和边缘数据的相应累积增量，τ是与每个工作线程相关联的用户定义的共享上下文，并在整个计算过程中保持不变。 所有这些参数都允许在此UDF中更新。 用户可以使用它为顶点和边缘生成新的积累变化量，或者直接更新它们的状态。由于点划分的切割策略，Exchange（）只能更新顶点的镜像版本数据（即局部状态）。用户也可以使用τ来计算和存储一些算法特定的非图上下文数据，这可能会 通过全球聚合共享。 默认情况下，未为枚举指定的顶点受顶点级锁保护，但TUX2还允许用户为某些应用程序实现其自己的无锁语义[14,21,37]。 这个阶段比GAS模型中的聚集/散布阶段更灵活，因为它不暗示或强制顶点数据沿着边缘传播的方向，并且它可以更新同一UDF中两个顶点的状态。 从而提高LDA和MF等算法的效率。\n\n![upload successful](\\blog\\images\\pasted-24.png)\n**Apply**\n\n这个阶段枚举一组顶点并同步它们的Master版本和Mirror版本。 对于每个顶点，Master从Mirror中累积增量，调用Apply（Du，au，τ）来更新其全局状态，然后更新Mirror上的状态。 为了支持Master和Mirror之间的异构，TUX2允许用户为需要同步的顶点的全局状态定义基类VertexDataSync; Master和Mirror可以定义不同的子类，每个子类继承自基类，以包含其他信息。 引擎仅同步Master顶点和Mirror顶点之间的VertexDataSync中的数据。\n\n**GlobalSync**\n\n该阶段负责同步跨作业者线程的上下文和/或通过一组顶点聚合数据。 有三个UDF与这个阶段相关联:\nAggregate（）将跨顶点的数据聚合到Workers上下文τ中。 Combine（）将Worker的上下文τ聚合到一个特殊的Worker中，该Worker为不同的时钟维护多个版本的上下文τ以支持SSP。 Apply（）完成全局聚合的τ（例如，用于重新缩放）。 执行Apply（）后，最终的聚合τ会同步回所有Workers。 如果未提供Aggregate（）函数，则此阶段将仅在Worker中汇总和同步上下文τ。\n\n![upload successful](\\blog\\images\\pasted-23.png)\n**Mini-Batch**\n\n这是一个包含一系列其他阶段的复合阶段; 它定义了每个小批量迭代执行的阶段。 MiniBatch根据要在每个最小批次中枚举的版本或边的数量来定义最小批量大小，对于双边图，则列出要枚举的顶点类型（请参见§4中的示例）。\n\n### Conclusion\n通过TUX2，我们提倡图计算和分布式机器学习的融合。 TUX2代表了朝这个方向迈出的关键一步，不仅展示了这种融合的可行性，而且展示了这种融合的潜力。 我们通过将重要的机器学习概念引入图计算来实现这一点; 定义一个新的灵活的图模型来有效地表达机器学习算法; 并通过对代表性机器学习算法进行广泛的评估来证明其优点。 展望未来，我们希望TUX2将为进一步研究图计算和分布式机器学习提供一个共同的基础，从而允许更多的机器学习算法和优化能够被轻松高效地表达和实现。\n\n","source":"_posts/TUX2-Distributed-Graph-Computation-for-Machine-Learning.md","raw":"title: 'TUX2: Distributed Graph Computation for Machine Learning'\nauthor: Master.TJ\ntags:\n  - 图计算\ncategories:\n  - 研究生论文研读\ndate: 2018-05-25 17:27:00\n---\n## Introduce\n在图形引擎（如GraphLab [29]）上的早期工作是基于机器学习的动机，基于观察到许多机器学习问题可以用图形自然而有效地建模，并通过迭代收敛算法解决。\n\n### 问题：\n然而，大多数后续的图形引擎工作都采用简单的图计算模型，由PageRank等基本图形基准测试驱动。 由此产生的图形引擎缺乏高效分布式机器学习的灵活性和其他关键功能。\n\n1. Heterogeneous vertices：在机器学习中，顶点都有不同的属性。然而在图计算中，图引擎一般都只含有一个属性的顶点。这样对于机器学习算法来说，会带来更多的编程复杂性和性能低下。\n2. Mini-Batch：Mini-Batch是一个十分重要的概念在机器学习中。但是在图计算中缺没有这样的概念，Min-Batch意味着在机器学习中，训练一部分子集然后更新整个模型。\n![upload successful](\\blog\\images\\pasted-19.png)\n3. Flexible consistency\n 在分布式图处理系统中，多个Worker一起工作处理整个图。在每次迭代的结束，图引擎会有一个很严重的Barrier限制。然而在Min-Bach中，Hard Barrier在多个Mini-Batch中会造成太多的同步开销。由于机器算法可以容忍这样的状态。所以它们使用这样一种Soft Barrier的机制 进行局部同步。\n![upload successful](\\blog\\images\\pasted-20.png)\n\n作者提出TUX2，一个分布式图形引擎，用于在图模型中表示的机器学习算法。 TUX2保留了图计算的好处，同时还支持过时同步并行（SSP）模型[20,11,42,13]，异构数据模型和新的MEGA（小批量，Exchange，GlobalSync和 应用）图形模型以实现高效的分布式机器学习.\n\n## TuX2 Desgin\nTUX2旨在保留图形引擎的优势，同时将其数据模型，编程模型和调度方法扩展到分布式机器学习。\n\nTUX2使用顶点切割方法(vertex-cut)，其中（高度）顶点的边集可以分成多个分区，每个分区保持顶点的副本。其中一个副本被指定为Master顶点;它维护顶点数据的主版本。所有剩余的副本都称为Mirror顶点，并且每个副本都维护一个本地缓存副本。我们采用顶点切割是因为它在处理幂律图中被证明是有效的，并且它自然地连接到参数服务器模型（paraemter-server model）[26,11]：所有顶点数据的主版本可以被视为（分布式）全局状态存储在参数服务器中。在每个分区中，TUX2将顶点和边保持在单独的数组中。Edge数组中的Edge按source vertex分组。每个顶点都有一个索引，给出它在Edge数组中的边集的偏移量。每条边都包含诸如包含目标顶点的分区的ID和相应顶点数组中该顶点的索引等信息。该图形数据结构适用于遍历，并且使用查找表优于顶点索引。\n\n每个分区都由一个进程管理，该进程在逻辑上同时扮演一个Worker角色，计算分区中的顶点并沿着Edge传播顶点数据，以及一个Server角色，以同步镜像顶点与其相对应Master顶点之间的状态。 在进程内部，TUX2使用多个线程进行并行化，并将分区的Server角色和Worker角色分配给同一个线程。 然后每个线程负责计算用于本地计算的Mirrors顶点子集，并维护进程拥有的分区中Master顶点子集的状态。 图2显示了数据在TUX2中如何分区，存储和分配给执行角色。\n\n![upload successful](\\blog\\images\\pasted-21.png)\n### Heterogenous Data Layout\n\n虽然传统图形引擎简单地假设了一个同质图，但TUX2支持多种数据布局维度的异构性，包括顶点类型和分区方法; 它甚至支持主点和镜像顶点数据类型之间的异构性。 \n\nTux2重点介绍二分图上的优化，因为许多机器学习问题自然地映射为具有两个不相交顶点集的二部图，例如MF中的用户和项目，LR中的特征和样本等等。 因此这两组顶点通常具有不同的属性。 例如，在LR的情况下，只有特征顶点包含权重字段，并且只有样本顶点包含目标标签字段。 而且，在像BlockPG [27]这样的LR变体中，特征顶点也维护着过去的历史信息。因此，TUX2允许用户定义不同的顶点类型，并将不同类型的顶点放置在不同的数组中。 这导致紧凑的数据表示，从而改善计算过程中的数据局部性。此外不同的顶点类型可能包含不同的顶点度数。例如，在用户项目图中，项目顶点可以链接到数千个用户，但用户顶点通常仅链接到数十个项目。TUX2使用PowerLyra [7]和BiGraph [8]中提出的二分图感知分区算法，以便只有高度顶点才具有Mirror 顶点。\n\n在二分图中，TUX2可以通过扫描一个类型的顶点来列举所有的边。列举边类型的选择有时具有显著的性能影响。用Mini-Batch来扫描镜像顶点会导致更有效的同步步骤，只要TUX2能够识别有更新的镜像集合，这些镜像会与它们的Master同步，因为这些顶点被连续地放置在数组中。相比之下，如果TUX2在一个Mini-Batch中扫描没有镜像的顶点，那么在扫描过程中为其他顶点类型更新的镜像将被分散，从而更昂贵的定位。因此，TUX2允许用户指定在计算过程中需要计算的顶点集。\n\n![upload successful](\\blog\\images\\pasted-22.png)\nFigure3 显示了如何在二分图下组织顶点数据，并以用户-项目图中的MF为例。由于用户顶点的度数一般都比较小，所有只有项目顶点使用点划分方法切割顶点。因此，Server角色中的Master顶点数组只包含项目顶点，而worker角色只管理用户顶点。这样，用户顶点也就没有镜像副本，也不需要分布式同步。在工作者角色中，项目和用户顶点的镜像存储在两个独立的数组中。\n\n另一种类型的异质性来自顶点的主副本副本上执行的不同计算，这可能需要不同的数据结构以实现同步效率。 例如，BlockPG算法访问和更新小批量中的一组特征的权重，而在采样顶点计算的目标函数可能取决于不在该块中的特征的权重。 这导致镜像上的辅助特征顶点属性，以记录特征权重的历史增量以递增地计算目标函数的值。 但是，主属性上不需要此增量属性，因此不需要在同步期间进行交换。 同样，主顶点也维护一些镜像上不需要的额外属性。 因此，TUX2允许用户为同一个顶点的主副镜像定义不同的数据结构。\n\n### Scheduling with SSP\n\nTUX2支持过时的同步并行(SSP)模型[11]，有有界的过时和小批量。SSP是基于每个clock的概念，其中一个clock对应于一个mini-Batch的迭代，并且由一组并发任务完成。迭代批处理可以看作是一个特殊的情况，每个迭代都使用所有的输入数据。SSP引入了一个显式的松弛参数，它指定了一个clock全局共享状态的视图的停顿。因此，这一空缺决定了任何任务可能取得进展的最慢的任务。随着s的松弛，时钟t上的任务保证会看到从时钟1到t-s-的所有更新，它可能会看到从时钟t-s到t-1的更新。图4展示了一个SSP执行，其松弛度为1。\n\n![upload successful](\\blog\\images\\pasted-25.png)\nTUX2在具有指定大小的Mini-Batch上执行每个迭代。每个工作人员首先选择一组顶点或边作为当前的小批量执行。在小批处理完成后，TUX2通过继续列举顶点或边缘数组的连续段，获取下一个小批量的另一组顶点或边。TUX2在小批处理粒度中支持SSP。它跟踪每个小批量迭代的进度，以便计算时钟。如果在所有的工作人员上完成相应的小批处理(包括主和镜像之间的同步)，并且如果结果更新被应用到并在状态中反映出来，那么工作人员就会认为时钟t已经完成了。一个工人可以执行一个任务在时钟t只有它知道所有时钟t -s -1已经完成,其中s是允许松懈。\n\n### MEGA Model in TUX2 TUX2\nTUX2引入了一个新的基于Stage的MEGA模型，其中每个阶段是对一组顶点及其Edge的计算。 每个阶段都有用户定义的函数（UDF）应用于在其中访问的顶点或边。 TUX2支持四种类型的阶段：Mini-Batch，Exchange，GlobalSync和Apply（因此命名为MEGA）; 它允许用户构建任意阶段的顺序。 该引擎负责调度每个阶段中多个CPU core或机器上的UDF并行执行。\n\nMEGA模型保留了GAS模型的简单性，同时引入了更多的灵活性来解决支持机器学习算法的GAS模型的缺陷。 例如，在诸如MF和LDA的算法中，处理一条边涉及更新两个顶点。 这需要两个GAS阶段，但是可以在我们的模型的一个Exchange阶段中完成。 对于LR，两个方向上的顶点数据传播之后应该跟一个Apply阶段，但是不需要Scatter阶段; 这可以在MEGA模型中避免，因为MEGA允许任意阶段的顺序。 接下来我们详细阐述不同类型的阶段。\n\n**Exchange** \n\nExchange（）在每个列举的边上执行。 Du和Dv分别是顶点u和v的数据。 D（u，v）是与边缘（u，v）相关的数据。 au，av和a（u，v）是顶点数据和边缘数据的相应累积增量，τ是与每个工作线程相关联的用户定义的共享上下文，并在整个计算过程中保持不变。 所有这些参数都允许在此UDF中更新。 用户可以使用它为顶点和边缘生成新的积累变化量，或者直接更新它们的状态。由于点划分的切割策略，Exchange（）只能更新顶点的镜像版本数据（即局部状态）。用户也可以使用τ来计算和存储一些算法特定的非图上下文数据，这可能会 通过全球聚合共享。 默认情况下，未为枚举指定的顶点受顶点级锁保护，但TUX2还允许用户为某些应用程序实现其自己的无锁语义[14,21,37]。 这个阶段比GAS模型中的聚集/散布阶段更灵活，因为它不暗示或强制顶点数据沿着边缘传播的方向，并且它可以更新同一UDF中两个顶点的状态。 从而提高LDA和MF等算法的效率。\n\n![upload successful](\\blog\\images\\pasted-24.png)\n**Apply**\n\n这个阶段枚举一组顶点并同步它们的Master版本和Mirror版本。 对于每个顶点，Master从Mirror中累积增量，调用Apply（Du，au，τ）来更新其全局状态，然后更新Mirror上的状态。 为了支持Master和Mirror之间的异构，TUX2允许用户为需要同步的顶点的全局状态定义基类VertexDataSync; Master和Mirror可以定义不同的子类，每个子类继承自基类，以包含其他信息。 引擎仅同步Master顶点和Mirror顶点之间的VertexDataSync中的数据。\n\n**GlobalSync**\n\n该阶段负责同步跨作业者线程的上下文和/或通过一组顶点聚合数据。 有三个UDF与这个阶段相关联:\nAggregate（）将跨顶点的数据聚合到Workers上下文τ中。 Combine（）将Worker的上下文τ聚合到一个特殊的Worker中，该Worker为不同的时钟维护多个版本的上下文τ以支持SSP。 Apply（）完成全局聚合的τ（例如，用于重新缩放）。 执行Apply（）后，最终的聚合τ会同步回所有Workers。 如果未提供Aggregate（）函数，则此阶段将仅在Worker中汇总和同步上下文τ。\n\n![upload successful](\\blog\\images\\pasted-23.png)\n**Mini-Batch**\n\n这是一个包含一系列其他阶段的复合阶段; 它定义了每个小批量迭代执行的阶段。 MiniBatch根据要在每个最小批次中枚举的版本或边的数量来定义最小批量大小，对于双边图，则列出要枚举的顶点类型（请参见§4中的示例）。\n\n### Conclusion\n通过TUX2，我们提倡图计算和分布式机器学习的融合。 TUX2代表了朝这个方向迈出的关键一步，不仅展示了这种融合的可行性，而且展示了这种融合的潜力。 我们通过将重要的机器学习概念引入图计算来实现这一点; 定义一个新的灵活的图模型来有效地表达机器学习算法; 并通过对代表性机器学习算法进行广泛的评估来证明其优点。 展望未来，我们希望TUX2将为进一步研究图计算和分布式机器学习提供一个共同的基础，从而允许更多的机器学习算法和优化能够被轻松高效地表达和实现。\n\n","slug":"TUX2-Distributed-Graph-Computation-for-Machine-Learning","published":1,"updated":"2024-05-08T19:47:58.626Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62b000ddoy94khgho8l","content":"<h2 id=\"Introduce\"><a href=\"#Introduce\" class=\"headerlink\" title=\"Introduce\"></a>Introduce</h2><p>在图形引擎（如GraphLab [29]）上的早期工作是基于机器学习的动机，基于观察到许多机器学习问题可以用图形自然而有效地建模，并通过迭代收敛算法解决。</p>\n<h3 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h3><p>然而，大多数后续的图形引擎工作都采用简单的图计算模型，由PageRank等基本图形基准测试驱动。 由此产生的图形引擎缺乏高效分布式机器学习的灵活性和其他关键功能。</p>\n<ol>\n<li>Heterogeneous vertices：在机器学习中，顶点都有不同的属性。然而在图计算中，图引擎一般都只含有一个属性的顶点。这样对于机器学习算法来说，会带来更多的编程复杂性和性能低下。</li>\n<li>Mini-Batch：Mini-Batch是一个十分重要的概念在机器学习中。但是在图计算中缺没有这样的概念，Min-Batch意味着在机器学习中，训练一部分子集然后更新整个模型。<br><img src=\"\\blog\\images\\pasted-19.png\" alt=\"upload successful\"></li>\n<li>Flexible consistency<br>在分布式图处理系统中，多个Worker一起工作处理整个图。在每次迭代的结束，图引擎会有一个很严重的Barrier限制。然而在Min-Bach中，Hard Barrier在多个Mini-Batch中会造成太多的同步开销。由于机器算法可以容忍这样的状态。所以它们使用这样一种Soft Barrier的机制 进行局部同步。<br><img src=\"\\blog\\images\\pasted-20.png\" alt=\"upload successful\"></li>\n</ol>\n<p>作者提出TUX2，一个分布式图形引擎，用于在图模型中表示的机器学习算法。 TUX2保留了图计算的好处，同时还支持过时同步并行（SSP）模型[20,11,42,13]，异构数据模型和新的MEGA（小批量，Exchange，GlobalSync和 应用）图形模型以实现高效的分布式机器学习.</p>\n<h2 id=\"TuX2-Desgin\"><a href=\"#TuX2-Desgin\" class=\"headerlink\" title=\"TuX2 Desgin\"></a>TuX2 Desgin</h2><p>TUX2旨在保留图形引擎的优势，同时将其数据模型，编程模型和调度方法扩展到分布式机器学习。</p>\n<p>TUX2使用顶点切割方法(vertex-cut)，其中（高度）顶点的边集可以分成多个分区，每个分区保持顶点的副本。其中一个副本被指定为Master顶点;它维护顶点数据的主版本。所有剩余的副本都称为Mirror顶点，并且每个副本都维护一个本地缓存副本。我们采用顶点切割是因为它在处理幂律图中被证明是有效的，并且它自然地连接到参数服务器模型（paraemter-server model）[26,11]：所有顶点数据的主版本可以被视为（分布式）全局状态存储在参数服务器中。在每个分区中，TUX2将顶点和边保持在单独的数组中。Edge数组中的Edge按source vertex分组。每个顶点都有一个索引，给出它在Edge数组中的边集的偏移量。每条边都包含诸如包含目标顶点的分区的ID和相应顶点数组中该顶点的索引等信息。该图形数据结构适用于遍历，并且使用查找表优于顶点索引。</p>\n<p>每个分区都由一个进程管理，该进程在逻辑上同时扮演一个Worker角色，计算分区中的顶点并沿着Edge传播顶点数据，以及一个Server角色，以同步镜像顶点与其相对应Master顶点之间的状态。 在进程内部，TUX2使用多个线程进行并行化，并将分区的Server角色和Worker角色分配给同一个线程。 然后每个线程负责计算用于本地计算的Mirrors顶点子集，并维护进程拥有的分区中Master顶点子集的状态。 图2显示了数据在TUX2中如何分区，存储和分配给执行角色。</p>\n<p><img src=\"\\blog\\images\\pasted-21.png\" alt=\"upload successful\"></p>\n<h3 id=\"Heterogenous-Data-Layout\"><a href=\"#Heterogenous-Data-Layout\" class=\"headerlink\" title=\"Heterogenous Data Layout\"></a>Heterogenous Data Layout</h3><p>虽然传统图形引擎简单地假设了一个同质图，但TUX2支持多种数据布局维度的异构性，包括顶点类型和分区方法; 它甚至支持主点和镜像顶点数据类型之间的异构性。 </p>\n<p>Tux2重点介绍二分图上的优化，因为许多机器学习问题自然地映射为具有两个不相交顶点集的二部图，例如MF中的用户和项目，LR中的特征和样本等等。 因此这两组顶点通常具有不同的属性。 例如，在LR的情况下，只有特征顶点包含权重字段，并且只有样本顶点包含目标标签字段。 而且，在像BlockPG [27]这样的LR变体中，特征顶点也维护着过去的历史信息。因此，TUX2允许用户定义不同的顶点类型，并将不同类型的顶点放置在不同的数组中。 这导致紧凑的数据表示，从而改善计算过程中的数据局部性。此外不同的顶点类型可能包含不同的顶点度数。例如，在用户项目图中，项目顶点可以链接到数千个用户，但用户顶点通常仅链接到数十个项目。TUX2使用PowerLyra [7]和BiGraph [8]中提出的二分图感知分区算法，以便只有高度顶点才具有Mirror 顶点。</p>\n<p>在二分图中，TUX2可以通过扫描一个类型的顶点来列举所有的边。列举边类型的选择有时具有显著的性能影响。用Mini-Batch来扫描镜像顶点会导致更有效的同步步骤，只要TUX2能够识别有更新的镜像集合，这些镜像会与它们的Master同步，因为这些顶点被连续地放置在数组中。相比之下，如果TUX2在一个Mini-Batch中扫描没有镜像的顶点，那么在扫描过程中为其他顶点类型更新的镜像将被分散，从而更昂贵的定位。因此，TUX2允许用户指定在计算过程中需要计算的顶点集。</p>\n<p><img src=\"\\blog\\images\\pasted-22.png\" alt=\"upload successful\"><br>Figure3 显示了如何在二分图下组织顶点数据，并以用户-项目图中的MF为例。由于用户顶点的度数一般都比较小，所有只有项目顶点使用点划分方法切割顶点。因此，Server角色中的Master顶点数组只包含项目顶点，而worker角色只管理用户顶点。这样，用户顶点也就没有镜像副本，也不需要分布式同步。在工作者角色中，项目和用户顶点的镜像存储在两个独立的数组中。</p>\n<p>另一种类型的异质性来自顶点的主副本副本上执行的不同计算，这可能需要不同的数据结构以实现同步效率。 例如，BlockPG算法访问和更新小批量中的一组特征的权重，而在采样顶点计算的目标函数可能取决于不在该块中的特征的权重。 这导致镜像上的辅助特征顶点属性，以记录特征权重的历史增量以递增地计算目标函数的值。 但是，主属性上不需要此增量属性，因此不需要在同步期间进行交换。 同样，主顶点也维护一些镜像上不需要的额外属性。 因此，TUX2允许用户为同一个顶点的主副镜像定义不同的数据结构。</p>\n<h3 id=\"Scheduling-with-SSP\"><a href=\"#Scheduling-with-SSP\" class=\"headerlink\" title=\"Scheduling with SSP\"></a>Scheduling with SSP</h3><p>TUX2支持过时的同步并行(SSP)模型[11]，有有界的过时和小批量。SSP是基于每个clock的概念，其中一个clock对应于一个mini-Batch的迭代，并且由一组并发任务完成。迭代批处理可以看作是一个特殊的情况，每个迭代都使用所有的输入数据。SSP引入了一个显式的松弛参数，它指定了一个clock全局共享状态的视图的停顿。因此，这一空缺决定了任何任务可能取得进展的最慢的任务。随着s的松弛，时钟t上的任务保证会看到从时钟1到t-s-的所有更新，它可能会看到从时钟t-s到t-1的更新。图4展示了一个SSP执行，其松弛度为1。</p>\n<p><img src=\"\\blog\\images\\pasted-25.png\" alt=\"upload successful\"><br>TUX2在具有指定大小的Mini-Batch上执行每个迭代。每个工作人员首先选择一组顶点或边作为当前的小批量执行。在小批处理完成后，TUX2通过继续列举顶点或边缘数组的连续段，获取下一个小批量的另一组顶点或边。TUX2在小批处理粒度中支持SSP。它跟踪每个小批量迭代的进度，以便计算时钟。如果在所有的工作人员上完成相应的小批处理(包括主和镜像之间的同步)，并且如果结果更新被应用到并在状态中反映出来，那么工作人员就会认为时钟t已经完成了。一个工人可以执行一个任务在时钟t只有它知道所有时钟t -s -1已经完成,其中s是允许松懈。</p>\n<h3 id=\"MEGA-Model-in-TUX2-TUX2\"><a href=\"#MEGA-Model-in-TUX2-TUX2\" class=\"headerlink\" title=\"MEGA Model in TUX2 TUX2\"></a>MEGA Model in TUX2 TUX2</h3><p>TUX2引入了一个新的基于Stage的MEGA模型，其中每个阶段是对一组顶点及其Edge的计算。 每个阶段都有用户定义的函数（UDF）应用于在其中访问的顶点或边。 TUX2支持四种类型的阶段：Mini-Batch，Exchange，GlobalSync和Apply（因此命名为MEGA）; 它允许用户构建任意阶段的顺序。 该引擎负责调度每个阶段中多个CPU core或机器上的UDF并行执行。</p>\n<p>MEGA模型保留了GAS模型的简单性，同时引入了更多的灵活性来解决支持机器学习算法的GAS模型的缺陷。 例如，在诸如MF和LDA的算法中，处理一条边涉及更新两个顶点。 这需要两个GAS阶段，但是可以在我们的模型的一个Exchange阶段中完成。 对于LR，两个方向上的顶点数据传播之后应该跟一个Apply阶段，但是不需要Scatter阶段; 这可以在MEGA模型中避免，因为MEGA允许任意阶段的顺序。 接下来我们详细阐述不同类型的阶段。</p>\n<p><strong>Exchange</strong> </p>\n<p>Exchange（）在每个列举的边上执行。 Du和Dv分别是顶点u和v的数据。 D（u，v）是与边缘（u，v）相关的数据。 au，av和a（u，v）是顶点数据和边缘数据的相应累积增量，τ是与每个工作线程相关联的用户定义的共享上下文，并在整个计算过程中保持不变。 所有这些参数都允许在此UDF中更新。 用户可以使用它为顶点和边缘生成新的积累变化量，或者直接更新它们的状态。由于点划分的切割策略，Exchange（）只能更新顶点的镜像版本数据（即局部状态）。用户也可以使用τ来计算和存储一些算法特定的非图上下文数据，这可能会 通过全球聚合共享。 默认情况下，未为枚举指定的顶点受顶点级锁保护，但TUX2还允许用户为某些应用程序实现其自己的无锁语义[14,21,37]。 这个阶段比GAS模型中的聚集/散布阶段更灵活，因为它不暗示或强制顶点数据沿着边缘传播的方向，并且它可以更新同一UDF中两个顶点的状态。 从而提高LDA和MF等算法的效率。</p>\n<p><img src=\"\\blog\\images\\pasted-24.png\" alt=\"upload successful\"><br><strong>Apply</strong></p>\n<p>这个阶段枚举一组顶点并同步它们的Master版本和Mirror版本。 对于每个顶点，Master从Mirror中累积增量，调用Apply（Du，au，τ）来更新其全局状态，然后更新Mirror上的状态。 为了支持Master和Mirror之间的异构，TUX2允许用户为需要同步的顶点的全局状态定义基类VertexDataSync; Master和Mirror可以定义不同的子类，每个子类继承自基类，以包含其他信息。 引擎仅同步Master顶点和Mirror顶点之间的VertexDataSync中的数据。</p>\n<p><strong>GlobalSync</strong></p>\n<p>该阶段负责同步跨作业者线程的上下文和/或通过一组顶点聚合数据。 有三个UDF与这个阶段相关联:<br>Aggregate（）将跨顶点的数据聚合到Workers上下文τ中。 Combine（）将Worker的上下文τ聚合到一个特殊的Worker中，该Worker为不同的时钟维护多个版本的上下文τ以支持SSP。 Apply（）完成全局聚合的τ（例如，用于重新缩放）。 执行Apply（）后，最终的聚合τ会同步回所有Workers。 如果未提供Aggregate（）函数，则此阶段将仅在Worker中汇总和同步上下文τ。</p>\n<p><img src=\"\\blog\\images\\pasted-23.png\" alt=\"upload successful\"><br><strong>Mini-Batch</strong></p>\n<p>这是一个包含一系列其他阶段的复合阶段; 它定义了每个小批量迭代执行的阶段。 MiniBatch根据要在每个最小批次中枚举的版本或边的数量来定义最小批量大小，对于双边图，则列出要枚举的顶点类型（请参见§4中的示例）。</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>通过TUX2，我们提倡图计算和分布式机器学习的融合。 TUX2代表了朝这个方向迈出的关键一步，不仅展示了这种融合的可行性，而且展示了这种融合的潜力。 我们通过将重要的机器学习概念引入图计算来实现这一点; 定义一个新的灵活的图模型来有效地表达机器学习算法; 并通过对代表性机器学习算法进行广泛的评估来证明其优点。 展望未来，我们希望TUX2将为进一步研究图计算和分布式机器学习提供一个共同的基础，从而允许更多的机器学习算法和优化能够被轻松高效地表达和实现。</p>\n","excerpt":"","more":"<h2 id=\"Introduce\"><a href=\"#Introduce\" class=\"headerlink\" title=\"Introduce\"></a>Introduce</h2><p>在图形引擎（如GraphLab [29]）上的早期工作是基于机器学习的动机，基于观察到许多机器学习问题可以用图形自然而有效地建模，并通过迭代收敛算法解决。</p>\n<h3 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h3><p>然而，大多数后续的图形引擎工作都采用简单的图计算模型，由PageRank等基本图形基准测试驱动。 由此产生的图形引擎缺乏高效分布式机器学习的灵活性和其他关键功能。</p>\n<ol>\n<li>Heterogeneous vertices：在机器学习中，顶点都有不同的属性。然而在图计算中，图引擎一般都只含有一个属性的顶点。这样对于机器学习算法来说，会带来更多的编程复杂性和性能低下。</li>\n<li>Mini-Batch：Mini-Batch是一个十分重要的概念在机器学习中。但是在图计算中缺没有这样的概念，Min-Batch意味着在机器学习中，训练一部分子集然后更新整个模型。<br><img src=\"\\blog\\images\\pasted-19.png\" alt=\"upload successful\"></li>\n<li>Flexible consistency<br>在分布式图处理系统中，多个Worker一起工作处理整个图。在每次迭代的结束，图引擎会有一个很严重的Barrier限制。然而在Min-Bach中，Hard Barrier在多个Mini-Batch中会造成太多的同步开销。由于机器算法可以容忍这样的状态。所以它们使用这样一种Soft Barrier的机制 进行局部同步。<br><img src=\"\\blog\\images\\pasted-20.png\" alt=\"upload successful\"></li>\n</ol>\n<p>作者提出TUX2，一个分布式图形引擎，用于在图模型中表示的机器学习算法。 TUX2保留了图计算的好处，同时还支持过时同步并行（SSP）模型[20,11,42,13]，异构数据模型和新的MEGA（小批量，Exchange，GlobalSync和 应用）图形模型以实现高效的分布式机器学习.</p>\n<h2 id=\"TuX2-Desgin\"><a href=\"#TuX2-Desgin\" class=\"headerlink\" title=\"TuX2 Desgin\"></a>TuX2 Desgin</h2><p>TUX2旨在保留图形引擎的优势，同时将其数据模型，编程模型和调度方法扩展到分布式机器学习。</p>\n<p>TUX2使用顶点切割方法(vertex-cut)，其中（高度）顶点的边集可以分成多个分区，每个分区保持顶点的副本。其中一个副本被指定为Master顶点;它维护顶点数据的主版本。所有剩余的副本都称为Mirror顶点，并且每个副本都维护一个本地缓存副本。我们采用顶点切割是因为它在处理幂律图中被证明是有效的，并且它自然地连接到参数服务器模型（paraemter-server model）[26,11]：所有顶点数据的主版本可以被视为（分布式）全局状态存储在参数服务器中。在每个分区中，TUX2将顶点和边保持在单独的数组中。Edge数组中的Edge按source vertex分组。每个顶点都有一个索引，给出它在Edge数组中的边集的偏移量。每条边都包含诸如包含目标顶点的分区的ID和相应顶点数组中该顶点的索引等信息。该图形数据结构适用于遍历，并且使用查找表优于顶点索引。</p>\n<p>每个分区都由一个进程管理，该进程在逻辑上同时扮演一个Worker角色，计算分区中的顶点并沿着Edge传播顶点数据，以及一个Server角色，以同步镜像顶点与其相对应Master顶点之间的状态。 在进程内部，TUX2使用多个线程进行并行化，并将分区的Server角色和Worker角色分配给同一个线程。 然后每个线程负责计算用于本地计算的Mirrors顶点子集，并维护进程拥有的分区中Master顶点子集的状态。 图2显示了数据在TUX2中如何分区，存储和分配给执行角色。</p>\n<p><img src=\"\\blog\\images\\pasted-21.png\" alt=\"upload successful\"></p>\n<h3 id=\"Heterogenous-Data-Layout\"><a href=\"#Heterogenous-Data-Layout\" class=\"headerlink\" title=\"Heterogenous Data Layout\"></a>Heterogenous Data Layout</h3><p>虽然传统图形引擎简单地假设了一个同质图，但TUX2支持多种数据布局维度的异构性，包括顶点类型和分区方法; 它甚至支持主点和镜像顶点数据类型之间的异构性。 </p>\n<p>Tux2重点介绍二分图上的优化，因为许多机器学习问题自然地映射为具有两个不相交顶点集的二部图，例如MF中的用户和项目，LR中的特征和样本等等。 因此这两组顶点通常具有不同的属性。 例如，在LR的情况下，只有特征顶点包含权重字段，并且只有样本顶点包含目标标签字段。 而且，在像BlockPG [27]这样的LR变体中，特征顶点也维护着过去的历史信息。因此，TUX2允许用户定义不同的顶点类型，并将不同类型的顶点放置在不同的数组中。 这导致紧凑的数据表示，从而改善计算过程中的数据局部性。此外不同的顶点类型可能包含不同的顶点度数。例如，在用户项目图中，项目顶点可以链接到数千个用户，但用户顶点通常仅链接到数十个项目。TUX2使用PowerLyra [7]和BiGraph [8]中提出的二分图感知分区算法，以便只有高度顶点才具有Mirror 顶点。</p>\n<p>在二分图中，TUX2可以通过扫描一个类型的顶点来列举所有的边。列举边类型的选择有时具有显著的性能影响。用Mini-Batch来扫描镜像顶点会导致更有效的同步步骤，只要TUX2能够识别有更新的镜像集合，这些镜像会与它们的Master同步，因为这些顶点被连续地放置在数组中。相比之下，如果TUX2在一个Mini-Batch中扫描没有镜像的顶点，那么在扫描过程中为其他顶点类型更新的镜像将被分散，从而更昂贵的定位。因此，TUX2允许用户指定在计算过程中需要计算的顶点集。</p>\n<p><img src=\"\\blog\\images\\pasted-22.png\" alt=\"upload successful\"><br>Figure3 显示了如何在二分图下组织顶点数据，并以用户-项目图中的MF为例。由于用户顶点的度数一般都比较小，所有只有项目顶点使用点划分方法切割顶点。因此，Server角色中的Master顶点数组只包含项目顶点，而worker角色只管理用户顶点。这样，用户顶点也就没有镜像副本，也不需要分布式同步。在工作者角色中，项目和用户顶点的镜像存储在两个独立的数组中。</p>\n<p>另一种类型的异质性来自顶点的主副本副本上执行的不同计算，这可能需要不同的数据结构以实现同步效率。 例如，BlockPG算法访问和更新小批量中的一组特征的权重，而在采样顶点计算的目标函数可能取决于不在该块中的特征的权重。 这导致镜像上的辅助特征顶点属性，以记录特征权重的历史增量以递增地计算目标函数的值。 但是，主属性上不需要此增量属性，因此不需要在同步期间进行交换。 同样，主顶点也维护一些镜像上不需要的额外属性。 因此，TUX2允许用户为同一个顶点的主副镜像定义不同的数据结构。</p>\n<h3 id=\"Scheduling-with-SSP\"><a href=\"#Scheduling-with-SSP\" class=\"headerlink\" title=\"Scheduling with SSP\"></a>Scheduling with SSP</h3><p>TUX2支持过时的同步并行(SSP)模型[11]，有有界的过时和小批量。SSP是基于每个clock的概念，其中一个clock对应于一个mini-Batch的迭代，并且由一组并发任务完成。迭代批处理可以看作是一个特殊的情况，每个迭代都使用所有的输入数据。SSP引入了一个显式的松弛参数，它指定了一个clock全局共享状态的视图的停顿。因此，这一空缺决定了任何任务可能取得进展的最慢的任务。随着s的松弛，时钟t上的任务保证会看到从时钟1到t-s-的所有更新，它可能会看到从时钟t-s到t-1的更新。图4展示了一个SSP执行，其松弛度为1。</p>\n<p><img src=\"\\blog\\images\\pasted-25.png\" alt=\"upload successful\"><br>TUX2在具有指定大小的Mini-Batch上执行每个迭代。每个工作人员首先选择一组顶点或边作为当前的小批量执行。在小批处理完成后，TUX2通过继续列举顶点或边缘数组的连续段，获取下一个小批量的另一组顶点或边。TUX2在小批处理粒度中支持SSP。它跟踪每个小批量迭代的进度，以便计算时钟。如果在所有的工作人员上完成相应的小批处理(包括主和镜像之间的同步)，并且如果结果更新被应用到并在状态中反映出来，那么工作人员就会认为时钟t已经完成了。一个工人可以执行一个任务在时钟t只有它知道所有时钟t -s -1已经完成,其中s是允许松懈。</p>\n<h3 id=\"MEGA-Model-in-TUX2-TUX2\"><a href=\"#MEGA-Model-in-TUX2-TUX2\" class=\"headerlink\" title=\"MEGA Model in TUX2 TUX2\"></a>MEGA Model in TUX2 TUX2</h3><p>TUX2引入了一个新的基于Stage的MEGA模型，其中每个阶段是对一组顶点及其Edge的计算。 每个阶段都有用户定义的函数（UDF）应用于在其中访问的顶点或边。 TUX2支持四种类型的阶段：Mini-Batch，Exchange，GlobalSync和Apply（因此命名为MEGA）; 它允许用户构建任意阶段的顺序。 该引擎负责调度每个阶段中多个CPU core或机器上的UDF并行执行。</p>\n<p>MEGA模型保留了GAS模型的简单性，同时引入了更多的灵活性来解决支持机器学习算法的GAS模型的缺陷。 例如，在诸如MF和LDA的算法中，处理一条边涉及更新两个顶点。 这需要两个GAS阶段，但是可以在我们的模型的一个Exchange阶段中完成。 对于LR，两个方向上的顶点数据传播之后应该跟一个Apply阶段，但是不需要Scatter阶段; 这可以在MEGA模型中避免，因为MEGA允许任意阶段的顺序。 接下来我们详细阐述不同类型的阶段。</p>\n<p><strong>Exchange</strong> </p>\n<p>Exchange（）在每个列举的边上执行。 Du和Dv分别是顶点u和v的数据。 D（u，v）是与边缘（u，v）相关的数据。 au，av和a（u，v）是顶点数据和边缘数据的相应累积增量，τ是与每个工作线程相关联的用户定义的共享上下文，并在整个计算过程中保持不变。 所有这些参数都允许在此UDF中更新。 用户可以使用它为顶点和边缘生成新的积累变化量，或者直接更新它们的状态。由于点划分的切割策略，Exchange（）只能更新顶点的镜像版本数据（即局部状态）。用户也可以使用τ来计算和存储一些算法特定的非图上下文数据，这可能会 通过全球聚合共享。 默认情况下，未为枚举指定的顶点受顶点级锁保护，但TUX2还允许用户为某些应用程序实现其自己的无锁语义[14,21,37]。 这个阶段比GAS模型中的聚集/散布阶段更灵活，因为它不暗示或强制顶点数据沿着边缘传播的方向，并且它可以更新同一UDF中两个顶点的状态。 从而提高LDA和MF等算法的效率。</p>\n<p><img src=\"\\blog\\images\\pasted-24.png\" alt=\"upload successful\"><br><strong>Apply</strong></p>\n<p>这个阶段枚举一组顶点并同步它们的Master版本和Mirror版本。 对于每个顶点，Master从Mirror中累积增量，调用Apply（Du，au，τ）来更新其全局状态，然后更新Mirror上的状态。 为了支持Master和Mirror之间的异构，TUX2允许用户为需要同步的顶点的全局状态定义基类VertexDataSync; Master和Mirror可以定义不同的子类，每个子类继承自基类，以包含其他信息。 引擎仅同步Master顶点和Mirror顶点之间的VertexDataSync中的数据。</p>\n<p><strong>GlobalSync</strong></p>\n<p>该阶段负责同步跨作业者线程的上下文和/或通过一组顶点聚合数据。 有三个UDF与这个阶段相关联:<br>Aggregate（）将跨顶点的数据聚合到Workers上下文τ中。 Combine（）将Worker的上下文τ聚合到一个特殊的Worker中，该Worker为不同的时钟维护多个版本的上下文τ以支持SSP。 Apply（）完成全局聚合的τ（例如，用于重新缩放）。 执行Apply（）后，最终的聚合τ会同步回所有Workers。 如果未提供Aggregate（）函数，则此阶段将仅在Worker中汇总和同步上下文τ。</p>\n<p><img src=\"\\blog\\images\\pasted-23.png\" alt=\"upload successful\"><br><strong>Mini-Batch</strong></p>\n<p>这是一个包含一系列其他阶段的复合阶段; 它定义了每个小批量迭代执行的阶段。 MiniBatch根据要在每个最小批次中枚举的版本或边的数量来定义最小批量大小，对于双边图，则列出要枚举的顶点类型（请参见§4中的示例）。</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>通过TUX2，我们提倡图计算和分布式机器学习的融合。 TUX2代表了朝这个方向迈出的关键一步，不仅展示了这种融合的可行性，而且展示了这种融合的潜力。 我们通过将重要的机器学习概念引入图计算来实现这一点; 定义一个新的灵活的图模型来有效地表达机器学习算法; 并通过对代表性机器学习算法进行广泛的评估来证明其优点。 展望未来，我们希望TUX2将为进一步研究图计算和分布式机器学习提供一个共同的基础，从而允许更多的机器学习算法和优化能够被轻松高效地表达和实现。</p>\n"},{"title":"Fast and Concurrent RDF Queries with RDMA-based Distributed Graph Exploration","author":"Master.TJ","date":"2018-05-25T09:41:00.000Z","_content":"\n## RDF图Graph应用场景：\n通过对大量且不断增长的RDF数据进行大量查询，RDF图形存储库为并发查询处理提供低延迟和高吞吐量势在必行。\n## 现有的工作存在的问题：\n然而，先前的系统在大数据集上仍然经历高的查询延迟，并且大多数先前的设计具有较差的资源利用率，使得每个查询被顺序地处理。查询处理集中的依赖于潜在大表的连接操作，这通常会产生巨大的冗余中间数据。 此外，使用关系表triplets来存储三元组可能会限制一般性，使得现有系统难以支持RDF数据的一般图形查询，如可达性分析和社区检测。\n\n## 现有的解决方案：\n1. 使用triple 存储和 triple join方法\n存在的问题：First,使用三元组存储会过度依赖Join操作，特别是分布式环境下的merge/hash join操作。Second, scan-join操作会产生大量的中间冗余结果。Third, 尽管现有的工作使用redundant six primary SPO4 permutation index 可以加速join操作，但是索引会导致大量的内存开销。\n2. 使用Graph store 和 Graph exploration\n存在的问题：之前的工作表明，最后一步join相应的子查询结果会造成一个潜在的性能瓶颈。特别是查询那些存在环的语句，或者有很大的中间结果的情况下。‘\n\n### Graph Model And  Graph Indexs\n在Wukong中这里有两种不同类型的索引结构。分别是 Predicate Index和Type Index索引。\n\n![upload successful](\\blog\\images\\pasted-35.png)\nWukong提出了预测索引（P-idx）来维护所有使用其特定谓词标记的主体和对象入边和出边。索引顶点本质上充当从谓词到相应的主体或对象的倒排索引。Wukong还提出了一种Type Index索引方便查询一个Subject属于的类型。与先前基于图的方法（使用单独的数据结构管理索引）不同，Wukong将索引作为RDF图的基本部分（顶点和边）处理，同时还考虑了这些索引的分割和存储。 \n好处：首先，这使用图探索简化了查询处理，以便图探索可以直接从索引顶点开始。 其次，这使得在多个服务器之间分配索引变得简单而高效。\n\n### Differentiated Graph Partitioning\n\n![upload successful](\\blog\\images\\pasted-38.png)\n受到PowerLyra的启发，Wukong采用不同的分区策略算法对于正常顶点和索引顶点来说。每个正常顶点（例如，DS）将被随机分配（即，通过 散列顶点ID）到只有一个机器的所有边缘（邻居的ID）。与正常顶点不同的是，每个索引顶点（例如，takeCourse和Course）将被拆分并复制到多个机器，其边缘链接到同一机器上的正常顶点。 这很自然地将索引和它们的负载分配给每台机器。 \n\n### RDMA-friendly Predicate-based Store\n\n![upload successful](\\blog\\images\\pasted-41.png)\nWukong采用一种基于RDMA-Based的分布式hash表结构存储RDF Graph Data。在这样的结构中，它包含两种不同的索引结构，一种是Type-index索引，存储Subject/Objetc的类型索引。一种是Predicate-Index索引，存储的是谓词的相邻顶点的索引。\n\n### Query Processing Query\n1. Basic Query Processing\nWukong利用图探索通过沿着图特别是根据子图的每个边。对于大多数情况下(谓词通常是知道的恒定变量，然而subject/object是自由变量)，Wukong利用谓词索引开始进行图探索。对于那些查询是一个子图环的查询，三个Subjet/Object都是自由变量。Wukong根据基于cost的方法和一些启发式的选择一个探索顺序。对于一些罕见的情况，那些谓词都是不知道的情况下，Wukong从一个静态的(常量)的顶点进行图形探索（通过pred 已知的顶点相关联的谓词）。\n2. Full-history Pruning\n在探索查询的每一个阶段中，通过RDMA READ读取其他机器上的数据，进行裁剪。裁剪那些没有必要的冗余数据。\n\n3. Migrating Execution or Data\n对于一个查询阶段，如果有很少的顶点数据需要抓取从远程机器中，Wukong 使用一个本地执行的模式同步利用单边RDMA READ直接从远程顶点抓取数据。对于一个查询阶段，如果许多顶点需要被抓取。Wuong 利用一个Fork-Join 执行模式异步的分开查询计算到多个子查询在远程机器上。\n\n![upload successful](\\blog\\images\\pasted-45.png)\n\n### Concurrent  Query Processing\n\nWork-obliger work 窃取算法\n邻近的Worker进程的查询超时时间（s.end < now）。如果是这样的话这个Worker可能在处理冗长的查询，因此后续的查询任务可能被延迟。在这种情况下，这个Worker从该Worker的工作对队列中窃取一个查询任务来处理。在逼迫相邻的woker(知道看到一个不忙的Worker)，Worker 进程持续通过从其中自己的工作队列中，持续处理自己的查询。持续处理自己的查询。","source":"_posts/Untitled.md","raw":"title: Fast and Concurrent RDF Queries with RDMA-based Distributed Graph Exploration\nauthor: Master.TJ\ntags:\n  - RDMA\n  - 实时流处理\ncategories:\n  - 研究生论文研读\ndate: 2018-05-25 17:41:00\n---\n\n## RDF图Graph应用场景：\n通过对大量且不断增长的RDF数据进行大量查询，RDF图形存储库为并发查询处理提供低延迟和高吞吐量势在必行。\n## 现有的工作存在的问题：\n然而，先前的系统在大数据集上仍然经历高的查询延迟，并且大多数先前的设计具有较差的资源利用率，使得每个查询被顺序地处理。查询处理集中的依赖于潜在大表的连接操作，这通常会产生巨大的冗余中间数据。 此外，使用关系表triplets来存储三元组可能会限制一般性，使得现有系统难以支持RDF数据的一般图形查询，如可达性分析和社区检测。\n\n## 现有的解决方案：\n1. 使用triple 存储和 triple join方法\n存在的问题：First,使用三元组存储会过度依赖Join操作，特别是分布式环境下的merge/hash join操作。Second, scan-join操作会产生大量的中间冗余结果。Third, 尽管现有的工作使用redundant six primary SPO4 permutation index 可以加速join操作，但是索引会导致大量的内存开销。\n2. 使用Graph store 和 Graph exploration\n存在的问题：之前的工作表明，最后一步join相应的子查询结果会造成一个潜在的性能瓶颈。特别是查询那些存在环的语句，或者有很大的中间结果的情况下。‘\n\n### Graph Model And  Graph Indexs\n在Wukong中这里有两种不同类型的索引结构。分别是 Predicate Index和Type Index索引。\n\n![upload successful](\\blog\\images\\pasted-35.png)\nWukong提出了预测索引（P-idx）来维护所有使用其特定谓词标记的主体和对象入边和出边。索引顶点本质上充当从谓词到相应的主体或对象的倒排索引。Wukong还提出了一种Type Index索引方便查询一个Subject属于的类型。与先前基于图的方法（使用单独的数据结构管理索引）不同，Wukong将索引作为RDF图的基本部分（顶点和边）处理，同时还考虑了这些索引的分割和存储。 \n好处：首先，这使用图探索简化了查询处理，以便图探索可以直接从索引顶点开始。 其次，这使得在多个服务器之间分配索引变得简单而高效。\n\n### Differentiated Graph Partitioning\n\n![upload successful](\\blog\\images\\pasted-38.png)\n受到PowerLyra的启发，Wukong采用不同的分区策略算法对于正常顶点和索引顶点来说。每个正常顶点（例如，DS）将被随机分配（即，通过 散列顶点ID）到只有一个机器的所有边缘（邻居的ID）。与正常顶点不同的是，每个索引顶点（例如，takeCourse和Course）将被拆分并复制到多个机器，其边缘链接到同一机器上的正常顶点。 这很自然地将索引和它们的负载分配给每台机器。 \n\n### RDMA-friendly Predicate-based Store\n\n![upload successful](\\blog\\images\\pasted-41.png)\nWukong采用一种基于RDMA-Based的分布式hash表结构存储RDF Graph Data。在这样的结构中，它包含两种不同的索引结构，一种是Type-index索引，存储Subject/Objetc的类型索引。一种是Predicate-Index索引，存储的是谓词的相邻顶点的索引。\n\n### Query Processing Query\n1. Basic Query Processing\nWukong利用图探索通过沿着图特别是根据子图的每个边。对于大多数情况下(谓词通常是知道的恒定变量，然而subject/object是自由变量)，Wukong利用谓词索引开始进行图探索。对于那些查询是一个子图环的查询，三个Subjet/Object都是自由变量。Wukong根据基于cost的方法和一些启发式的选择一个探索顺序。对于一些罕见的情况，那些谓词都是不知道的情况下，Wukong从一个静态的(常量)的顶点进行图形探索（通过pred 已知的顶点相关联的谓词）。\n2. Full-history Pruning\n在探索查询的每一个阶段中，通过RDMA READ读取其他机器上的数据，进行裁剪。裁剪那些没有必要的冗余数据。\n\n3. Migrating Execution or Data\n对于一个查询阶段，如果有很少的顶点数据需要抓取从远程机器中，Wukong 使用一个本地执行的模式同步利用单边RDMA READ直接从远程顶点抓取数据。对于一个查询阶段，如果许多顶点需要被抓取。Wuong 利用一个Fork-Join 执行模式异步的分开查询计算到多个子查询在远程机器上。\n\n![upload successful](\\blog\\images\\pasted-45.png)\n\n### Concurrent  Query Processing\n\nWork-obliger work 窃取算法\n邻近的Worker进程的查询超时时间（s.end < now）。如果是这样的话这个Worker可能在处理冗长的查询，因此后续的查询任务可能被延迟。在这种情况下，这个Worker从该Worker的工作对队列中窃取一个查询任务来处理。在逼迫相邻的woker(知道看到一个不忙的Worker)，Worker 进程持续通过从其中自己的工作队列中，持续处理自己的查询。持续处理自己的查询。","slug":"Untitled","published":1,"updated":"2024-05-08T19:47:58.626Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62c000edoy90oly8zmq","content":"<h2 id=\"RDF图Graph应用场景：\"><a href=\"#RDF图Graph应用场景：\" class=\"headerlink\" title=\"RDF图Graph应用场景：\"></a>RDF图Graph应用场景：</h2><p>通过对大量且不断增长的RDF数据进行大量查询，RDF图形存储库为并发查询处理提供低延迟和高吞吐量势在必行。</p>\n<h2 id=\"现有的工作存在的问题：\"><a href=\"#现有的工作存在的问题：\" class=\"headerlink\" title=\"现有的工作存在的问题：\"></a>现有的工作存在的问题：</h2><p>然而，先前的系统在大数据集上仍然经历高的查询延迟，并且大多数先前的设计具有较差的资源利用率，使得每个查询被顺序地处理。查询处理集中的依赖于潜在大表的连接操作，这通常会产生巨大的冗余中间数据。 此外，使用关系表triplets来存储三元组可能会限制一般性，使得现有系统难以支持RDF数据的一般图形查询，如可达性分析和社区检测。</p>\n<h2 id=\"现有的解决方案：\"><a href=\"#现有的解决方案：\" class=\"headerlink\" title=\"现有的解决方案：\"></a>现有的解决方案：</h2><ol>\n<li>使用triple 存储和 triple join方法<br>存在的问题：First,使用三元组存储会过度依赖Join操作，特别是分布式环境下的merge/hash join操作。Second, scan-join操作会产生大量的中间冗余结果。Third, 尽管现有的工作使用redundant six primary SPO4 permutation index 可以加速join操作，但是索引会导致大量的内存开销。</li>\n<li>使用Graph store 和 Graph exploration<br>存在的问题：之前的工作表明，最后一步join相应的子查询结果会造成一个潜在的性能瓶颈。特别是查询那些存在环的语句，或者有很大的中间结果的情况下。‘</li>\n</ol>\n<h3 id=\"Graph-Model-And-Graph-Indexs\"><a href=\"#Graph-Model-And-Graph-Indexs\" class=\"headerlink\" title=\"Graph Model And  Graph Indexs\"></a>Graph Model And  Graph Indexs</h3><p>在Wukong中这里有两种不同类型的索引结构。分别是 Predicate Index和Type Index索引。</p>\n<p><img src=\"\\blog\\images\\pasted-35.png\" alt=\"upload successful\"><br>Wukong提出了预测索引（P-idx）来维护所有使用其特定谓词标记的主体和对象入边和出边。索引顶点本质上充当从谓词到相应的主体或对象的倒排索引。Wukong还提出了一种Type Index索引方便查询一个Subject属于的类型。与先前基于图的方法（使用单独的数据结构管理索引）不同，Wukong将索引作为RDF图的基本部分（顶点和边）处理，同时还考虑了这些索引的分割和存储。<br>好处：首先，这使用图探索简化了查询处理，以便图探索可以直接从索引顶点开始。 其次，这使得在多个服务器之间分配索引变得简单而高效。</p>\n<h3 id=\"Differentiated-Graph-Partitioning\"><a href=\"#Differentiated-Graph-Partitioning\" class=\"headerlink\" title=\"Differentiated Graph Partitioning\"></a>Differentiated Graph Partitioning</h3><p><img src=\"\\blog\\images\\pasted-38.png\" alt=\"upload successful\"><br>受到PowerLyra的启发，Wukong采用不同的分区策略算法对于正常顶点和索引顶点来说。每个正常顶点（例如，DS）将被随机分配（即，通过 散列顶点ID）到只有一个机器的所有边缘（邻居的ID）。与正常顶点不同的是，每个索引顶点（例如，takeCourse和Course）将被拆分并复制到多个机器，其边缘链接到同一机器上的正常顶点。 这很自然地将索引和它们的负载分配给每台机器。 </p>\n<h3 id=\"RDMA-friendly-Predicate-based-Store\"><a href=\"#RDMA-friendly-Predicate-based-Store\" class=\"headerlink\" title=\"RDMA-friendly Predicate-based Store\"></a>RDMA-friendly Predicate-based Store</h3><p><img src=\"\\blog\\images\\pasted-41.png\" alt=\"upload successful\"><br>Wukong采用一种基于RDMA-Based的分布式hash表结构存储RDF Graph Data。在这样的结构中，它包含两种不同的索引结构，一种是Type-index索引，存储Subject/Objetc的类型索引。一种是Predicate-Index索引，存储的是谓词的相邻顶点的索引。</p>\n<h3 id=\"Query-Processing-Query\"><a href=\"#Query-Processing-Query\" class=\"headerlink\" title=\"Query Processing Query\"></a>Query Processing Query</h3><ol>\n<li>Basic Query Processing<br>Wukong利用图探索通过沿着图特别是根据子图的每个边。对于大多数情况下(谓词通常是知道的恒定变量，然而subject/object是自由变量)，Wukong利用谓词索引开始进行图探索。对于那些查询是一个子图环的查询，三个Subjet/Object都是自由变量。Wukong根据基于cost的方法和一些启发式的选择一个探索顺序。对于一些罕见的情况，那些谓词都是不知道的情况下，Wukong从一个静态的(常量)的顶点进行图形探索（通过pred 已知的顶点相关联的谓词）。</li>\n<li><p>Full-history Pruning<br>在探索查询的每一个阶段中，通过RDMA READ读取其他机器上的数据，进行裁剪。裁剪那些没有必要的冗余数据。</p>\n</li>\n<li><p>Migrating Execution or Data<br>对于一个查询阶段，如果有很少的顶点数据需要抓取从远程机器中，Wukong 使用一个本地执行的模式同步利用单边RDMA READ直接从远程顶点抓取数据。对于一个查询阶段，如果许多顶点需要被抓取。Wuong 利用一个Fork-Join 执行模式异步的分开查询计算到多个子查询在远程机器上。</p>\n</li>\n</ol>\n<p><img src=\"\\blog\\images\\pasted-45.png\" alt=\"upload successful\"></p>\n<h3 id=\"Concurrent-Query-Processing\"><a href=\"#Concurrent-Query-Processing\" class=\"headerlink\" title=\"Concurrent  Query Processing\"></a>Concurrent  Query Processing</h3><p>Work-obliger work 窃取算法<br>邻近的Worker进程的查询超时时间（s.end &lt; now）。如果是这样的话这个Worker可能在处理冗长的查询，因此后续的查询任务可能被延迟。在这种情况下，这个Worker从该Worker的工作对队列中窃取一个查询任务来处理。在逼迫相邻的woker(知道看到一个不忙的Worker)，Worker 进程持续通过从其中自己的工作队列中，持续处理自己的查询。持续处理自己的查询。</p>\n","excerpt":"","more":"<h2 id=\"RDF图Graph应用场景：\"><a href=\"#RDF图Graph应用场景：\" class=\"headerlink\" title=\"RDF图Graph应用场景：\"></a>RDF图Graph应用场景：</h2><p>通过对大量且不断增长的RDF数据进行大量查询，RDF图形存储库为并发查询处理提供低延迟和高吞吐量势在必行。</p>\n<h2 id=\"现有的工作存在的问题：\"><a href=\"#现有的工作存在的问题：\" class=\"headerlink\" title=\"现有的工作存在的问题：\"></a>现有的工作存在的问题：</h2><p>然而，先前的系统在大数据集上仍然经历高的查询延迟，并且大多数先前的设计具有较差的资源利用率，使得每个查询被顺序地处理。查询处理集中的依赖于潜在大表的连接操作，这通常会产生巨大的冗余中间数据。 此外，使用关系表triplets来存储三元组可能会限制一般性，使得现有系统难以支持RDF数据的一般图形查询，如可达性分析和社区检测。</p>\n<h2 id=\"现有的解决方案：\"><a href=\"#现有的解决方案：\" class=\"headerlink\" title=\"现有的解决方案：\"></a>现有的解决方案：</h2><ol>\n<li>使用triple 存储和 triple join方法<br>存在的问题：First,使用三元组存储会过度依赖Join操作，特别是分布式环境下的merge/hash join操作。Second, scan-join操作会产生大量的中间冗余结果。Third, 尽管现有的工作使用redundant six primary SPO4 permutation index 可以加速join操作，但是索引会导致大量的内存开销。</li>\n<li>使用Graph store 和 Graph exploration<br>存在的问题：之前的工作表明，最后一步join相应的子查询结果会造成一个潜在的性能瓶颈。特别是查询那些存在环的语句，或者有很大的中间结果的情况下。‘</li>\n</ol>\n<h3 id=\"Graph-Model-And-Graph-Indexs\"><a href=\"#Graph-Model-And-Graph-Indexs\" class=\"headerlink\" title=\"Graph Model And  Graph Indexs\"></a>Graph Model And  Graph Indexs</h3><p>在Wukong中这里有两种不同类型的索引结构。分别是 Predicate Index和Type Index索引。</p>\n<p><img src=\"\\blog\\images\\pasted-35.png\" alt=\"upload successful\"><br>Wukong提出了预测索引（P-idx）来维护所有使用其特定谓词标记的主体和对象入边和出边。索引顶点本质上充当从谓词到相应的主体或对象的倒排索引。Wukong还提出了一种Type Index索引方便查询一个Subject属于的类型。与先前基于图的方法（使用单独的数据结构管理索引）不同，Wukong将索引作为RDF图的基本部分（顶点和边）处理，同时还考虑了这些索引的分割和存储。<br>好处：首先，这使用图探索简化了查询处理，以便图探索可以直接从索引顶点开始。 其次，这使得在多个服务器之间分配索引变得简单而高效。</p>\n<h3 id=\"Differentiated-Graph-Partitioning\"><a href=\"#Differentiated-Graph-Partitioning\" class=\"headerlink\" title=\"Differentiated Graph Partitioning\"></a>Differentiated Graph Partitioning</h3><p><img src=\"\\blog\\images\\pasted-38.png\" alt=\"upload successful\"><br>受到PowerLyra的启发，Wukong采用不同的分区策略算法对于正常顶点和索引顶点来说。每个正常顶点（例如，DS）将被随机分配（即，通过 散列顶点ID）到只有一个机器的所有边缘（邻居的ID）。与正常顶点不同的是，每个索引顶点（例如，takeCourse和Course）将被拆分并复制到多个机器，其边缘链接到同一机器上的正常顶点。 这很自然地将索引和它们的负载分配给每台机器。 </p>\n<h3 id=\"RDMA-friendly-Predicate-based-Store\"><a href=\"#RDMA-friendly-Predicate-based-Store\" class=\"headerlink\" title=\"RDMA-friendly Predicate-based Store\"></a>RDMA-friendly Predicate-based Store</h3><p><img src=\"\\blog\\images\\pasted-41.png\" alt=\"upload successful\"><br>Wukong采用一种基于RDMA-Based的分布式hash表结构存储RDF Graph Data。在这样的结构中，它包含两种不同的索引结构，一种是Type-index索引，存储Subject/Objetc的类型索引。一种是Predicate-Index索引，存储的是谓词的相邻顶点的索引。</p>\n<h3 id=\"Query-Processing-Query\"><a href=\"#Query-Processing-Query\" class=\"headerlink\" title=\"Query Processing Query\"></a>Query Processing Query</h3><ol>\n<li>Basic Query Processing<br>Wukong利用图探索通过沿着图特别是根据子图的每个边。对于大多数情况下(谓词通常是知道的恒定变量，然而subject/object是自由变量)，Wukong利用谓词索引开始进行图探索。对于那些查询是一个子图环的查询，三个Subjet/Object都是自由变量。Wukong根据基于cost的方法和一些启发式的选择一个探索顺序。对于一些罕见的情况，那些谓词都是不知道的情况下，Wukong从一个静态的(常量)的顶点进行图形探索（通过pred 已知的顶点相关联的谓词）。</li>\n<li><p>Full-history Pruning<br>在探索查询的每一个阶段中，通过RDMA READ读取其他机器上的数据，进行裁剪。裁剪那些没有必要的冗余数据。</p>\n</li>\n<li><p>Migrating Execution or Data<br>对于一个查询阶段，如果有很少的顶点数据需要抓取从远程机器中，Wukong 使用一个本地执行的模式同步利用单边RDMA READ直接从远程顶点抓取数据。对于一个查询阶段，如果许多顶点需要被抓取。Wuong 利用一个Fork-Join 执行模式异步的分开查询计算到多个子查询在远程机器上。</p>\n</li>\n</ol>\n<p><img src=\"\\blog\\images\\pasted-45.png\" alt=\"upload successful\"></p>\n<h3 id=\"Concurrent-Query-Processing\"><a href=\"#Concurrent-Query-Processing\" class=\"headerlink\" title=\"Concurrent  Query Processing\"></a>Concurrent  Query Processing</h3><p>Work-obliger work 窃取算法<br>邻近的Worker进程的查询超时时间（s.end &lt; now）。如果是这样的话这个Worker可能在处理冗长的查询，因此后续的查询任务可能被延迟。在这种情况下，这个Worker从该Worker的工作对队列中窃取一个查询任务来处理。在逼迫相邻的woker(知道看到一个不忙的Worker)，Worker 进程持续通过从其中自己的工作队列中，持续处理自己的查询。持续处理自己的查询。</p>\n"},{"title":"内存映射IO (MMIO)","author":"Master.TJ","date":"2018-05-25T07:46:00.000Z","_content":"MMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。\n\n### 基本概念\nMMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。（来自百度百科）\n简而言之，MMIO就是通过将外围设备映射到内存空间，便于CPU的访问。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。前者就是我们常说的I/O端口，它实际上的应该被称为I/O地址空间。\n小概念：\n32位操作系统，32bit的处理器，拥有32bit寻址能力，即可访问2^32=4G的物理地址，那么就具有4G内存的识别能力。\n物理地址：并不是指物理内存的地址，而是指处理器和系统内存之间所用到的地址，可以理解为CPU最为方便访问的地址（有别于我们之前所知道的物理地址的定义：段地址*16+偏移地址），而这一个内存并不独属于物理内存，而被分成了很多部分，物理内存当然也能够占用其中的一部分。\n\n### PortIO和MMIO 的主要区别\n1）前者不占用CPU的物理地址空间，后者占有（这是对x86架构说的，一些架构，如IA64，port I/O占用物理地址空间）。\n2）前者是顺序访问。也就是说在一条I/O指令完成前，下一条指令不会执行。例如通过Port I/O对设备发起了操作，造成了设备寄存器状态变化，这个变化在下一条指令执行前生效。uncache的MMIO通过uncahce memory的特性保证顺序性。\n3）使用方式不同\n由于port I/O有独立的64K I/O地址空间，但CPU的地址线只有一套，所以必须区分地址属于物理地址空间还是I/O地址空间。","source":"_posts/内存映射IO-MMIO.md","raw":"title: 内存映射IO (MMIO)\nauthor: Master.TJ\ntags:\n  - 计算机硬件\ncategories:\n  - 计算机硬件\ndate: 2018-05-25 15:46:00\n---\nMMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。\n\n### 基本概念\nMMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。（来自百度百科）\n简而言之，MMIO就是通过将外围设备映射到内存空间，便于CPU的访问。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。前者就是我们常说的I/O端口，它实际上的应该被称为I/O地址空间。\n小概念：\n32位操作系统，32bit的处理器，拥有32bit寻址能力，即可访问2^32=4G的物理地址，那么就具有4G内存的识别能力。\n物理地址：并不是指物理内存的地址，而是指处理器和系统内存之间所用到的地址，可以理解为CPU最为方便访问的地址（有别于我们之前所知道的物理地址的定义：段地址*16+偏移地址），而这一个内存并不独属于物理内存，而被分成了很多部分，物理内存当然也能够占用其中的一部分。\n\n### PortIO和MMIO 的主要区别\n1）前者不占用CPU的物理地址空间，后者占有（这是对x86架构说的，一些架构，如IA64，port I/O占用物理地址空间）。\n2）前者是顺序访问。也就是说在一条I/O指令完成前，下一条指令不会执行。例如通过Port I/O对设备发起了操作，造成了设备寄存器状态变化，这个变化在下一条指令执行前生效。uncache的MMIO通过uncahce memory的特性保证顺序性。\n3）使用方式不同\n由于port I/O有独立的64K I/O地址空间，但CPU的地址线只有一套，所以必须区分地址属于物理地址空间还是I/O地址空间。","slug":"内存映射IO-MMIO","published":1,"updated":"2024-05-08T19:47:58.627Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62f000fdoy97nwi73io","content":"<p>MMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>MMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。（来自百度百科）<br>简而言之，MMIO就是通过将外围设备映射到内存空间，便于CPU的访问。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。前者就是我们常说的I/O端口，它实际上的应该被称为I/O地址空间。<br>小概念：<br>32位操作系统，32bit的处理器，拥有32bit寻址能力，即可访问2^32=4G的物理地址，那么就具有4G内存的识别能力。<br>物理地址：并不是指物理内存的地址，而是指处理器和系统内存之间所用到的地址，可以理解为CPU最为方便访问的地址（有别于我们之前所知道的物理地址的定义：段地址*16+偏移地址），而这一个内存并不独属于物理内存，而被分成了很多部分，物理内存当然也能够占用其中的一部分。</p>\n<h3 id=\"PortIO和MMIO-的主要区别\"><a href=\"#PortIO和MMIO-的主要区别\" class=\"headerlink\" title=\"PortIO和MMIO 的主要区别\"></a>PortIO和MMIO 的主要区别</h3><p>1）前者不占用CPU的物理地址空间，后者占有（这是对x86架构说的，一些架构，如IA64，port I/O占用物理地址空间）。<br>2）前者是顺序访问。也就是说在一条I/O指令完成前，下一条指令不会执行。例如通过Port I/O对设备发起了操作，造成了设备寄存器状态变化，这个变化在下一条指令执行前生效。uncache的MMIO通过uncahce memory的特性保证顺序性。<br>3）使用方式不同<br>由于port I/O有独立的64K I/O地址空间，但CPU的地址线只有一套，所以必须区分地址属于物理地址空间还是I/O地址空间。</p>\n","excerpt":"","more":"<p>MMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>MMIO(Memory mapping I/O)即内存映射I/O，它是PCI规范的一部分，I/O设备被放置在内存空间而不是I/O空间。从处理器的角度看，内存映射I/O后系统设备访问起来和内存一样。这样访问AGP/PCI-E显卡上的帧缓存，BIOS，PCI设备就可以使用读写内存一样的汇编指令完成，简化了程序设计的难度和接口的复杂性。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。（来自百度百科）<br>简而言之，MMIO就是通过将外围设备映射到内存空间，便于CPU的访问。I/O作为CPU和外设交流的一个渠道，主要分为两种，一种是Port I/O，一种是MMIO(Memory mapping I/O)。前者就是我们常说的I/O端口，它实际上的应该被称为I/O地址空间。<br>小概念：<br>32位操作系统，32bit的处理器，拥有32bit寻址能力，即可访问2^32=4G的物理地址，那么就具有4G内存的识别能力。<br>物理地址：并不是指物理内存的地址，而是指处理器和系统内存之间所用到的地址，可以理解为CPU最为方便访问的地址（有别于我们之前所知道的物理地址的定义：段地址*16+偏移地址），而这一个内存并不独属于物理内存，而被分成了很多部分，物理内存当然也能够占用其中的一部分。</p>\n<h3 id=\"PortIO和MMIO-的主要区别\"><a href=\"#PortIO和MMIO-的主要区别\" class=\"headerlink\" title=\"PortIO和MMIO 的主要区别\"></a>PortIO和MMIO 的主要区别</h3><p>1）前者不占用CPU的物理地址空间，后者占有（这是对x86架构说的，一些架构，如IA64，port I/O占用物理地址空间）。<br>2）前者是顺序访问。也就是说在一条I/O指令完成前，下一条指令不会执行。例如通过Port I/O对设备发起了操作，造成了设备寄存器状态变化，这个变化在下一条指令执行前生效。uncache的MMIO通过uncahce memory的特性保证顺序性。<br>3）使用方式不同<br>由于port I/O有独立的64K I/O地址空间，但CPU的地址线只有一套，所以必须区分地址属于物理地址空间还是I/O地址空间。</p>\n"},{"title":"虚拟内存","author":"Master.TJ","date":"2018-05-29T09:32:37.000Z","_content":"虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。\n\n## 技术介绍\n虚拟内存别称虚拟存储器（Virtual Memory）。电脑中所运行的程序均需经由内存执行，若执行的程序占用内存很大或很多，则会导致内存消耗殆尽。为解决该问题，Windows中运用了虚拟内存 [2]  技术，即匀出一部分硬盘空间来充当内存使用。当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。若计算机运行程序或操作所需的随机存储器(RAM)不足时，则 Windows 会用虚拟存储器进行补偿。它将计算机的RAM和硬盘上的临时空间组合。当RAM运行速率缓慢时，它便将数据从RAM移动到称为“分页文件”的空间中。将数据移入分页文件可释放RAM，以便完成工作。 一般而言，计算机的RAM容量越大，程序运行得越快。若计算机的速率由于RAM可用空间匮乏而减缓，则可尝试通过增加虚拟内存来进行补偿。但是，计算机从RAM读取数据的速率要比从硬盘读取数据的速率快，因而扩增RAM容量（可加内存条）是最佳选择。\n\n虚拟内存是Windows 为作为内存使用的一部分硬盘空间。虚拟内存在硬盘上其实就是为一个硕大无比的文件，文件名是PageFile.Sys，通常状态下是看不到的。必须关闭资源管理器对系统文件的保护功能才能看到这个文件。虚拟内存有时候也被称为是“页面文件”就是从这个文件的文件名中来的。\n\n内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，WINDOWS运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，这部分空间即称为虚拟内存，虚拟内存在硬盘上的存在形式就是 PAGEFILE.SYS这个页面文件。\n","source":"_posts/虚拟内存.md","raw":"title: 虚拟内存\nauthor: Master.TJ\ndate: 2018-05-29 17:32:37\ntags:\n---\n虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。\n\n## 技术介绍\n虚拟内存别称虚拟存储器（Virtual Memory）。电脑中所运行的程序均需经由内存执行，若执行的程序占用内存很大或很多，则会导致内存消耗殆尽。为解决该问题，Windows中运用了虚拟内存 [2]  技术，即匀出一部分硬盘空间来充当内存使用。当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。若计算机运行程序或操作所需的随机存储器(RAM)不足时，则 Windows 会用虚拟存储器进行补偿。它将计算机的RAM和硬盘上的临时空间组合。当RAM运行速率缓慢时，它便将数据从RAM移动到称为“分页文件”的空间中。将数据移入分页文件可释放RAM，以便完成工作。 一般而言，计算机的RAM容量越大，程序运行得越快。若计算机的速率由于RAM可用空间匮乏而减缓，则可尝试通过增加虚拟内存来进行补偿。但是，计算机从RAM读取数据的速率要比从硬盘读取数据的速率快，因而扩增RAM容量（可加内存条）是最佳选择。\n\n虚拟内存是Windows 为作为内存使用的一部分硬盘空间。虚拟内存在硬盘上其实就是为一个硕大无比的文件，文件名是PageFile.Sys，通常状态下是看不到的。必须关闭资源管理器对系统文件的保护功能才能看到这个文件。虚拟内存有时候也被称为是“页面文件”就是从这个文件的文件名中来的。\n\n内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，WINDOWS运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，这部分空间即称为虚拟内存，虚拟内存在硬盘上的存在形式就是 PAGEFILE.SYS这个页面文件。\n","slug":"虚拟内存","published":1,"updated":"2024-05-08T19:47:58.627Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62j000gdoy9dqfkfeym","content":"<p>虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。</p>\n<h2 id=\"技术介绍\"><a href=\"#技术介绍\" class=\"headerlink\" title=\"技术介绍\"></a>技术介绍</h2><p>虚拟内存别称虚拟存储器（Virtual Memory）。电脑中所运行的程序均需经由内存执行，若执行的程序占用内存很大或很多，则会导致内存消耗殆尽。为解决该问题，Windows中运用了虚拟内存 [2]  技术，即匀出一部分硬盘空间来充当内存使用。当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。若计算机运行程序或操作所需的随机存储器(RAM)不足时，则 Windows 会用虚拟存储器进行补偿。它将计算机的RAM和硬盘上的临时空间组合。当RAM运行速率缓慢时，它便将数据从RAM移动到称为“分页文件”的空间中。将数据移入分页文件可释放RAM，以便完成工作。 一般而言，计算机的RAM容量越大，程序运行得越快。若计算机的速率由于RAM可用空间匮乏而减缓，则可尝试通过增加虚拟内存来进行补偿。但是，计算机从RAM读取数据的速率要比从硬盘读取数据的速率快，因而扩增RAM容量（可加内存条）是最佳选择。</p>\n<p>虚拟内存是Windows 为作为内存使用的一部分硬盘空间。虚拟内存在硬盘上其实就是为一个硕大无比的文件，文件名是PageFile.Sys，通常状态下是看不到的。必须关闭资源管理器对系统文件的保护功能才能看到这个文件。虚拟内存有时候也被称为是“页面文件”就是从这个文件的文件名中来的。</p>\n<p>内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，WINDOWS运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，这部分空间即称为虚拟内存，虚拟内存在硬盘上的存在形式就是 PAGEFILE.SYS这个页面文件。</p>\n","excerpt":"","more":"<p>虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。</p>\n<h2 id=\"技术介绍\"><a href=\"#技术介绍\" class=\"headerlink\" title=\"技术介绍\"></a>技术介绍</h2><p>虚拟内存别称虚拟存储器（Virtual Memory）。电脑中所运行的程序均需经由内存执行，若执行的程序占用内存很大或很多，则会导致内存消耗殆尽。为解决该问题，Windows中运用了虚拟内存 [2]  技术，即匀出一部分硬盘空间来充当内存使用。当内存耗尽时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。若计算机运行程序或操作所需的随机存储器(RAM)不足时，则 Windows 会用虚拟存储器进行补偿。它将计算机的RAM和硬盘上的临时空间组合。当RAM运行速率缓慢时，它便将数据从RAM移动到称为“分页文件”的空间中。将数据移入分页文件可释放RAM，以便完成工作。 一般而言，计算机的RAM容量越大，程序运行得越快。若计算机的速率由于RAM可用空间匮乏而减缓，则可尝试通过增加虚拟内存来进行补偿。但是，计算机从RAM读取数据的速率要比从硬盘读取数据的速率快，因而扩增RAM容量（可加内存条）是最佳选择。</p>\n<p>虚拟内存是Windows 为作为内存使用的一部分硬盘空间。虚拟内存在硬盘上其实就是为一个硕大无比的文件，文件名是PageFile.Sys，通常状态下是看不到的。必须关闭资源管理器对系统文件的保护功能才能看到这个文件。虚拟内存有时候也被称为是“页面文件”就是从这个文件的文件名中来的。</p>\n<p>内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。为了解决这个问题，WINDOWS运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，这部分空间即称为虚拟内存，虚拟内存在硬盘上的存在形式就是 PAGEFILE.SYS这个页面文件。</p>\n"},{"title":"深入浅出全面解析RDMA","author":"Master.TJ","date":"2018-06-04T09:32:00.000Z","_content":"  RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。\n\n 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。\n\n一、背景介绍\n\n![upload successful](\\blog\\images\\pasted-59.png)\n\n1.1 传统TCP/IP通信模式\n\n传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。\n\n![upload successful](\\blog\\images\\pasted-60.png)\n\n如今随着社会的发展，我们希望更快和更轻量级的网络通信。\n\n1.2 通信网络定义\n\n   计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。\n\n1.3  当今网络现状\n\n   当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。\n\n1.4 传统TCP/IP存在的问题\n\n   传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。\n\n二、相关工作\n\n    高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。\n\n2.1 TCP Offloading Engine\n\n   在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。\n\n   这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。\n\n2.2 User-Net Networking(U-Net)\n\n   U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。\n\n![upload successful](\\blog\\images\\pasted-61.png)\n\n   U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。\n\n三、RDMA详解\n\n   RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。\n\n![upload successful](\\blog\\images\\pasted-62.png)\n\nRDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth\n\n3.1 RDMA 简介\n\nRemote：数据通过网络与远程机器间进行数据传输\n\nDirect：没有内核的参与，有关发送传输的所有内容都卸载到网卡上\n\nMemory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制\n\nAccess：send、receive、read、write、atomic操作\n\n3.2 RDMA基本概念\n\n   RDMA有两种基本操作。\n\nMemory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。\nMessaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。\n    RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失[1]，以及使用链路层重传的基于位错误的损失[8]。因此，不可靠的传输很少会丢弃数据包。 \n\n**目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。**\n\n\n![upload successful](\\blog\\images\\pasted-63.png)\n\n\n3.3 RDMA三种不同的硬件实现\n\n   目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。\n\n![upload successful](\\blog\\images\\pasted-64.png)\n\n目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。\n\nInfiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。\nRoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。\niWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。\n\n![upload successful](\\blog\\images\\pasted-65.png)\n\n![upload successful](\\blog\\images\\pasted-66.png)\n\n3.4 RDMA技术\n\n![upload successful](\\blog\\images\\pasted-67.png)\n\n传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。\n\n3.5 RDMA整体系统架构图\n\n![upload successful](\\blog\\images\\pasted-68.png)\n\n   上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。\n\n3.6 RDMA技术详解\n\nRDMA 的工作过程如下:\n\n1) 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。\n\n2) NIC 读取缓冲的内容，并通过网络传送到远程NIC。\n\n3) 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。\n\n4) 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。\n\n3.7 RDMA操作细节\n\n   RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。\n    消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。\n\n   RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。\n\n\n![upload successful](\\blog\\images\\pasted-69.png)\n\n3.7.1 RDAM单边操作 (RDMA READ)\n\nREAD和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。\n\n对于单边操作，以存储网络环境下的存储为例，数据的流程如下：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。\n4.   A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到B的VA虚拟地址。\n5.   B在存储完成后，会向A返回整个数据传输的状态信息。\n\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n3.7.2 RDMA 单边操作 (RDMA WRITE)\n\n对于单边操作，以存储网络环境下的存储为例，数据的流程如下：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。\n4.   A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。\n5.   A在发送数据完成后，会向B返回整个数据传输的状态信息。\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n 3.7.3 RDMA 双边操作 (RDMA SEND/RECEIVE)\n\n RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。\n对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：\n1.   首先，A和B都要创建并初始化好各自的QP，CQ\n2.   A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。\n3.   A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。\n4.  AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。\n双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。","source":"_posts/深入浅出全面解析RDMA.md","raw":"title: 深入浅出全面解析RDMA\nauthor: Master.TJ\ntags:\n  - RDMA\ncategories:\n  - RDMA技术\ndate: 2018-06-04 17:32:00\n---\n  RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。\n\n 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。\n\n一、背景介绍\n\n![upload successful](\\blog\\images\\pasted-59.png)\n\n1.1 传统TCP/IP通信模式\n\n传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。\n\n![upload successful](\\blog\\images\\pasted-60.png)\n\n如今随着社会的发展，我们希望更快和更轻量级的网络通信。\n\n1.2 通信网络定义\n\n   计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。\n\n1.3  当今网络现状\n\n   当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。\n\n1.4 传统TCP/IP存在的问题\n\n   传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。\n\n二、相关工作\n\n    高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。\n\n2.1 TCP Offloading Engine\n\n   在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。\n\n   这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。\n\n2.2 User-Net Networking(U-Net)\n\n   U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。\n\n![upload successful](\\blog\\images\\pasted-61.png)\n\n   U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。\n\n三、RDMA详解\n\n   RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。\n\n![upload successful](\\blog\\images\\pasted-62.png)\n\nRDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth\n\n3.1 RDMA 简介\n\nRemote：数据通过网络与远程机器间进行数据传输\n\nDirect：没有内核的参与，有关发送传输的所有内容都卸载到网卡上\n\nMemory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制\n\nAccess：send、receive、read、write、atomic操作\n\n3.2 RDMA基本概念\n\n   RDMA有两种基本操作。\n\nMemory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。\nMessaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。\n    RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失[1]，以及使用链路层重传的基于位错误的损失[8]。因此，不可靠的传输很少会丢弃数据包。 \n\n**目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。**\n\n\n![upload successful](\\blog\\images\\pasted-63.png)\n\n\n3.3 RDMA三种不同的硬件实现\n\n   目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。\n\n![upload successful](\\blog\\images\\pasted-64.png)\n\n目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。\n\nInfiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。\nRoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。\niWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。\n\n![upload successful](\\blog\\images\\pasted-65.png)\n\n![upload successful](\\blog\\images\\pasted-66.png)\n\n3.4 RDMA技术\n\n![upload successful](\\blog\\images\\pasted-67.png)\n\n传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。\n\n3.5 RDMA整体系统架构图\n\n![upload successful](\\blog\\images\\pasted-68.png)\n\n   上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。\n\n3.6 RDMA技术详解\n\nRDMA 的工作过程如下:\n\n1) 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。\n\n2) NIC 读取缓冲的内容，并通过网络传送到远程NIC。\n\n3) 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。\n\n4) 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。\n\n3.7 RDMA操作细节\n\n   RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。\n    消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。\n\n   RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。\n\n\n![upload successful](\\blog\\images\\pasted-69.png)\n\n3.7.1 RDAM单边操作 (RDMA READ)\n\nREAD和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。\n\n对于单边操作，以存储网络环境下的存储为例，数据的流程如下：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。\n4.   A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到B的VA虚拟地址。\n5.   B在存储完成后，会向A返回整个数据传输的状态信息。\n\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n3.7.2 RDMA 单边操作 (RDMA WRITE)\n\n对于单边操作，以存储网络环境下的存储为例，数据的流程如下：\n1.   首先A、B建立连接，QP已经创建并且初始化。\n2.   数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。\n3.   B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。\n4.   A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。\n5.   A在发送数据完成后，会向B返回整个数据传输的状态信息。\n单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。\n\n 3.7.3 RDMA 双边操作 (RDMA SEND/RECEIVE)\n\n RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。\n对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：\n1.   首先，A和B都要创建并初始化好各自的QP，CQ\n2.   A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。\n3.   A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。\n4.  AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。\n双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。","slug":"深入浅出全面解析RDMA","published":1,"updated":"2024-05-08T19:47:58.627Z","comments":1,"layout":"post","photos":[],"_id":"clvy8u62q000jdoy96oup5pa5","content":"<p>  RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。</p>\n<p> 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。</p>\n<p>一、背景介绍</p>\n<p><img src=\"\\blog\\images\\pasted-59.png\" alt=\"upload successful\"></p>\n<p>1.1 传统TCP/IP通信模式</p>\n<p>传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。</p>\n<p><img src=\"\\blog\\images\\pasted-60.png\" alt=\"upload successful\"></p>\n<p>如今随着社会的发展，我们希望更快和更轻量级的网络通信。</p>\n<p>1.2 通信网络定义</p>\n<p>   计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。</p>\n<p>1.3  当今网络现状</p>\n<p>   当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。</p>\n<p>1.4 传统TCP/IP存在的问题</p>\n<p>   传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。</p>\n<p>二、相关工作</p>\n<pre><code>高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。\n</code></pre><p>2.1 TCP Offloading Engine</p>\n<p>   在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。</p>\n<p>   这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。</p>\n<p>2.2 User-Net Networking(U-Net)</p>\n<p>   U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。</p>\n<p><img src=\"\\blog\\images\\pasted-61.png\" alt=\"upload successful\"></p>\n<p>   U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。</p>\n<p>三、RDMA详解</p>\n<p>   RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。</p>\n<p><img src=\"\\blog\\images\\pasted-62.png\" alt=\"upload successful\"></p>\n<p>RDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth</p>\n<p>3.1 RDMA 简介</p>\n<p>Remote：数据通过网络与远程机器间进行数据传输</p>\n<p>Direct：没有内核的参与，有关发送传输的所有内容都卸载到网卡上</p>\n<p>Memory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制</p>\n<p>Access：send、receive、read、write、atomic操作</p>\n<p>3.2 RDMA基本概念</p>\n<p>   RDMA有两种基本操作。</p>\n<p>Memory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。<br>Messaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。<br>    RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失[1]，以及使用链路层重传的基于位错误的损失[8]。因此，不可靠的传输很少会丢弃数据包。 </p>\n<p><strong>目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。</strong></p>\n<p><img src=\"\\blog\\images\\pasted-63.png\" alt=\"upload successful\"></p>\n<p>3.3 RDMA三种不同的硬件实现</p>\n<p>   目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。</p>\n<p><img src=\"\\blog\\images\\pasted-64.png\" alt=\"upload successful\"></p>\n<p>目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。</p>\n<p>Infiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。<br>RoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。<br>iWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。</p>\n<p><img src=\"\\blog\\images\\pasted-65.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-66.png\" alt=\"upload successful\"></p>\n<p>3.4 RDMA技术</p>\n<p><img src=\"\\blog\\images\\pasted-67.png\" alt=\"upload successful\"></p>\n<p>传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。</p>\n<p>3.5 RDMA整体系统架构图</p>\n<p><img src=\"\\blog\\images\\pasted-68.png\" alt=\"upload successful\"></p>\n<p>   上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。</p>\n<p>3.6 RDMA技术详解</p>\n<p>RDMA 的工作过程如下:</p>\n<p>1) 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。</p>\n<p>2) NIC 读取缓冲的内容，并通过网络传送到远程NIC。</p>\n<p>3) 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。</p>\n<p>4) 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。</p>\n<p>3.7 RDMA操作细节</p>\n<p>   RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。<br>    消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。</p>\n<p>   RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。</p>\n<p><img src=\"\\blog\\images\\pasted-69.png\" alt=\"upload successful\"></p>\n<p>3.7.1 RDAM单边操作 (RDMA READ)</p>\n<p>READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。</p>\n<p>对于单边操作，以存储网络环境下的存储为例，数据的流程如下：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。</li>\n<li>A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到B的VA虚拟地址。</li>\n<li>B在存储完成后，会向A返回整个数据传输的状态信息。</li>\n</ol>\n<p>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>3.7.2 RDMA 单边操作 (RDMA WRITE)</p>\n<p>对于单边操作，以存储网络环境下的存储为例，数据的流程如下：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。</li>\n<li>A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。</li>\n<li><p>A在发送数据完成后，会向B返回整个数据传输的状态信息。<br>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>3.7.3 RDMA 双边操作 (RDMA SEND/RECEIVE)</p>\n<p>RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。<br>对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：</p>\n</li>\n<li>首先，A和B都要创建并初始化好各自的QP，CQ</li>\n<li>A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。</li>\n<li>A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。</li>\n<li>AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。<br>双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。</li>\n</ol>\n","excerpt":"","more":"<p>  RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。</p>\n<p> 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。</p>\n<p>一、背景介绍</p>\n<p><img src=\"\\blog\\images\\pasted-59.png\" alt=\"upload successful\"></p>\n<p>1.1 传统TCP/IP通信模式</p>\n<p>传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。</p>\n<p><img src=\"\\blog\\images\\pasted-60.png\" alt=\"upload successful\"></p>\n<p>如今随着社会的发展，我们希望更快和更轻量级的网络通信。</p>\n<p>1.2 通信网络定义</p>\n<p>   计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。</p>\n<p>1.3  当今网络现状</p>\n<p>   当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。</p>\n<p>1.4 传统TCP/IP存在的问题</p>\n<p>   传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。</p>\n<p>二、相关工作</p>\n<pre><code>高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。\n</code></pre><p>2.1 TCP Offloading Engine</p>\n<p>   在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。</p>\n<p>   这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。</p>\n<p>2.2 User-Net Networking(U-Net)</p>\n<p>   U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。</p>\n<p><img src=\"\\blog\\images\\pasted-61.png\" alt=\"upload successful\"></p>\n<p>   U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。</p>\n<p>三、RDMA详解</p>\n<p>   RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。</p>\n<p><img src=\"\\blog\\images\\pasted-62.png\" alt=\"upload successful\"></p>\n<p>RDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth</p>\n<p>3.1 RDMA 简介</p>\n<p>Remote：数据通过网络与远程机器间进行数据传输</p>\n<p>Direct：没有内核的参与，有关发送传输的所有内容都卸载到网卡上</p>\n<p>Memory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制</p>\n<p>Access：send、receive、read、write、atomic操作</p>\n<p>3.2 RDMA基本概念</p>\n<p>   RDMA有两种基本操作。</p>\n<p>Memory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。<br>Messaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。<br>    RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失[1]，以及使用链路层重传的基于位错误的损失[8]。因此，不可靠的传输很少会丢弃数据包。 </p>\n<p><strong>目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。</strong></p>\n<p><img src=\"\\blog\\images\\pasted-63.png\" alt=\"upload successful\"></p>\n<p>3.3 RDMA三种不同的硬件实现</p>\n<p>   目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。</p>\n<p><img src=\"\\blog\\images\\pasted-64.png\" alt=\"upload successful\"></p>\n<p>目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。</p>\n<p>Infiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。<br>RoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。<br>iWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。</p>\n<p><img src=\"\\blog\\images\\pasted-65.png\" alt=\"upload successful\"></p>\n<p><img src=\"\\blog\\images\\pasted-66.png\" alt=\"upload successful\"></p>\n<p>3.4 RDMA技术</p>\n<p><img src=\"\\blog\\images\\pasted-67.png\" alt=\"upload successful\"></p>\n<p>传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。</p>\n<p>3.5 RDMA整体系统架构图</p>\n<p><img src=\"\\blog\\images\\pasted-68.png\" alt=\"upload successful\"></p>\n<p>   上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。</p>\n<p>3.6 RDMA技术详解</p>\n<p>RDMA 的工作过程如下:</p>\n<p>1) 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。</p>\n<p>2) NIC 读取缓冲的内容，并通过网络传送到远程NIC。</p>\n<p>3) 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。</p>\n<p>4) 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。</p>\n<p>3.7 RDMA操作细节</p>\n<p>   RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。<br>    消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。</p>\n<p>   RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。</p>\n<p><img src=\"\\blog\\images\\pasted-69.png\" alt=\"upload successful\"></p>\n<p>3.7.1 RDAM单边操作 (RDMA READ)</p>\n<p>READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。</p>\n<p>对于单边操作，以存储网络环境下的存储为例，数据的流程如下：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。</li>\n<li>A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到B的VA虚拟地址。</li>\n<li>B在存储完成后，会向A返回整个数据传输的状态信息。</li>\n</ol>\n<p>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>3.7.2 RDMA 单边操作 (RDMA WRITE)</p>\n<p>对于单边操作，以存储网络环境下的存储为例，数据的流程如下：</p>\n<ol>\n<li>首先A、B建立连接，QP已经创建并且初始化。</li>\n<li>数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。</li>\n<li>B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。</li>\n<li>A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。</li>\n<li><p>A在发送数据完成后，会向B返回整个数据传输的状态信息。<br>单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。</p>\n<p>3.7.3 RDMA 双边操作 (RDMA SEND/RECEIVE)</p>\n<p>RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。<br>对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下：</p>\n</li>\n<li>首先，A和B都要创建并初始化好各自的QP，CQ</li>\n<li>A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。</li>\n<li>A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。</li>\n<li>AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。<br>双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。</li>\n</ol>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clvy8u61s0001doy9fw621nhm","category_id":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64b0012doy988ib6qnj"},{"post_id":"clvy8u6260009doy94wpnfozd","category_id":"clvy8u62t000mdoy9f8c7c73d","_id":"clvy8u64b0014doy9a6y394hx"},{"post_id":"clvy8u628000adoy9djet2drv","category_id":"clvy8u62y000odoy9eiuug831","_id":"clvy8u64b0016doy901vc7f1y"},{"post_id":"clvy8u62a000cdoy9gj1x6hsx","category_id":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64c0019doy9hwiifpul"},{"post_id":"clvy8u62b000ddoy94khgho8l","category_id":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64c001bdoy928lzdg94"},{"post_id":"clvy8u62c000edoy90oly8zmq","category_id":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64c001ddoy91q9o25n4"},{"post_id":"clvy8u62f000fdoy97nwi73io","category_id":"clvy8u62y000odoy9eiuug831","_id":"clvy8u64d001fdoy95gov9kbt"},{"post_id":"clvy8u6250008doy92x7wdeoo","category_id":"clvy8u62k000hdoy90xbj7r8e","_id":"clvy8u64s001kdoy9bh0k476u"},{"post_id":"clvy8u6250008doy92x7wdeoo","category_id":"clvy8u64a0011doy936lcfwth","_id":"clvy8u64s001ldoy9afhn4uec"},{"post_id":"clvy8u62q000jdoy96oup5pa5","category_id":"clvy8u64c0017doy9d2jf1wwc","_id":"clvy8u64s001mdoy9cpqw1frc"}],"PostTag":[{"post_id":"clvy8u61s0001doy9fw621nhm","tag_id":"clvy8u62p000idoy9797h7ye1","_id":"clvy8u64a0010doy98hsf6w06"},{"post_id":"clvy8u6220007doy9fi7j993u","tag_id":"clvy8u62p000idoy9797h7ye1","_id":"clvy8u64b0013doy9896661gi"},{"post_id":"clvy8u6250008doy92x7wdeoo","tag_id":"clvy8u62v000ndoy90uen6kve","_id":"clvy8u64b0015doy9cbjmfdao"},{"post_id":"clvy8u6260009doy94wpnfozd","tag_id":"clvy8u62z000pdoy9h6a37ef2","_id":"clvy8u64c0018doy982rve6mf"},{"post_id":"clvy8u628000adoy9djet2drv","tag_id":"clvy8u633000rdoy9bsvfg05l","_id":"clvy8u64c001adoy9d90v3e1n"},{"post_id":"clvy8u629000bdoy9b0goa7g2","tag_id":"clvy8u62v000ndoy90uen6kve","_id":"clvy8u64c001cdoy991da28ps"},{"post_id":"clvy8u62b000ddoy94khgho8l","tag_id":"clvy8u62p000idoy9797h7ye1","_id":"clvy8u64d001edoy9bd3pg20r"},{"post_id":"clvy8u62c000edoy90oly8zmq","tag_id":"clvy8u62v000ndoy90uen6kve","_id":"clvy8u64d001gdoy95ew8eqdc"},{"post_id":"clvy8u62c000edoy90oly8zmq","tag_id":"clvy8u639000ydoy93a255vxq","_id":"clvy8u64d001hdoy95h2uc1o9"},{"post_id":"clvy8u62f000fdoy97nwi73io","tag_id":"clvy8u633000rdoy9bsvfg05l","_id":"clvy8u64d001idoy9fw3l65n5"},{"post_id":"clvy8u62q000jdoy96oup5pa5","tag_id":"clvy8u62v000ndoy90uen6kve","_id":"clvy8u64d001jdoy9hwcjaynp"}],"Tag":[{"name":"图计算","_id":"clvy8u62p000idoy9797h7ye1"},{"name":"RDMA","_id":"clvy8u62v000ndoy90uen6kve"},{"name":"-linux","_id":"clvy8u62z000pdoy9h6a37ef2"},{"name":"计算机硬件","_id":"clvy8u633000rdoy9bsvfg05l"},{"name":"实时流处理","_id":"clvy8u639000ydoy93a255vxq"}]}}